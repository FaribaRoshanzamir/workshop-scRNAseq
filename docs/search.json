[
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-seurat",
    "href": "labs/index.html#fa-brands-r-project-seurat",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-bioconductor",
    "href": "labs/index.html#fa-brands-r-project-bioconductor",
    "title": "Labs",
    "section": " Bioconductor",
    "text": "Bioconductor\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-python-scanpy",
    "href": "labs/index.html#fa-brands-python-scanpy",
    "title": "Labs",
    "section": " Scanpy",
    "text": "Scanpy\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Trajectory inference using PAGA\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html",
    "href": "labs/seurat/seurat_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_data",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_covid &lt;- \"./data/covid\"\nif (!dir.exists(path_covid)) dir.create(path_covid, recursive = T)\n\npath_results &lt;- \"data/covid/results\"\nif (!dir.exists(path_results)) dir.create(path_results, recursive = T)\n\n\nfile_list &lt;- c(\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n)\n\nfor (i in file_list) {\n    path_file &lt;- file.path(path_covid, i)\n    if (!file.exists(path_file)) {\n        download.file(url = file.path(file.path(path_data, \"covid\"), i), destfile = path_file)\n    }\n}\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(Matrix)\n    library(ggplot2)\n    library(patchwork)\n    # remotes::install_github(\"chris-mcginnis-ucsf/DoubletFinder\", upgrade = FALSE, dependencies = TRUE)\n    library(DoubletFinder)\n})\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\n\ncov.15 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_15.h5\"),\n    use.names = T\n)\ncov.1 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_1.h5\"),\n    use.names = T\n)\ncov.16 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_16.h5\"),\n    use.names = T\n)\ncov.17 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_17.h5\"),\n    use.names = T\n)\n\nctrl.5 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_5.h5\"),\n    use.names = T\n)\nctrl.13 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_13.h5\"),\n    use.names = T\n)\nctrl.14 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_14.h5\"),\n    use.names = T\n)\nctrl.19 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_19.h5\"),\n    use.names = T\n)"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_collate",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\nWe can now load the expression matrices and merge them into a single object. Each analysis workflow (Seurat, Scater, Scanpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column Chemistry in the metadata for plotting later on.\n\nsdata.cov1 &lt;- CreateSeuratObject(cov.1, project = \"covid_1\")\nsdata.cov15 &lt;- CreateSeuratObject(cov.15, project = \"covid_15\")\nsdata.cov17 &lt;- CreateSeuratObject(cov.17, project = \"covid_17\")\nsdata.cov16 &lt;- CreateSeuratObject(cov.16, project = \"covid_16\")\nsdata.ctrl5 &lt;- CreateSeuratObject(ctrl.5, project = \"ctrl_5\")\nsdata.ctrl13 &lt;- CreateSeuratObject(ctrl.13, project = \"ctrl_13\")\nsdata.ctrl14 &lt;- CreateSeuratObject(ctrl.14, project = \"ctrl_14\")\nsdata.ctrl19 &lt;- CreateSeuratObject(ctrl.19, project = \"ctrl_19\")\n\n\n# add metadata\nsdata.cov1$type &lt;- \"Covid\"\nsdata.cov15$type &lt;- \"Covid\"\nsdata.cov16$type &lt;- \"Covid\"\nsdata.cov17$type &lt;- \"Covid\"\n\nsdata.ctrl5$type &lt;- \"Ctrl\"\nsdata.ctrl13$type &lt;- \"Ctrl\"\nsdata.ctrl14$type &lt;- \"Ctrl\"\nsdata.ctrl19$type &lt;- \"Ctrl\"\n\n# Merge datasets into one single seurat object\nalldata &lt;- merge(sdata.cov1, c(sdata.cov15, sdata.cov16, sdata.cov17, sdata.ctrl5, sdata.ctrl13, sdata.ctrl14, sdata.ctrl19), add.cell.ids = c(\"covid_1\", \"covid_15\", \"covid_16\", \"covid_17\", \"ctrl_5\", \"ctrl_13\", \"ctrl_14\", \"ctrl_19\"))\n\nOnce you have created the merged Seurat object, the count matrices and individual count matrices and objects are not needed anymore. It is a good idea to remove them and run garbage collect to free up some memory.\n\n# remove all objects that will not be used.\nrm(cov.1, cov.15, cov.16, cov.17, ctrl.5, ctrl.13, ctrl.14, ctrl.19, sdata.cov1, sdata.cov15, sdata.cov16, sdata.cov17, sdata.ctrl5, sdata.ctrl13, sdata.ctrl14, sdata.ctrl19)\n# run garbage collect to free up memory\ngc()\n\n           used  (Mb) gc trigger (Mb)  max used   (Mb)\nNcells  3325459 177.6    4998412  267   4998412  267.0\nVcells 58182395 443.9  150859912 1151 136166604 1038.9\n\n\nHere is how the count matrix and the metadata look like for every cell.\n\nas.data.frame(alldata@assays$RNA@counts[1:10, 1:2])\n\n\n\n  \n\n\nhead(alldata@meta.data, 10)"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_calqc",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion hemoglobin genes can give an indication of red blood cell contamination. This will be helpful to visualize them across different metadata parameteres (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\n\n# method 1: doing it using Seurat function\nalldata &lt;- PercentageFeatureSet(alldata, \"^MT-\", col.name = \"percent_mito\")\n\n\n# OBS! Do not run now!\n# example method 2: doing it manually\ntotal_counts_per_cell &lt;- colSums(alldata@assays$RNA@counts)\nmito_genes &lt;- rownames(alldata)[grep(\"^MT-\", rownames(alldata))]\nalldata$percent_mito2 &lt;- colSums(alldata@assays$RNA@counts[mito_genes, ]) / total_counts_per_cell\n\n\n# Ribosomal\nalldata &lt;- PercentageFeatureSet(alldata, \"^RP[SL]\", col.name = \"percent_ribo\")\n# Percentage hemoglobin genes - includes all genes starting with HB except HBP.\nalldata &lt;- PercentageFeatureSet(alldata, \"^HB[^(P|E|S)]\", col.name = \"percent_hb\")\n# Percentage for some platelet markers\nalldata &lt;- PercentageFeatureSet(alldata, \"PECAM1|PF4\", col.name = \"percent_plat\")\n\nNow you can see that we have additional data in the metadata slot.\n\nhead(alldata[[]])"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_plotqc",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\nfeats &lt;- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\", \"percent_ribo\", \"percent_hb\", \"percent_plat\")\nVlnPlot(alldata, group.by = \"orig.ident\", features = feats, pt.size = 0.1, ncol = 3) + NoLegend()\n\n\n\n\n\n\n\n\nAs you can see, there is quite some difference in quality for the 4 datasets, with for instance the covid_15 sample having fewer cells with many detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. And we can plot the different QC-measures as scatter plots.\n\nFeatureScatter(alldata, \"nCount_RNA\", \"nFeature_RNA\", group.by = \"orig.ident\", pt.size = .5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_filter",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\n\nselected_c &lt;- WhichCells(alldata, expression = nFeature_RNA &gt; 200)\nselected_f &lt;- rownames(alldata)[Matrix::rowSums(alldata) &gt; 3]\n\ndata.filt &lt;- subset(alldata, features = selected_f, cells = selected_c)\ndim(data.filt)\n\n[1] 18877 10656\n\ntable(data.filt$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n    1254     1283     1127     1371     1417     1399     1434     1371 \n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip and run DoubletFinder instead\n# data.filt &lt;- subset(data.filt, cells=WhichCells(data.filt, expression = nFeature_RNA &lt; 4100))\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\n\n# Compute the proportion of counts of each gene per cell\n# Use sparse matrix operations, if your dataset is large, doing matrix devisions the regular way will take a very long time.\n\nC &lt;- data.filt@assays$RNA@counts\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p)) * 100\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])),\n    cex = 0.1, las = 1, xlab = \"Percent counts per cell\",\n    col = (scales::hue_pal())(20)[20:1], horizontal = TRUE\n)\n\n\n\n\n\n\n\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\nselected_mito &lt;- WhichCells(data.filt, expression = percent_mito &lt; 20)\nselected_ribo &lt;- WhichCells(data.filt, expression = percent_ribo &gt; 5)\n\n# and subset the object to only keep those cells\ndata.filt &lt;- subset(data.filt, cells = selected_mito)\ndata.filt &lt;- subset(data.filt, cells = selected_ribo)\ndim(data.filt)\n\n[1] 18877  7431\n\ntable(data.filt$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n     900      599      373     1101     1173     1063     1170     1052 \n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats another time.\n\nfeats &lt;- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\", \"percent_ribo\", \"percent_hb\")\nVlnPlot(data.filt, group.by = \"orig.ident\", features = feats, pt.size = 0.1, ncol = 3) + NoLegend()\n\n\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis.\n\ndim(data.filt)\n\n[1] 18877  7431\n\n# Filter MALAT1\ndata.filt &lt;- data.filt[!grepl(\"MALAT1\", rownames(data.filt)), ]\n\n# Filter Mitocondrial\ndata.filt &lt;- data.filt[!grepl(\"^MT-\", rownames(data.filt)), ]\n\n# Filter Ribossomal gene (optional if that is a problem on your data)\n# data.filt &lt;- data.filt[ ! grepl(\"^RP[SL]\", rownames(data.filt)), ]\n\n# Filter Hemoglobin gene (optional if that is a problem on your data)\ndata.filt &lt;- data.filt[!grepl(\"^HB[^(P)]\", rownames(data.filt)), ]\n\ndim(data.filt)\n\n[1] 18851  7431"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_sex",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain you experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also bee a good way to detect if there has been any sample mixups, if the sample metadata sex does not agree with the computational predictions.\nTo get chromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. R package biomaRt can be used to fetch annotation information. The code to run biomaRt is provided. As the biomart instances quite often are unresponsive, we will download and use a file that was created in advance.\n\n# this code chunk is not executed\nsuppressMessages(library(biomaRt))\n\n# initialize connection to mart, may take some time if the sites are unresponsive.\nmart &lt;- useMart(\"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n\n# fetch chromosome info plus some other annotations\ngenes_table &lt;- try(biomaRt::getBM(attributes = c(\n    \"ensembl_gene_id\", \"external_gene_name\",\n    \"description\", \"gene_biotype\", \"chromosome_name\", \"start_position\"\n), mart = mart, useCache = F))\n\nwrite.csv(genes_table, file = \"data/results/genes_table.csv\")\n\n\ngenes_file &lt;- file.path(path_results, \"genes_table.csv\")\n\nif (!file.exists(genes_file)) download.file(file.path(path_data, \"covid/results/genes_table.csv\"), destfile = genes_file)\ngenes.table &lt;- read.csv(genes_file)\n\ngenes.table &lt;- genes.table[genes.table$external_gene_name %in% rownames(data.filt), ]\n\nNow that we have the chromosome information, we can calculate per cell the proportion of reads that comes from chromosome Y.\n\nchrY.gene &lt;- genes.table$external_gene_name[genes.table$chromosome_name == \"Y\"]\ndata.filt$pct_chrY &lt;- colSums(data.filt@assays$RNA@counts[chrY.gene, ]) / colSums(data.filt@assays$RNA@counts)\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\nFeatureScatter(data.filt, feature1 = \"XIST\", feature2 = \"pct_chrY\")\n\n\n\n\n\n\n\n\nPlot as violins.\n\nVlnPlot(data.filt, features = c(\"XIST\", \"pct_chrY\"))\n\n\n\n\n\n\n\n\nHere, we can see clearly that we have two males and 4 females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_cellcycle",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\n# Before running CellCycleScoring the data need to be normalized and logtransformed.\ndata.filt &lt;- NormalizeData(data.filt)\ndata.filt &lt;- CellCycleScoring(\n    object = data.filt,\n    g2m.features = cc.genes$g2m.genes,\n    s.features = cc.genes$s.genes\n)\n\nWe can now plot a violin plot for the cell cycle scores as well.\n\nVlnPlot(data.filt, features = c(\"S.Score\", \"G2M.Score\"), group.by = \"orig.ident\", ncol = 3, pt.size = .1)\n\n\n\n\n\n\n\n\nIn this case it looks like we only have a few cycling cells in the datasets.\nSeurat does an automatic prediction of cell cycle phase with a default cutoff of the scores at zero. As you can see this does not fit this data very well, so be cautios with using these predictions. Instead we suggest that you look at the scores.\n\nFeatureScatter(data.filt, \"S.Score\", \"G2M.Score\", group.by = \"Phase\")"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_doublet",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\n\n\n\n\n\n\nCaution\n\n\n\nIdeally doublet prediction should be run on each sample separately, especially if your different samples have different proportions of cell types. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs so it is okay to run them together.\n\n\nHere, we will use DoubletFinder to predict doublet cells. But before doing doublet detection we need to run scaling, variable gene selection and pca, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.\n\ndata.filt &lt;- FindVariableFeatures(data.filt, verbose = F)\ndata.filt &lt;- ScaleData(data.filt, vars.to.regress = c(\"nFeature_RNA\", \"percent_mito\"), verbose = F)\ndata.filt &lt;- RunPCA(data.filt, verbose = F, npcs = 20)\ndata.filt &lt;- RunUMAP(data.filt, dims = 1:10, verbose = F)\n\nThen we run doubletFinder, selecting first 10 PCs and a pK value of 0.9. To optimize the parameters, you can run the paramSweep function in the package.\n\nsuppressMessages(library(DoubletFinder))\n# Can run parameter optimization with paramSweep\n\n# sweep.res &lt;- paramSweep_v3(data.filt)\n# sweep.stats &lt;- summarizeSweep(sweep.res, GT = FALSE)\n# bcmvn &lt;- find.pK(sweep.stats)\n# barplot(bcmvn$BCmetric, names.arg = bcmvn$pK, las=2)\n\n# define the expected number of doublet cellscells.\nnExp &lt;- round(ncol(data.filt) * 0.04) # expect 4% doublets\ndata.filt &lt;- doubletFinder_v3(data.filt, pN = 0.25, pK = 0.09, nExp = nExp, PCs = 1:10)\n\n[1] \"Creating 2477 artificial doublets...\"\n[1] \"Creating Seurat object...\"\n[1] \"Normalizing Seurat object...\"\n[1] \"Finding variable genes...\"\n[1] \"Scaling data...\"\n[1] \"Running PCA...\"\n[1] \"Calculating PC distance matrix...\"\n[1] \"Computing pANN...\"\n[1] \"Classifying doublets..\"\n\n\n\n# name of the DF prediction can change, so extract the correct column name.\nDF.name &lt;- colnames(data.filt@meta.data)[grepl(\"DF.classification\", colnames(data.filt@meta.data))]\n\nwrap_plots(\n    DimPlot(data.filt, group.by = \"orig.ident\") + NoAxes(),\n    DimPlot(data.filt, group.by = DF.name) + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nWe should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.\n\nVlnPlot(data.filt, features = \"nFeature_RNA\", group.by = DF.name, pt.size = .1)\n\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\ndata.filt &lt;- data.filt[, data.filt@meta.data[, DF.name] == \"Singlet\"]\ndim(data.filt)\n\n[1] 18851  7134"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_save",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory results and save data to that folder. This will be used in downstream labs.\n\nsaveRDS(data.filt, file.path(path_results, \"seurat_covid_qc.rds\"))"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-session",
    "href": "labs/seurat/seurat_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] KernSmooth_2.23-20  fields_14.1         viridis_0.6.3      \n [4] viridisLite_0.4.2   spam_2.9-1          DoubletFinder_2.0.3\n [7] patchwork_1.1.2     ggplot2_3.4.2       Matrix_1.5-4       \n[10] SeuratObject_4.1.3  Seurat_4.3.0       \n\nloaded via a namespace (and not attached):\n  [1] deldir_1.0-9           pbapply_1.7-0          gridExtra_2.3         \n  [4] rlang_1.1.1            magrittr_2.0.3         RcppAnnoy_0.0.20      \n  [7] spatstat.geom_3.2-1    matrixStats_1.0.0      ggridges_0.5.4        \n [10] compiler_4.3.0         maps_3.4.1             png_0.1-8             \n [13] vctrs_0.6.2            reshape2_1.4.4         hdf5r_1.3.8           \n [16] stringr_1.5.0          pkgconfig_2.0.3        fastmap_1.1.1         \n [19] ellipsis_0.3.2         labeling_0.4.2         utf8_1.2.3            \n [22] promises_1.2.0.1       rmarkdown_2.22         bit_4.0.5             \n [25] purrr_1.0.1            xfun_0.39              jsonlite_1.8.5        \n [28] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-3  \n [31] irlba_2.3.5.1          parallel_4.3.0         cluster_2.1.4         \n [34] R6_2.5.1               ica_1.0-3              stringi_1.7.12        \n [37] RColorBrewer_1.1-3     spatstat.data_3.0-1    reticulate_1.30       \n [40] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [43] Rcpp_1.0.10            knitr_1.43             tensor_1.5            \n [46] future.apply_1.11.0    zoo_1.8-12             sctransform_0.3.5     \n [49] httpuv_1.6.11          splines_4.3.0          igraph_1.4.3          \n [52] tidyselect_1.2.0       abind_1.4-5            rstudioapi_0.14       \n [55] yaml_2.3.7             spatstat.random_3.1-5  codetools_0.2-19      \n [58] miniUI_0.1.1.1         spatstat.explore_3.2-1 listenv_0.9.0         \n [61] lattice_0.21-8         tibble_3.2.1           plyr_1.8.8            \n [64] withr_2.5.0            shiny_1.7.4            ROCR_1.0-11           \n [67] evaluate_0.21          Rtsne_0.16             future_1.32.0         \n [70] survival_3.5-5         polyclip_1.10-4        fitdistrplus_1.1-11   \n [73] pillar_1.9.0           plotly_4.10.2          generics_0.1.3        \n [76] sp_1.6-1               munsell_0.5.0          scales_1.2.1          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.0            data.table_1.14.8     \n [85] RANN_2.6.1             dotCall64_1.0-2        leiden_0.4.3          \n [88] cowplot_1.1.1          grid_4.3.0             tidyr_1.3.0           \n [91] colorspace_2.1-0       nlme_3.1-162           cli_3.6.1             \n [94] spatstat.sparse_3.0-1  fansi_1.0.4            dplyr_1.1.2           \n [97] uwot_0.1.14            gtable_0.3.3           digest_0.6.31         \n[100] progressr_0.13.0       ggrepel_0.9.3          farver_2.1.1          \n[103] htmlwidgets_1.6.2      htmltools_0.5.5        lifecycle_1.0.3       \n[106] httr_1.4.6             mime_0.12              bit64_4.0.5           \n[109] MASS_7.3-58.4"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html",
    "href": "labs/seurat/seurat_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_prep",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\n# Activate conda environment to get the correct python path\nreticulate::use_condaenv(\"seurat\", conda = \"/opt/conda/bin/conda\")\nreticulate::py_discover_config()\n\npython:         /opt/conda/envs/seurat/bin/python\nlibpython:      /opt/conda/envs/seurat/lib/libpython3.8.so\npythonhome:     /opt/conda/envs/seurat:/opt/conda/envs/seurat\nversion:        3.8.18 | packaged by conda-forge | (default, Dec 23 2023, 17:21:28)  [GCC 12.3.0]\nnumpy:          /opt/conda/envs/seurat/lib/python3.8/site-packages/numpy\nnumpy_version:  1.24.4\n\nNOTE: Python version was forced by use_python function\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(ggplot2) # plotting\n    library(patchwork) # combining figures\n    library(scran)\n})\n\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/seurat_covid_qc.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_fs",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nNext, we first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\n\nsuppressWarnings(suppressMessages(alldata &lt;- FindVariableFeatures(alldata, selection.method = \"vst\", nfeatures = 2000, verbose = FALSE, assay = \"RNA\")))\ntop20 &lt;- head(VariableFeatures(alldata), 20)\n\nLabelPoints(plot = VariableFeaturePlot(alldata), points = top20, repel = TRUE)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_zs",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the data is prepared, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling is called Z-score normalization it is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\n\nalldata &lt;- ScaleData(alldata, vars.to.regress = c(\"percent_mito\", \"nFeature_RNA\"), assay = \"RNA\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_pca",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of life sciences, we want to segregate samples based on gene expression patterns in the data.\nTo run PCA you can use the function RunPCA().\n\nalldata &lt;- RunPCA(alldata, npcs = 50, verbose = F)\n\nWe then plot the first principal components.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 1:2),\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 3:4),\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 5:6),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nTo identify which genes (Seurat) or metadata parameters (Scater/Scran) contribute the most to each PC, one can retrieve the loading matrix information. Unfortunately, this is not implemented in Scater/Scran, so you will need to compute PCA using logcounts.\n\nVizDimLoadings(alldata, dims = 1:5, reduction = \"pca\", ncol = 5, balanced = T)\n\n\n\n\n\n\n\n\nWe can also plot the amount of variance explained by each PC.\n\nElbowPlot(alldata, reduction = \"pca\", ndims = 50)\n\n\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_tsne",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe can now run BH-tSNE.\n\nalldata &lt;- RunTSNE(\n    alldata,\n    reduction = \"pca\", dims = 1:30,\n    perplexity = 30,\n    max_iter = 1000,\n    theta = 0.5,\n    eta = 200,\n    num_threads = 0\n)\n# see ?Rtsne and ?RunTSNE for more info\n\nWe can now plot the tSNE colored per dataset. We can clearly see the effect of batches present in the dataset.\n\nDimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_umap",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nWe can now run UMAP for cell embeddings.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction = \"pca\",\n    dims = 1:30,\n    n.components = 2,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n# see ?RunUMAP for more info\n\nAnother usefullness of UMAP is that it is not limitted by the number of dimensions the data cen be reduced into (unlike tSNE). We can simply reduce the dimentions altering the n.components parameter. So here we will create an UMAP with 10 dimensions.\nIn Seurat we can add in additional reductions, by default they are named “pca”, “umap”, “tsne” etc. depending on the function you run. Here we will specify an alternative name for the umap with the reduction.name parameter.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction.name = \"UMAP10_on_PCA\",\n    reduction = \"pca\",\n    dims = 1:30,\n    n.components = 10,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n# see ?RunUMAP for more info\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    DimPlot(alldata, reduction = \"UMAP10_on_PCA\", group.by = \"orig.ident\", dims = 1:2) + ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    DimPlot(alldata, reduction = \"UMAP10_on_PCA\", group.by = \"orig.ident\", dims = 3:4) + ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE, what similarities/differences do you see, can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\"),\n    DimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_zsg",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_zsg",
    "title": " Dimensionality Reduction",
    "section": "7 Z-scores & DR graphs",
    "text": "7 Z-scores & DR graphs\nAlthough running a second dimensionality reduction (i.e tSNE or UMAP) on PCA would be a standard approach (because it allows higher computation efficiency), the options are actually limitless. Below we will show a couple of other common options such as running directly on the scaled data (z-scores) (which was used for PCA) or on a graph built from scaled data. We will show from now on only UMAP, but the same applies for tSNE.\n\n7.1 UMAP from z-scores\nTo run tSNE or UMAP on the scaled data, one first needs to select the number of variables to use. This is because including dimensions that do contribute to the separation of your cell types will in the end mask those differences. Another reason for it is because running with all genes/features also will take longer or might be computationally unfeasible. Therefore we will use the scaled data of the highly variable genes.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction.name = \"UMAP_on_ScaleData\",\n    features = alldata@assays$RNA@var.features,\n    assay = \"RNA\",\n    n.components = 2,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n\n\n\n7.2 UMAP from graph\nTo run tSNE or UMAP on the a graph, we first need to build a graph from the data. In fact, both tSNE and UMAP first build a graph from the data using a specified distance matrix and then optimize the embedding. Since a graph is just a matrix containing distances from cell to cell and as such, you can run either UMAP or tSNE using any other distance metric desired. Euclidean and Correlation are usually the most commonly used.\n\n# Build Graph\nalldata &lt;- FindNeighbors(alldata,\n    reduction = \"pca\",\n    assay = \"RNA\",\n    k.param = 20,\n    features = alldata@assays$RNA@var.features\n)\n\nalldata &lt;- RunUMAP(alldata,\n    reduction.name = \"UMAP_on_Graph\",\n    umap.method = \"umap-learn\",\n    graph = \"RNA_snn\",\n    n.epochs = 200,\n    assay = \"RNA\"\n)\n\nWe can now plot the UMAP comparing both on PCA vs ScaledSata vs Graph.\n\np1 &lt;- DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_PCA\")\np2 &lt;- DimPlot(alldata, reduction = \"UMAP_on_ScaleData\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_ScaleData\")\np3 &lt;- DimPlot(alldata, reduction = \"UMAP_on_Graph\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_Graph\")\nwrap_plots(p1, p2, p3, nrow = 3) + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "8 Genes of interest",
    "text": "8 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nmyfeatures &lt;- c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")\nFeaturePlot(alldata, reduction = \"umap\", dims = 1:2, features = myfeatures, ncol = 4, order = T) +\n    NoLegend() + NoAxes() + NoGrid()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_save",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "9 Save data",
    "text": "9 Save data\nWe can finally save the object for use in future steps.\n\nsaveRDS(alldata, \"data/covid/results/seurat_covid_qc_dr.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-session",
    "href": "labs/seurat/seurat_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] scran_1.30.0                scuttle_1.12.0             \n [3] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [5] Biobase_2.62.0              GenomicRanges_1.54.1       \n [7] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n [9] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[11] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n[13] patchwork_1.1.2             ggplot2_3.4.2              \n[15] SeuratObject_4.1.3          Seurat_4.3.0               \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3        rstudioapi_0.14          \n  [3] jsonlite_1.8.5            magrittr_2.0.3           \n  [5] spatstat.utils_3.0-3      farver_2.1.1             \n  [7] rmarkdown_2.22            zlibbioc_1.48.0          \n  [9] vctrs_0.6.2               ROCR_1.0-11              \n [11] DelayedMatrixStats_1.24.0 spatstat.explore_3.2-1   \n [13] RCurl_1.98-1.12           S4Arrays_1.2.0           \n [15] htmltools_0.5.5           BiocNeighbors_1.20.2     \n [17] SparseArray_1.2.3         sctransform_0.3.5        \n [19] parallelly_1.36.0         KernSmooth_2.23-20       \n [21] htmlwidgets_1.6.2         ica_1.0-3                \n [23] plyr_1.8.8                plotly_4.10.2            \n [25] zoo_1.8-12                igraph_1.4.3             \n [27] mime_0.12                 lifecycle_1.0.3          \n [29] pkgconfig_2.0.3           rsvd_1.0.5               \n [31] Matrix_1.5-4              R6_2.5.1                 \n [33] fastmap_1.1.1             GenomeInfoDbData_1.2.11  \n [35] fitdistrplus_1.1-11       future_1.32.0            \n [37] shiny_1.7.4               digest_0.6.31            \n [39] colorspace_2.1-0          rprojroot_2.0.3          \n [41] tensor_1.5                dqrng_0.3.0              \n [43] irlba_2.3.5.1             beachmat_2.18.0          \n [45] labeling_0.4.2            progressr_0.13.0         \n [47] fansi_1.0.4               spatstat.sparse_3.0-1    \n [49] httr_1.4.6                polyclip_1.10-4          \n [51] abind_1.4-5               compiler_4.3.0           \n [53] here_1.0.1                withr_2.5.0              \n [55] BiocParallel_1.36.0       MASS_7.3-58.4            \n [57] DelayedArray_0.28.0       bluster_1.12.0           \n [59] tools_4.3.0               lmtest_0.9-40            \n [61] httpuv_1.6.11             future.apply_1.11.0      \n [63] goftest_1.2-3             glue_1.6.2               \n [65] nlme_3.1-162              promises_1.2.0.1         \n [67] grid_4.3.0                Rtsne_0.16               \n [69] cluster_2.1.4             reshape2_1.4.4           \n [71] generics_0.1.3            gtable_0.3.3             \n [73] spatstat.data_3.0-1       tidyr_1.3.0              \n [75] data.table_1.14.8         metapod_1.10.1           \n [77] ScaledMatrix_1.10.0       BiocSingular_1.18.0      \n [79] sp_1.6-1                  utf8_1.2.3               \n [81] XVector_0.42.0            spatstat.geom_3.2-1      \n [83] RcppAnnoy_0.0.20          ggrepel_0.9.3            \n [85] RANN_2.6.1                pillar_1.9.0             \n [87] stringr_1.5.0             limma_3.58.1             \n [89] later_1.3.1               splines_4.3.0            \n [91] dplyr_1.1.2               lattice_0.21-8           \n [93] survival_3.5-5            deldir_1.0-9             \n [95] tidyselect_1.2.0          locfit_1.5-9.8           \n [97] miniUI_0.1.1.1            pbapply_1.7-0            \n [99] knitr_1.43                gridExtra_2.3            \n[101] edgeR_4.0.7               scattermore_1.2          \n[103] xfun_0.39                 statmod_1.5.0            \n[105] stringi_1.7.12            lazyeval_0.2.2           \n[107] yaml_2.3.7                evaluate_0.21            \n[109] codetools_0.2-19          tibble_3.2.1             \n[111] cli_3.6.1                 uwot_0.1.14              \n[113] xtable_1.8-4              reticulate_1.30          \n[115] munsell_0.5.0             Rcpp_1.0.10              \n[117] globals_0.16.2            spatstat.random_3.1-5    \n[119] png_0.1-8                 parallel_4.3.0           \n[121] ellipsis_0.3.2            sparseMatrixStats_1.14.0 \n[123] bitops_1.0-7              listenv_0.9.0            \n[125] viridisLite_0.4.2         scales_1.2.1             \n[127] ggridges_0.5.4            crayon_1.5.2             \n[129] leiden_0.4.3              purrr_1.0.1              \n[131] rlang_1.1.1               cowplot_1.1.1"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html",
    "href": "labs/seurat/seurat_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-int_prep",
    "href": "labs/seurat/seurat_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(ggplot2)\n    library(patchwork)\n    library(reticulate)\n})\n\n# Activate scanorama Python venv\nreticulate::use_virtualenv(\"/opt/venv/scanorama\")\nreticulate::py_discover_config()\n\npython:         /opt/venv/scanorama/bin/python\nlibpython:      /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so\npythonhome:     /opt/venv/scanorama:/opt/venv/scanorama\nversion:        3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\nnumpy:          /opt/venv/scanorama/lib/python3.10/site-packages/numpy\nnumpy_version:  1.26.3\n\nNOTE: Python version was forced by use_python function\n\n\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr.rds\"\nif(!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/seurat_covid_qc_dr.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)\nprint(names(alldata@reductions))\n\n[1] \"pca\"               \"umap\"              \"tsne\"             \n[4] \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\" \"UMAP_on_Graph\"    \n\n\nWe split the combined object into a list, with each dataset as an element. We perform standard preprocessing (log-normalization), and identify variable features individually for each dataset based on a variance stabilizing transformation (vst).\n\nalldata.list &lt;- SplitObject(alldata, split.by = \"orig.ident\")\n\nfor (i in 1:length(alldata.list)) {\n    alldata.list[[i]] &lt;- NormalizeData(alldata.list[[i]], verbose = FALSE)\n    alldata.list[[i]] &lt;- FindVariableFeatures(alldata.list[[i]], selection.method = \"vst\", nfeatures = 2000,verbose = FALSE)\n}\n\n# get the variable genes from all the datasets.\nhvgs_per_dataset &lt;- lapply(alldata.list, function(x) { x@assays$RNA@var.features })\n\n# also add in the variable genes that was selected on the whole dataset\nhvgs_per_dataset$all = VariableFeatures(alldata)\n\ntemp &lt;- unique(unlist(hvgs_per_dataset))\noverlap &lt;- sapply( hvgs_per_dataset , function(x) { temp %in% x } )\npheatmap::pheatmap(t(overlap*1),cluster_rows = F ,\n                   color = c(\"grey90\",\"grey20\"))\n\n\n\n\n\n\n\n\nAs you can see, there are a lot of genes that are variable in just one dataset. There are also some genes in the gene set that was selected using all the data that are not variable in any of the individual datasets. These are most likely genes driven by batch effects.\nA better way to select features for integration is to combine the information on variable genes across the dataset. This can be done with the function SelectIntegrationFeatures that combines the ranks of the variable features in the different datasets.\n\nhvgs_all = SelectIntegrationFeatures(alldata.list)\nhvgs_per_dataset$all_ranks = hvgs_all\n\ntemp &lt;- unique(unlist(hvgs_per_dataset))\noverlap &lt;- sapply( hvgs_per_dataset , function(x) { temp %in% x } )\npheatmap::pheatmap(t(overlap*1),cluster_rows = F ,\n                   color = c(\"grey90\",\"grey20\"))\n\n\n\n\n\n\n\n\nFor all downstream integration we will use this set of genes."
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#cca",
    "href": "labs/seurat/seurat_03_integration.html#cca",
    "title": " Data Integration",
    "section": "2 CCA",
    "text": "2 CCA\nWe identify anchors using the FindIntegrationAnchors function, which takes a list of Seurat objects as input.\n\nalldata.anchors &lt;- FindIntegrationAnchors(object.list = alldata.list, dims = 1:30,reduction = \"cca\", anchor.features = hvgs_all)\n\nWe then pass these anchors to the IntegrateData function, which returns a Seurat object.\n\nalldata.int &lt;- IntegrateData(anchorset = alldata.anchors, dims = 1:30, new.assay.name = \"CCA\")\n\nWe can observe that a new assay slot is now created under the name CCA. If you do not specify the assay name the default will be integrated.\n\nnames(alldata.int@assays)\n\n[1] \"RNA\" \"CCA\"\n\n# by default, Seurat now sets the integrated assay as the default assay, so any operation you now perform will be on the integrated data.\nalldata.int@active.assay\n\n[1] \"CCA\"\n\n\nAfter running IntegrateData, the Seurat object will contain a new Assay with the integrated (or batch-corrected) expression matrix. Note that the original (uncorrected values) are still stored in the object in the “RNA” assay, so you can switch back and forth. We can then use this new integrated matrix for downstream analysis and visualization. Here we scale the integrated data, run PCA, and visualize the results with UMAP and TSNE. The integrated datasets cluster by cell type, instead of by technology.\nAs CCA is the active.assay now the functions will by default run on the data in that assay. But you could also specify in each of the functions to run them in a specific assay with the parameter assay = \"CCA\".\n\n#Run Dimensionality reduction on integrated space\nalldata.int &lt;- ScaleData(alldata.int, verbose = FALSE)\nalldata.int &lt;- RunPCA(alldata.int, npcs = 30, verbose = FALSE)\nalldata.int &lt;- RunUMAP(alldata.int, dims = 1:30)\nalldata.int &lt;- RunTSNE(alldata.int, dims = 1:30)\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nwrap_plots(\n  DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"PCA raw_data\"),\n  DimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"tSNE raw_data\"),\n  DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"UMAP raw_data\"),\n  \n  DimPlot(alldata.int, reduction = \"pca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"PCA integrated\"),\n  DimPlot(alldata.int, reduction = \"tsne\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"tSNE integrated\"),\n  DimPlot(alldata.int, reduction = \"umap\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"UMAP integrated\"),\n  ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n2.1 Clean memory\nAgain we have a lot of large objects in the memory. We have the original data alldata but also the integrated data in alldata.int. We also have the split objects in alldata.list and the anchors in alldata.anchors. In principle we only need the integrated object for now, but we will also keep the list for running Scanorama further down in the tutorial.\nWe also want to keep is the orignial umap for visualization purposes, so we copy it over to the integrated object.\n\nalldata.int@reductions$umap_raw = alldata@reductions$umap\n\n# remove all objects that will not be used.\nrm(alldata,  alldata.anchors)\n# run garbage collect to free up memory\ngc()\n\n            used   (Mb) gc trigger   (Mb)  max used   (Mb)\nNcells   3414313  182.4    4989403  266.5   4989403  266.5\nVcells 203222859 1550.5  564336378 4305.6 879335547 6708.8\n\n\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nmyfeatures &lt;- c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")\nFeaturePlot(alldata.int, reduction = \"umap\", dims = 1:2, features = myfeatures, ncol = 4, order = T) + NoLegend() + NoAxes() + NoGrid()"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#harmony",
    "href": "labs/seurat/seurat_03_integration.html#harmony",
    "title": " Data Integration",
    "section": "3 Harmony",
    "text": "3 Harmony\nAn alternative method for integration is Harmony, for more details on the method, please se their paper Nat. Methods.\nThis method runs the integration on a dimensionality reduction, in most applications the PCA. So first, we will rerun scaling and PCA with the same set of genes that were used for the CCA integration.\nOBS! Make sure to revert back to the RNA assay.\n\nalldata.int@active.assay = \"RNA\"\nVariableFeatures(alldata.int) = hvgs_all\nalldata.int = ScaleData(alldata.int, vars.to.regress = c(\"percent_mito\", \"nFeature_RNA\"))\nalldata.int = RunPCA(alldata.int, reduction.name = \"pca_harmony\")\n\nNow we are ready to run Harmony.\n\nlibrary(harmony)\n\nalldata.int &lt;- RunHarmony(\n  alldata.int,\n  group.by.vars = \"orig.ident\",\n  reduction.use = \"pca_harmony\",\n  dims.use = 1:50,\n  assay.use = \"RNA\")\n\nHarmony will create another reduction slot in your seurat object with the name “harmony”, so now we can use that reduction instead of PCA to run UMAP.\n\nalldata.int &lt;- RunUMAP(alldata.int, dims = 1:50, reduction = \"harmony\", reduction.name = \"umap_harmony\")\n\nDimPlot(alldata.int, reduction = \"umap_harmony\", group.by = \"orig.ident\") + NoAxes() + ggtitle(\"Harmony UMAP\")"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#scanorama",
    "href": "labs/seurat/seurat_03_integration.html#scanorama",
    "title": " Data Integration",
    "section": "4 Scanorama",
    "text": "4 Scanorama\nAnother integration method is Scanorama (see Nat. Biotech.). This method is implemented in python, but we can run it through the Reticulate package.\n\nassaylist &lt;- list()\ngenelist &lt;- list()\nfor(i in 1:length(alldata.list)) {\n  assaylist[[i]] &lt;- t(as.matrix(GetAssayData(alldata.list[[i]], \"data\")[hvgs_all,]))\n  genelist[[i]] &lt;- hvgs_all\n}\n\nlapply(assaylist,dim)\n\n[[1]]\n[1]  873 2000\n\n[[2]]\n[1]  556 2000\n\n[[3]]\n[1]  358 2000\n\n[[4]]\n[1] 1050 2000\n\n[[5]]\n[1] 1034 2000\n\n[[6]]\n[1] 1126 2000\n\n[[7]]\n[1]  998 2000\n\n[[8]]\n[1] 1139 2000\n\n\n\n# Activate scanorama Python venv\nscanorama &lt;- reticulate::import(\"scanorama\")\n\nintegrated.data &lt;- scanorama$integrate(datasets_full = assaylist,\n                                       genes_list = genelist )\n\n# Now we create a new dim reduction object in the format that Seurat uses\nintdimred &lt;- do.call(rbind, integrated.data[[1]])\ncolnames(intdimred) &lt;- paste0(\"PC_\", 1:100)\nrownames(intdimred) &lt;- colnames(alldata.int)\n\n# Add standard deviations in order to draw Elbow Plots in Seurat\nstdevs &lt;- apply(intdimred, MARGIN = 2, FUN = sd)\n\n# Create a new dim red object.\nalldata.int[[\"scanorama\"]] &lt;- CreateDimReducObject(\n  embeddings = intdimred,\n  stdev      = stdevs,\n  key        = \"PC_\",\n  assay      = \"RNA\")\n\n\n#Here we use all PCs computed from Scanorama for UMAP calculation\nalldata.int &lt;- RunUMAP(alldata.int, dims = 1:100, reduction = \"scanorama\",reduction.name = \"umap_scanorama\")\n\nDimPlot(alldata.int, reduction = \"umap_scanorama\", group.by = \"orig.ident\") + NoAxes() + ggtitle(\"Harmony UMAP\")"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#overview-all-methods",
    "href": "labs/seurat/seurat_03_integration.html#overview-all-methods",
    "title": " Data Integration",
    "section": "5 Overview all methods",
    "text": "5 Overview all methods\nNow we will plot UMAPS with all three integration methods side by side.\n\np1 &lt;- DimPlot(alldata.int, reduction = \"umap_raw\", group.by = \"orig.ident\") + ggtitle(\"UMAP raw_data\")\np2 &lt;- DimPlot(alldata.int, reduction = \"umap\", group.by = \"orig.ident\") + ggtitle(\"UMAP CCA\")\np3 &lt;- DimPlot(alldata.int, reduction = \"umap_harmony\", group.by = \"orig.ident\") + ggtitle(\"UMAP Harmony\")\np4 &lt;- DimPlot(alldata.int, reduction = \"umap_scanorama\", group.by = \"orig.ident\")+ggtitle(\"UMAP Scanorama\")\n\nwrap_plots(p1, p2, p3, p4, nrow = 2) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLook at the different integration results, which one do you think looks the best? How would you motivate selecting one method over the other? How do you think you could best evaluate if the integration worked well?\n\n\nLet’s save the integrated data for further analysis.\n\nsaveRDS(alldata.int,\"data/covid/results/seurat_covid_qc_dr_int.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#extra-task",
    "href": "labs/seurat/seurat_03_integration.html#extra-task",
    "title": " Data Integration",
    "section": "6 Extra task",
    "text": "6 Extra task\nYou have now done the Seurat integration with CCA which is quite slow. There are other options in the FindIntegrationAnchors function. Try rerunning the integration with rpca and/or rlsi and create a new UMAP. Compare the results."
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-session",
    "href": "labs/seurat/seurat_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] harmony_1.2.0      Rcpp_1.0.10        reticulate_1.30    patchwork_1.1.2   \n[5] ggplot2_3.4.2      SeuratObject_4.1.3 Seurat_4.3.0      \n\nloaded via a namespace (and not attached):\n  [1] deldir_1.0-9           pbapply_1.7-0          gridExtra_2.3         \n  [4] rlang_1.1.1            magrittr_2.0.3         RcppAnnoy_0.0.20      \n  [7] spatstat.geom_3.2-1    matrixStats_1.0.0      ggridges_0.5.4        \n [10] compiler_4.3.0         png_0.1-8              vctrs_0.6.2           \n [13] reshape2_1.4.4         stringr_1.5.0          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.2        \n [19] utf8_1.2.3             promises_1.2.0.1       rmarkdown_2.22        \n [22] purrr_1.0.1            xfun_0.39              jsonlite_1.8.5        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-3  \n [28] irlba_2.3.5.1          parallel_4.3.0         cluster_2.1.4         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.7.12        \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-1    parallelly_1.36.0     \n [37] lmtest_0.9-40          scattermore_1.2        knitr_1.43            \n [40] tensor_1.5             future.apply_1.11.0    zoo_1.8-12            \n [43] sctransform_0.3.5      httpuv_1.6.11          Matrix_1.5-4          \n [46] splines_4.3.0          igraph_1.4.3           tidyselect_1.2.0      \n [49] abind_1.4-5            rstudioapi_0.14        yaml_2.3.7            \n [52] spatstat.random_3.1-5  codetools_0.2-19       miniUI_0.1.1.1        \n [55] spatstat.explore_3.2-1 listenv_0.9.0          lattice_0.21-8        \n [58] tibble_3.2.1           plyr_1.8.8             withr_2.5.0           \n [61] shiny_1.7.4            ROCR_1.0-11            evaluate_0.21         \n [64] Rtsne_0.16             future_1.32.0          survival_3.5-5        \n [67] polyclip_1.10-4        fitdistrplus_1.1-11    pillar_1.9.0          \n [70] KernSmooth_2.23-20     plotly_4.10.2          generics_0.1.3        \n [73] rprojroot_2.0.3        sp_1.6-1               munsell_0.5.0         \n [76] scales_1.2.1           globals_0.16.2         xtable_1.8-4          \n [79] RhpcBLASctl_0.23-42    glue_1.6.2             pheatmap_1.0.12       \n [82] lazyeval_0.2.2         tools_4.3.0            data.table_1.14.8     \n [85] RANN_2.6.1             leiden_0.4.3           cowplot_1.1.1         \n [88] grid_4.3.0             tidyr_1.3.0            colorspace_2.1-0      \n [91] nlme_3.1-162           cli_3.6.1              spatstat.sparse_3.0-1 \n [94] fansi_1.0.4            viridisLite_0.4.2      dplyr_1.1.2           \n [97] uwot_0.1.14            gtable_0.3.3           digest_0.6.31         \n[100] progressr_0.13.0       ggrepel_0.9.3          farver_2.1.1          \n[103] htmlwidgets_1.6.2      htmltools_0.5.5        lifecycle_1.0.3       \n[106] here_1.0.1             httr_1.4.6             mime_0.12             \n[109] MASS_7.3-58.4"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html",
    "href": "labs/seurat/seurat_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will continue the analysis of the integrated dataset. We will use the integrated PCA to perform the clustering. First we will construct a \\(k\\)-nearest neighbor graph in order to perform a clustering on the graph. We will also show how to perform hierarchical clustering and k-means clustering on PCA space.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(clustree)\n})\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr_int.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/seurat_covid_qc_dr_int.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)\nprint(names(alldata@reductions))\n\n[1] \"pca\"          \"umap\"         \"tsne\"         \"umap_raw\"     \"pca_harmony\" \n[6] \"harmony\"      \"umap_harmony\""
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_graphclust",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps: 1) Build a kNN graph from the data. 2) Prune spurious connections from kNN graph (optional step). This is a SNN graph. 3) Find groups of cells that maximizes the connections within the group compared other groups.\n\n1.1 Building kNN / SNN graph\nThe first step into graph clustering is to construct a k-nn graph, in case you don’t have one. For this, we will use the PCA space. Thus, as done for dimensionality reduction, we will use ony the top N PCA dimensions for this purpose (the same used for computing UMAP / tSNE).\nAs we can see above, the Seurat function FindNeighbors() already computes both the KNN and SNN graphs, in which we can control the minimal percentage of shared neighbours to be kept. See ?FindNeighbors for additional options.\n\n# check if CCA is still the active assay\nalldata@active.assay\n\n[1] \"RNA\"\n\n# set the correct assay.\nalldata@active.assay &lt;- \"CCA\"\n\nalldata &lt;- FindNeighbors(alldata, dims = 1:30, k.param = 60, prune.SNN = 1 / 15)\n\n# check the names for graphs in the object.\nnames(alldata@graphs)\n\n[1] \"CCA_nn\"  \"CCA_snn\"\n\n\nWe can take a look at the kNN and SNN graphs. The kNN graph is a matrix where every connection between cells is represented as \\(1\\)s. This is called a unweighted graph (default in Seurat). In the SNN graph on the other hand, Some cell connections have more importance than others, in that case the scale of the graph from \\(0\\) to a maximum distance (in this case \\(1\\)). Usually, the smaller the distance, the closer two points are, and stronger is their connection. This is called a weighted graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (&gt; 100k cells).\n\npheatmap(alldata@graphs$CCA_nn[1:200, 1:200],\n    col = c(\"white\", \"black\"), border_color = \"grey90\", main = \"KNN graph\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\npheatmap(alldata@graphs$CCA_snn[1:200, 1:200],\n    col = colorRampPalette(c(\"white\", \"yellow\", \"red\"))(100),\n    border_color = \"grey90\", main = \"SNN graph\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n\n\n\n1.2 Clustering on a graph\nOnce the graph is built, we can now perform graph clustering. The clustering is done respective to a resolution which can be interpreted as how coarse you want your cluster to be. Higher resolution means higher number of clusters.\nIn Seurat, the function FindClusters() will do a graph-based clustering using “Louvain” algorithim by default (algorithm = 1). To use the leiden algorithm, you need to set it to algorithm = 4. See ?FindClusters for additional options.\nBy default it will run clustering on the SNN graph we created in the previous step, but you can also specify different graphs for clustering with graph.name.\n\n# Clustering with louvain (algorithm 1) and a few different resolutions\nfor (res in c(0.1, 0.25, .5, 1, 1.5, 2)) {\n    alldata &lt;- FindClusters(alldata, graph.name = \"CCA_snn\", resolution = res, algorithm = 1)\n}\n\n# each time you run clustering, the data is stored in meta data columns:\n# seurat_clusters - lastest results only\n# CCA_snn_res.XX - for each different resolution you test.\n\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap\", group.by = \"CCA_snn_res.0.5\") + ggtitle(\"louvain_0.5\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"CCA_snn_res.1\") + ggtitle(\"louvain_1\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"CCA_snn_res.2\") + ggtitle(\"louvain_2\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nWe can now use the clustree package to visualize how cells are distributed between clusters depending on resolution.\n\nsuppressPackageStartupMessages(library(clustree))\nclustree(alldata@meta.data, prefix = \"CCA_snn_res.\")"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_kmean",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\nfor (k in c(5, 7, 10, 12, 15, 17, 20)) {\n    alldata@meta.data[, paste0(\"kmeans_\", k)] &lt;- kmeans(x = alldata@reductions[[\"pca\"]]@cell.embeddings, centers = k, nstart = 100)$cluster\n}\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap\", group.by = \"kmeans_5\") + ggtitle(\"kmeans_5\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"kmeans_10\") + ggtitle(\"kmeans_10\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"kmeans_15\") + ggtitle(\"kmeans_15\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\nclustree(alldata@meta.data, prefix = \"kmeans_\")"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_hier",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\n\n3.1 Defining distance between cells\nThe base R stats package already contains a function dist that calculates distances between all pairs of samples. Since we want to compute distances between samples, rather than among genes, we need to transpose the data before applying it to the dist function. This can be done by simply adding the transpose function t() to the data. The distance methods available in dist are: ‘euclidean’, ‘maximum’, ‘manhattan’, ‘canberra’, ‘binary’ or ‘minkowski’.\n\nd &lt;- dist(alldata@reductions[[\"pca\"]]@cell.embeddings, method = \"euclidean\")\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n[adj = ]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\n\n# Compute sample correlations\nsample_cor &lt;- cor(Matrix::t(alldata@reductions[[\"pca\"]]@cell.embeddings))\n\n# Transform the scale from correlations\nsample_cor &lt;- (1 - sample_cor) / 2\n\n# Convert it to a distance object\nd2 &lt;- as.dist(sample_cor)\n\n\n\n3.2 Clustering cells\nAfter having calculated the distances between samples calculated, we can now proceed with the hierarchical clustering per-se. We will use the function hclust for this purpose, in which we can simply run it with the distance objects created above. The methods available are: ‘ward.D’, ‘ward.D2’, ‘single’, ‘complete’, ‘average’, ‘mcquitty’, ‘median’ or ‘centroid’. It is possible to plot the dendrogram for all cells, but this is very time consuming and we will omit for this tutorial.\n\n# euclidean\nh_euclidean &lt;- hclust(d, method = \"ward.D2\")\n\n# correlation\nh_correlation &lt;- hclust(d2, method = \"ward.D2\")\n\nOnce your dendrogram is created, the next step is to define which samples belong to a particular cluster. After identifying the dendrogram, we can now literally cut the tree at a fixed threshold (with cutree) at different levels to define the clusters. We can either define the number of clusters or decide on a height. We can simply try different clustering levels.\n\n# euclidean distance\nalldata$hc_euclidean_5 &lt;- cutree(h_euclidean, k = 5)\nalldata$hc_euclidean_10 &lt;- cutree(h_euclidean, k = 10)\nalldata$hc_euclidean_15 &lt;- cutree(h_euclidean, k = 15)\n\n# correlation distance\nalldata$hc_corelation_5 &lt;- cutree(h_correlation, k = 5)\nalldata$hc_corelation_10 &lt;- cutree(h_correlation, k = 10)\nalldata$hc_corelation_15 &lt;- cutree(h_correlation, k = 15)\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_euclidean_5\") + ggtitle(\"hc_euc_5\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_euclidean_10\") + ggtitle(\"hc_euc_10\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_euclidean_15\") + ggtitle(\"hc_euc_15\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_corelation_5\") + ggtitle(\"hc_cor_5\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_corelation_10\") + ggtitle(\"hc_cor_10\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"hc_corelation_15\") + ggtitle(\"hc_cor_15\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nsaveRDS(alldata, \"data/covid/results/seurat_covid_qc_dr_int_cl.rds\")\n\n\n\n3.3 Distribution of clusters\nNow, we can select one of our clustering methods and compare the proportion of samples across the clusters.\nSelect the “CCA_snn_res.0.5” and plot proportion of samples per cluster and also proportion covid vs ctrl.\n\np1 &lt;- ggplot(alldata@meta.data, aes(x = CCA_snn_res.0.5, fill = orig.ident)) +\n    geom_bar(position = \"fill\")\np2 &lt;- ggplot(alldata@meta.data, aes(x = CCA_snn_res.0.5, fill = type)) +\n    geom_bar(position = \"fill\")\n\np1 + p2\n\n\n\n\n\n\n\n\nIn this case we have quite good representation of each sample in each cluster. But there are clearly some biases with more cells from one sample in some clusters and also more covid cells in some of the clusters.\nWe can also plot it in the other direction, the proportion of each cluster per sample.\n\nggplot(alldata@meta.data, aes(x = orig.ident, fill = CCA_snn_res.0.5)) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated due to quality metrics. Could it be explained biologically, or could you have technical bias there?"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-session",
    "href": "labs/seurat/seurat_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "4 Session info",
    "text": "4 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] clustree_0.5.0     ggraph_2.1.0       pheatmap_1.0.12    ggplot2_3.4.2     \n[5] patchwork_1.1.2    SeuratObject_4.1.3 Seurat_4.3.0      \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3     rstudioapi_0.14        jsonlite_1.8.5        \n  [4] magrittr_2.0.3         spatstat.utils_3.0-3   farver_2.1.1          \n  [7] rmarkdown_2.22         vctrs_0.6.2            ROCR_1.0-11           \n [10] spatstat.explore_3.2-1 htmltools_0.5.5        sctransform_0.3.5     \n [13] parallelly_1.36.0      KernSmooth_2.23-20     htmlwidgets_1.6.2     \n [16] ica_1.0-3              plyr_1.8.8             plotly_4.10.2         \n [19] zoo_1.8-12             igraph_1.4.3           mime_0.12             \n [22] lifecycle_1.0.3        pkgconfig_2.0.3        Matrix_1.5-4          \n [25] R6_2.5.1               fastmap_1.1.1          fitdistrplus_1.1-11   \n [28] future_1.32.0          shiny_1.7.4            digest_0.6.31         \n [31] colorspace_2.1-0       tensor_1.5             irlba_2.3.5.1         \n [34] labeling_0.4.2         progressr_0.13.0       fansi_1.0.4           \n [37] spatstat.sparse_3.0-1  httr_1.4.6             polyclip_1.10-4       \n [40] abind_1.4-5            compiler_4.3.0         withr_2.5.0           \n [43] backports_1.4.1        viridis_0.6.3          ggforce_0.4.1         \n [46] MASS_7.3-58.4          tools_4.3.0            lmtest_0.9-40         \n [49] httpuv_1.6.11          future.apply_1.11.0    goftest_1.2-3         \n [52] glue_1.6.2             nlme_3.1-162           promises_1.2.0.1      \n [55] grid_4.3.0             checkmate_2.2.0        Rtsne_0.16            \n [58] cluster_2.1.4          reshape2_1.4.4         generics_0.1.3        \n [61] gtable_0.3.3           spatstat.data_3.0-1    tidyr_1.3.0           \n [64] data.table_1.14.8      tidygraph_1.2.3        sp_1.6-1              \n [67] utf8_1.2.3             spatstat.geom_3.2-1    RcppAnnoy_0.0.20      \n [70] ggrepel_0.9.3          RANN_2.6.1             pillar_1.9.0          \n [73] stringr_1.5.0          later_1.3.1            splines_4.3.0         \n [76] dplyr_1.1.2            tweenr_2.0.2           lattice_0.21-8        \n [79] survival_3.5-5         deldir_1.0-9           tidyselect_1.2.0      \n [82] miniUI_0.1.1.1         pbapply_1.7-0          knitr_1.43            \n [85] gridExtra_2.3          scattermore_1.2        xfun_0.39             \n [88] graphlayouts_1.0.0     matrixStats_1.0.0      stringi_1.7.12        \n [91] lazyeval_0.2.2         yaml_2.3.7             evaluate_0.21         \n [94] codetools_0.2-19       tibble_3.2.1           cli_3.6.1             \n [97] uwot_0.1.14            xtable_1.8-4           reticulate_1.30       \n[100] munsell_0.5.0          Rcpp_1.0.10            globals_0.16.2        \n[103] spatstat.random_3.1-5  png_0.1-8              parallel_4.3.0        \n[106] ellipsis_0.3.2         listenv_0.9.0          viridisLite_0.4.2     \n[109] scales_1.2.1           ggridges_0.5.4         leiden_0.4.3          \n[112] purrr_1.0.1            rlang_1.1.1            cowplot_1.1.1"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html",
    "href": "labs/seurat/seurat_05_dge.html",
    "title": " Differential gene expression",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will cover about Differetial gene expression, which comprises an extensive range of topics and methods. In single cell, differential expresison can have multiple functionalities such as of identifying marker genes for cell populations, as well as differentially regulated genes across conditions (healthy vs control). We will also exercise on how to account the batch information in your test.\nWe can first load the data from the clustering session. Moreover, we can already decide which clustering resolution to use. First let’s define using the louvain clustering to identifying differentially expressed genes.\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(dplyr)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(enrichR)\n    library(Matrix)\n    library(edgeR)\n    library(MAST)\n})\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr_int_cl.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/seurat_covid_qc_dr_int_cl.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)\n# Set the identity as louvain with resolution 0.5\nsel.clust &lt;- \"CCA_snn_res.0.5\"\n\nalldata &lt;- SetIdent(alldata, value = sel.clust)\ntable(alldata@active.ident)\n\n\n   0    1    2    3    4    5    6    7    8 \n2056 1259 1113  646  535  494  365  337  329\n# plot this clustering\nwrap_plots(\n    DimPlot(alldata, label = T) + NoAxes(),\n    DimPlot(alldata, group.by = \"orig.ident\") + NoAxes(),\n    DimPlot(alldata, group.by = \"type\") + NoAxes(),\n    ncol = 3\n)"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#meta-dge_cmg",
    "href": "labs/seurat/seurat_05_dge.html#meta-dge_cmg",
    "title": " Differential gene expression",
    "section": "1 Cell marker genes",
    "text": "1 Cell marker genes\nLet us first compute a ranking for the highly differential genes in each cluster. There are many different tests and parameters to be chosen that can be used to refine your results. When looking for marker genes, we want genes that are positivelly expressed in a cell type and possibly not expressed in the others.\n\n# Compute differentiall expression\nmarkers_genes &lt;- FindAllMarkers(\n    alldata,\n    log2FC.threshold = 0.2,\n    test.use = \"wilcox\",\n    min.pct = 0.1,\n    min.diff.pct = 0.2,\n    only.pos = TRUE,\n    max.cells.per.ident = 50,\n    assay = \"RNA\"\n)\n\nWe can now select the top 25 up regulated genes for plotting.\n\nmarkers_genes %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-25, p_val_adj) -&gt; top25\nhead(top25)\n\n\n\n  \n\n\n\n\npar(mfrow = c(2, 5), mar = c(4, 6, 3, 1))\nfor (i in unique(top25$cluster)) {\n    barplot(sort(setNames(top25$avg_log2FC, top25$gene)[top25$cluster == i], F),\n        horiz = T, las = 1, main = paste0(i, \" vs. rest\"), border = \"white\", yaxs = \"i\"\n    )\n    abline(v = c(0, 0.25), lty = c(1, 2))\n}\n\n\n\n\n\n\n\n\nWe can visualize them as a heatmap. Here we are selecting the top 5.\n\nmarkers_genes %&gt;%\n    group_by(cluster) %&gt;%\n    slice_min(p_val_adj, n = 5, with_ties = FALSE) -&gt; top5\n# create a scale.data slot for the selected genes\nalldata &lt;- ScaleData(alldata, features = as.character(unique(top5$gene)), assay = \"RNA\")\nDoHeatmap(alldata, features = as.character(unique(top5$gene)), group.by = sel.clust, assay = \"RNA\")\n\n\n\n\n\n\n\n\nAnother way is by representing the overal group expression and detection rates in a dot-plot.\n\nDotPlot(alldata, features = rev(as.character(unique(top5$gene))), group.by = sel.clust, assay = \"RNA\") + coord_flip()\n\n\n\n\n\n\n\n\nWe can also plot a violin plot for each gene.\n\n# take top 3 genes per cluster/\ntop5 %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-3, p_val) -&gt; top3\n\n# set pt.size to zero if you do not want all the points to hide the violin shapes, or to a small value like 0.1\nVlnPlot(alldata, features = as.character(unique(top3$gene)), ncol = 5, group.by = sel.clust, assay = \"RNA\", pt.size = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nTake a screen shot of those results and re-run the same code above with another test: “wilcox” (Wilcoxon Rank Sum test), “bimod” (Likelihood-ratio test), “roc” (Identifies ‘markers’ of gene expression using ROC analysis),“t” (Student’s t-test),“negbinom” (negative binomial generalized linear model),“poisson” (poisson generalized linear model), “LR” (logistic regression), “MAST” (hurdle model), “DESeq2” (negative binomial distribution)."
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#meta-dge_cond",
    "href": "labs/seurat/seurat_05_dge.html#meta-dge_cond",
    "title": " Differential gene expression",
    "section": "2 DGE across conditions",
    "text": "2 DGE across conditions\nThe second way of computing differential expression is to answer which genes are differentially expressed within a cluster. For example, in our case we have libraries comming from patients and controls and we would like to know which genes are influenced the most in a particular cell type. For this end, we will first subset our data for the desired cell cluster, then change the cell identities to the variable of comparison (which now in our case is the “type”, e.g. Covid/Ctrl).\n\n# select all cells in cluster 1\ncell_selection &lt;- subset(alldata, cells = colnames(alldata)[alldata@meta.data[, sel.clust] == 3])\ncell_selection &lt;- SetIdent(cell_selection, value = \"type\")\n# Compute differentiall expression\nDGE_cell_selection &lt;- FindAllMarkers(cell_selection,\n    log2FC.threshold = 0.2,\n    test.use = \"wilcox\",\n    min.pct = 0.1,\n    min.diff.pct = 0.2,\n    only.pos = TRUE,\n    max.cells.per.ident = 50,\n    assay = \"RNA\"\n)\n\nWe can now plot the expression across the type.\n\nDGE_cell_selection %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-5, p_val) -&gt; top5_cell_selection\nVlnPlot(cell_selection, features = as.character(unique(top5_cell_selection$gene)), ncol = 5, group.by = \"type\", assay = \"RNA\", pt.size = .1)\n\n\n\n\n\n\n\n\nWe can also plot these genes across all clusters, but split by “type”, to check if the genes are also up/downregulated in other celltypes.\n\nVlnPlot(alldata,\n    features = as.character(unique(top5_cell_selection$gene)),\n    ncol = 4, split.by = \"type\", assay = \"RNA\", pt.size = 0\n)\n\n\n\n\n\n\n\n\nAs you can see, we hwve many sex chromosome related genes among the top DE genes. And if you remember from the QC lab, we have inbalanced sex distribution among our subjects, so this may not be related to covid at all.\n\n2.1 Remove sex chromosome genes\nTo remove some of the bias due to inbalanced sex in the subjects we can remove the sex chromosome related genes.\n\ngenes_file &lt;- file.path(\"data/covid/results/genes_table.csv\")\nif (!file.exists(genes_file)) download.file(file.path(path_data, \"covid/results/genes_table.csv\"), destfile = genes_file)\n\n\ngene.info &lt;- read.csv(genes_file) # was created in the QC exercise\n\nauto.genes &lt;- gene.info$external_gene_name[!(gene.info$chromosome_name %in% c(\"X\", \"Y\"))]\n\ncell_selection@active.assay &lt;- \"RNA\"\nkeep.genes &lt;- intersect(rownames(cell_selection), auto.genes)\ncell_selection &lt;- cell_selection[keep.genes, ]\n\n# then renormalize the data\ncell_selection &lt;- NormalizeData(cell_selection)\n\nRerun differential expression:\n\n# Compute differential expression\nDGE_cell_selection &lt;- FindMarkers(cell_selection,\n    ident.1 = \"Covid\", ident.2 = \"Ctrl\",\n    logfc.threshold = 0.2, test.use = \"wilcox\", min.pct = 0.1,\n    min.diff.pct = 0.2, assay = \"RNA\"\n)\n\n# Define as Covid or Ctrl in the df and add a gene column\nDGE_cell_selection$direction &lt;- ifelse(DGE_cell_selection$avg_log2FC &gt; 0, \"Covid\", \"Ctrl\")\nDGE_cell_selection$gene &lt;- rownames(DGE_cell_selection)\n\n\nDGE_cell_selection %&gt;%\n    group_by(direction) %&gt;%\n    top_n(-5, p_val) %&gt;%\n    arrange(direction) -&gt; top5_cell_selection\n\n\nVlnPlot(cell_selection,\n    features = as.character(unique(top5_cell_selection$gene)),\n    ncol = 5, group.by = \"type\", assay = \"RNA\", pt.size = .1\n)\n\n\n\n\n\n\n\n\nWe can also plot these genes across all clusters, but split by “type”, to check if the genes are also up/downregulated in other celltypes/clusters.\n\nVlnPlot(alldata,\n    features = as.character(unique(top5_cell_selection$gene)),\n    ncol = 4, split.by = \"type\", assay = \"RNA\", pt.size = 0\n)"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#patient-batch-effects",
    "href": "labs/seurat/seurat_05_dge.html#patient-batch-effects",
    "title": " Differential gene expression",
    "section": "3 Patient Batch effects",
    "text": "3 Patient Batch effects\nWhen we are testing for Covid vs Control we are running a DGE test for 4 vs 4 individuals. That will be very sensitive to sample differences unless we find a way to control for it. So first, lets check how the top DGEs are expressed across the individuals within cluster 3:\n\nVlnPlot(cell_selection, group.by = \"orig.ident\", features = as.character(unique(top5_cell_selection$gene)), ncol = 4, assay = \"RNA\", pt.size = 0)\n\n\n\n\n\n\n\n\nAs you can see, many of the genes detected as DGE in Covid are unique to one or 2 patients.\nWe can examine more genes with a DotPlot:\n\nDGE_cell_selection %&gt;%\n    group_by(direction) %&gt;%\n    top_n(-20, p_val) -&gt; top20_cell_selection\nDotPlot(cell_selection, features = rev(as.character(unique(top20_cell_selection$gene))), group.by = \"orig.ident\", assay = \"RNA\") + coord_flip() + RotatedAxis()\n\n\n\n\n\n\n\n\nAs you can see, most of the DGEs are driven by the covid_17 patient. It is also a sample with very high number of cells:\n\ntable(cell_selection$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n      95       32       37      173       64       62       37      146"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#subsample",
    "href": "labs/seurat/seurat_05_dge.html#subsample",
    "title": " Differential gene expression",
    "section": "4 Subsample",
    "text": "4 Subsample\nSo one obvious thing to consider is an equal amount of cells per individual so that the DGE results are not dominated by a single sample.\nSo we will use the downsample option in the Seurat function WhichCells to select 30 cells per cluster:\n\ncell_selection &lt;- SetIdent(cell_selection, value = \"orig.ident\")\nsub_data &lt;- subset(cell_selection, cells = WhichCells(cell_selection, downsample = 30))\n\ntable(sub_data$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n      30       30       30       30       30       30       30       30 \n\n\nAnd now we run DGE analysis again:\n\nsub_data &lt;- SetIdent(sub_data, value = \"type\")\n\n# Compute differentiall expression\nDGE_sub &lt;- FindMarkers(sub_data,\n    ident.1 = \"Covid\", ident.2 = \"Ctrl\",\n    logfc.threshold = 0.2, test.use = \"wilcox\", min.pct = 0.1,\n    min.diff.pct = 0.2, assay = \"RNA\"\n)\n\n# Define as Covid or Ctrl in the df and add a gene column\nDGE_sub$direction &lt;- ifelse(DGE_sub$avg_log2FC &gt; 0, \"Covid\", \"Ctrl\")\nDGE_sub$gene &lt;- rownames(DGE_sub)\n\n\nDGE_sub %&gt;%\n    group_by(direction) %&gt;%\n    top_n(-5, p_val) %&gt;%\n    arrange(direction) -&gt; top5_sub\n\nVlnPlot(sub_data,\n    features = as.character(unique(top5_sub$gene)),\n    ncol = 5, group.by = \"type\", assay = \"RNA\", pt.size = .1\n)\n\n\n\n\n\n\n\n\nPlot as dotplot, but in the full (not subsampled) data, still only showing cluster 3:\n\nDGE_sub %&gt;%\n    group_by(direction) %&gt;%\n    top_n(-20, p_val) -&gt; top20_sub\nDotPlot(cell_selection, features = rev(as.character(unique(top20_sub$gene))), group.by = \"orig.ident\", assay = \"RNA\") +\n    coord_flip() + RotatedAxis()\n\n\n\n\n\n\n\n\nIt looks much better now. But if we look per patient you can see that we still have some genes that are dominated by a single patient.\nWhy do you think this is?"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#pseudobulk",
    "href": "labs/seurat/seurat_05_dge.html#pseudobulk",
    "title": " Differential gene expression",
    "section": "5 Pseudobulk",
    "text": "5 Pseudobulk\nOne option is to treat the samples as pseudobulks and do differential expression for the 4 patients vs 4 controls. You do lose some information about cell variability within each patient, but instead you gain the advantage of mainly looking for effects that are seen in multiple patients.\nHowever, having only 4 patients is perhaps too low, with many more patients it will work better to run pseudobulk analysis.\nFor a fair comparison we should have equal number of cells per sample when we create the pseudobulk, so we will use the subsampled object.\n\n# get the count matrix for all cells\nDGE_DATA &lt;- sub_data@assays$RNA@counts\n\n# Compute pseudobulk\nmm &lt;- Matrix::sparse.model.matrix(~ 0 + sub_data$orig.ident)\npseudobulk &lt;- DGE_DATA %*% mm\n\nThen run edgeR:\n\n# define the groups\nbulk.labels &lt;- c(\"Covid\", \"Covid\", \"Covid\", \"Covid\", \"Ctrl\", \"Ctrl\", \"Ctrl\", \"Ctrl\")\n\ndge.list &lt;- DGEList(counts = pseudobulk, group = factor(bulk.labels))\nkeep &lt;- filterByExpr(dge.list)\ndge.list &lt;- dge.list[keep, , keep.lib.sizes = FALSE]\n\ndge.list &lt;- calcNormFactors(dge.list)\ndesign &lt;- model.matrix(~bulk.labels)\n\ndge.list &lt;- estimateDisp(dge.list, design)\n\nfit &lt;- glmQLFit(dge.list, design)\nqlf &lt;- glmQLFTest(fit, coef = 2)\ntopTags(qlf)\n\nCoefficient:  bulk.labelsCtrl \n            logFC   logCPM        F       PValue        FDR\nS100A8  -2.672605 6.972711 37.41996 6.779653e-06 0.01083389\nS100A9  -2.512717 7.374885 27.28588 5.193871e-05 0.04149903\nSTAG3   -3.378653 7.540873 24.35275 8.987020e-05 0.04787086\nPIM3    -1.412489 7.839512 17.02383 6.030641e-04 0.23537510\nIGHA1   -2.676072 6.965149 16.09405 7.364678e-04 0.23537510\nDYNC1H1  1.279395 6.711434 12.94684 1.976508e-03 0.52641010\nPHACTR1 -1.207474 7.908323 11.47741 3.176723e-03 0.67568316\nCCR7    -1.301642 8.017766 11.28727 3.382644e-03 0.67568316\nWDFY2    1.172984 7.133247 10.76672 4.049332e-03 0.69392707\nMOB3A   -1.128665 7.131236 10.56187 4.342472e-03 0.69392707\n\n\nAs you can see, we have very few significant genes. Since we only have 4 vs 4 samples, we should not expect too many genes with this method.\nAgain as dotplot including top 10 genes:\n\nres.edgeR &lt;- topTags(qlf, 100)$table\nres.edgeR$dir &lt;- ifelse(res.edgeR$logFC &gt; 0, \"Covid\", \"Ctrl\")\nres.edgeR$gene &lt;- rownames(res.edgeR)\n\nres.edgeR %&gt;%\n    group_by(dir) %&gt;%\n    top_n(-10, PValue) %&gt;%\n    arrange(dir) -&gt; top.edgeR\n\nDotPlot(cell_selection,\n    features = as.character(unique(top.edgeR$gene)), group.by = \"orig.ident\",\n    assay = \"RNA\"\n) + coord_flip() + ggtitle(\"EdgeR pseudobulk\") + RotatedAxis()\n\n\n\n\n\n\n\n\nAs you can see, even if we get few genes detected the seem to make sense across all the patients."
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#mast-random-effect",
    "href": "labs/seurat/seurat_05_dge.html#mast-random-effect",
    "title": " Differential gene expression",
    "section": "6 MAST random effect",
    "text": "6 MAST random effect\nMAST has the option to add a random effect for the patient when running DGE analysis. It is quite slow, even with this small dataset, so it may not be practical for a larger dataset unless you have access to a compute cluster.\nWe will run MAST with and without patient info as random effect and compare the results\nFirst, filter genes in part to speed up the process but also to avoid too many warnings in the model fitting step of MAST. We will keep genes that are expressed with at least 2 reads in 2 covid patients or 2 controls.\n\n# select genes that are expressed in at least 2 patients or 2 ctrls with &gt; 2 reads.\nnPatient &lt;- sapply(unique(cell_selection$orig.ident), function(x) {\n    rowSums(cell_selection@assays$RNA@counts[, cell_selection$orig.ident\n    == x] &gt; 2)\n})\nnCovid &lt;- rowSums(nPatient[, 1:3] &gt; 2)\nnCtrl &lt;- rowSums(nPatient[, 4:6] &gt; 2)\n\nsel &lt;- nCovid &gt;= 2 | nCtrl &gt;= 2\ncell_selection_sub &lt;- cell_selection[sel, ]\n\nSet up the MAST object.\n\n# create the feature data\nfData &lt;- data.frame(primerid = rownames(cell_selection_sub))\nm &lt;- cell_selection_sub@meta.data\nm$wellKey &lt;- rownames(m)\n\n# make sure type and orig.ident are factors\nm$orig.ident &lt;- factor(m$orig.ident)\nm$type &lt;- factor(m$type)\n\nsca &lt;- MAST::FromMatrix(\n    exprsArray = as.matrix(x = cell_selection_sub@assays$RNA@data),\n    check_sanity = FALSE, cData = m, fData = fData\n)\n\nFirst, run the regular MAST analysis without random effects\n\n# takes a while to run, so save a file to tmpdir in case you have to rerun the code\ntmpdir &lt;- \"data/covid/results/tmp_dge\"\ndir.create(tmpdir, showWarnings = F)\n\ntmpfile1 &lt;- file.path(tmpdir, \"mast_bayesglm_cl3.Rds\")\nif (file.exists(tmpfile1)) {\n    fcHurdle1 &lt;- readRDS(tmpfile1)\n} else {\n    zlmCond &lt;- suppressMessages(MAST::zlm(~ type + nFeature_RNA, sca, method = \"bayesglm\", ebayes = T))\n    summaryCond &lt;- suppressMessages(MAST::summary(zlmCond, doLRT = \"typeCtrl\"))\n    summaryDt &lt;- summaryCond$datatable\n    fcHurdle &lt;- merge(summaryDt[summaryDt$contrast == \"typeCtrl\" & summaryDt$component ==\n        \"logFC\", c(1, 7, 5, 6, 8)], summaryDt[summaryDt$contrast == \"typeCtrl\" &\n        summaryDt$component == \"H\", c(1, 4)], by = \"primerid\")\n    fcHurdle1 &lt;- stats::na.omit(as.data.frame(fcHurdle))\n    saveRDS(fcHurdle1, tmpfile1)\n}\n\nThen run MAST with glmer and random effect.\n\nlibrary(lme4)\n\ntmpfile2 &lt;- file.path(tmpdir, \"mast_glme_cl3.Rds\")\nif (file.exists(tmpfile2)) {\n    fcHurdle2 &lt;- readRDS(tmpfile2)\n} else {\n    zlmCond &lt;- suppressMessages(MAST::zlm(~ type + nFeature_RNA + (1 | orig.ident), sca,\n        method = \"glmer\",\n        ebayes = F, strictConvergence = FALSE\n    ))\n\n    summaryCond &lt;- suppressMessages(MAST::summary(zlmCond, doLRT = \"typeCtrl\"))\n    summaryDt &lt;- summaryCond$datatable\n    fcHurdle &lt;- merge(summaryDt[summaryDt$contrast == \"typeCtrl\" & summaryDt$component ==\n        \"logFC\", c(1, 7, 5, 6, 8)], summaryDt[summaryDt$contrast == \"typeCtrl\" &\n        summaryDt$component == \"H\", c(1, 4)], by = \"primerid\")\n    fcHurdle2 &lt;- stats::na.omit(as.data.frame(fcHurdle))\n    saveRDS(fcHurdle2, tmpfile2)\n}\n\nTop genes with normal MAST:\n\ntop1 &lt;- head(fcHurdle1[order(fcHurdle1$`Pr(&gt;Chisq)`), ], 10)\ntop1\n\n\n\n  \n\n\nfcHurdle1$pval &lt;- fcHurdle1$`Pr(&gt;Chisq)`\nfcHurdle1$dir &lt;- ifelse(fcHurdle1$z &gt; 0, \"up\", \"down\")\nfcHurdle1 %&gt;%\n    group_by(dir) %&gt;%\n    top_n(-10, pval) %&gt;%\n    arrange(z) -&gt; mastN\n\nmastN &lt;- mastN$primerid\n\nTop genes with random effect:\n\ntop2 &lt;- head(fcHurdle2[order(fcHurdle2$`Pr(&gt;Chisq)`), ], 10)\ntop2\n\n\n\n  \n\n\nfcHurdle2$pval &lt;- fcHurdle2$`Pr(&gt;Chisq)`\nfcHurdle2$dir &lt;- ifelse(fcHurdle2$z &gt; 0, \"up\", \"down\")\nfcHurdle2 %&gt;%\n    group_by(dir) %&gt;%\n    top_n(-10, pval) %&gt;%\n    arrange(z) -&gt; mastR\n\nmastR &lt;- mastR$primerid\n\nAs you can see, we have lower significance for the genes with the random effect added.\nDotplot for top10 genes in each direction:\n\np1 &lt;- DotPlot(cell_selection, features = mastN, group.by = \"orig.ident\", assay = \"RNA\") +\n    coord_flip() + RotatedAxis() + ggtitle(\"Regular MAST\")\n\np2 &lt;- DotPlot(cell_selection, features = mastR, group.by = \"orig.ident\", assay = \"RNA\") +\n    coord_flip() + RotatedAxis() + ggtitle(\"With random effect\")\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nYou have now run DGE analysis for Covid vs Ctrl in cluster 3 with several diffent methods. Have a look at the different results, where did you get more/less significant genes? Which results would you like to present in a paper? Discuss with a neighbor which one you think looks best and why."
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#meta-dge_gsa",
    "href": "labs/seurat/seurat_05_dge.html#meta-dge_gsa",
    "title": " Differential gene expression",
    "section": "7 Gene Set Analysis (GSA)",
    "text": "7 Gene Set Analysis (GSA)\n\n7.1 Hypergeometric enrichment test\nHaving a defined list of differentially expressed genes, you can now look for their combined function using hypergeometric test.\nIn this case we will use the DGE from MAST with random effect to run enrichment analysis.\n\n# Load additional packages\nlibrary(enrichR)\n\n# Check available databases to perform enrichment (then choose one)\nenrichR::listEnrichrDbs()\n\n\n\n  \n\n\n# Perform enrichment\nenrich_results &lt;- enrichr(\n    genes     = fcHurdle2$primerid[fcHurdle2$z &lt; 0 & fcHurdle2$pval &lt; 0.05],\n    databases = \"GO_Biological_Process_2017b\"\n)[[1]]\n\nUploading data to Enrichr... Done.\n  Querying GO_Biological_Process_2017b... Done.\nParsing results... Done.\n\n\nSome databases of interest:\nGO_Biological_Process_2017bKEGG_2019_HumanKEGG_2019_MouseWikiPathways_2019_HumanWikiPathways_2019_Mouse\nYou visualize your results using a simple barplot, for example:\n\npar(mfrow = c(1, 1), mar = c(3, 25, 2, 1))\nbarplot(\n    height = -log10(enrich_results$P.value)[10:1],\n    names.arg = enrich_results$Term[10:1],\n    horiz = TRUE,\n    las = 1,\n    border = FALSE,\n    cex.names = .6\n)\nabline(v = c(-log10(0.05)), lty = 2)\nabline(v = 0, lty = 1)"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#meta-dge_gsea",
    "href": "labs/seurat/seurat_05_dge.html#meta-dge_gsea",
    "title": " Differential gene expression",
    "section": "8 Gene Set Enrichment Analysis (GSEA)",
    "text": "8 Gene Set Enrichment Analysis (GSEA)\nBesides the enrichment using hypergeometric test, we can also perform gene set enrichment analysis (GSEA), which scores ranked genes list (usually based on fold changes) and computes permutation test to check if a particular gene set is more present in the Up-regulated genes, among the DOWN_regulated genes or not differentially regulated.\nBefore, we ran FindMarkers with the default settings for reporting only significantly up/down regulated genes, but now we need statistics on a larger set of genes, so we will have to rerun the test with more lenient cutoffs.\n\nsub_data &lt;- SetIdent(sub_data, value = \"type\")\n\nDGE_cell_selection2 &lt;- FindMarkers(\n    sub_data,\n    ident.1 = \"Covid\",\n    log2FC.threshold = -Inf,\n    test.use = \"wilcox\",\n    min.pct = 0.05,\n    min.diff.pct = 0,\n    only.pos = FALSE,\n    max.cells.per.ident = 50,\n    assay = \"RNA\"\n)\n\n# Create a gene rank based on the gene expression fold change\ngene_rank &lt;- setNames(DGE_cell_selection2$avg_log2FC, casefold(rownames(DGE_cell_selection2), upper = T))\n\nOnce our list of genes are sorted, we can proceed with the enrichment itself. We can use the package to get gene set from the Molecular Signature Database (MSigDB) and select KEGG pathways as an example.\n\nlibrary(msigdbr)\n\n# Download gene sets\nmsigdbgmt &lt;- msigdbr::msigdbr(\"Homo sapiens\")\nmsigdbgmt &lt;- as.data.frame(msigdbgmt)\n\n# List available gene sets\nunique(msigdbgmt$gs_subcat)\n\n [1] \"MIR:MIR_Legacy\"  \"TFT:TFT_Legacy\"  \"CGP\"             \"TFT:GTRD\"       \n [5] \"\"                \"VAX\"             \"CP:BIOCARTA\"     \"CGN\"            \n [9] \"GO:BP\"           \"GO:CC\"           \"IMMUNESIGDB\"     \"GO:MF\"          \n[13] \"HPO\"             \"CP:KEGG\"         \"MIR:MIRDB\"       \"CM\"             \n[17] \"CP\"              \"CP:PID\"          \"CP:REACTOME\"     \"CP:WIKIPATHWAYS\"\n\n# Subset which gene set you want to use.\nmsigdbgmt_subset &lt;- msigdbgmt[msigdbgmt$gs_subcat == \"CP:WIKIPATHWAYS\", ]\ngmt &lt;- lapply(unique(msigdbgmt_subset$gs_name), function(x) {\n    msigdbgmt_subset[msigdbgmt_subset$gs_name == x, \"gene_symbol\"]\n})\nnames(gmt) &lt;- unique(paste0(msigdbgmt_subset$gs_name, \"_\", msigdbgmt_subset$gs_exact_source))\n\nNext, we will be using the GSEA. This will result in a table containing information for several pathways. We can then sort and filter those pathways to visualize only the top ones. You can select/filter them by either p-value or normalized enrichment score (NES).\n\nlibrary(fgsea)\n\n# Perform enrichemnt analysis\nfgseaRes &lt;- fgsea(pathways = gmt, stats = gene_rank, minSize = 15, maxSize = 500)\nfgseaRes &lt;- fgseaRes[order(fgseaRes$pval, decreasing = T), ]\n\n# Filter the results table to show only the top 10 UP or DOWN regulated processes (optional)\ntop10_UP &lt;- fgseaRes$pathway[1:10]\n\n# Nice summary table (shown as a plot)\nplotGseaTable(gmt[top10_UP], gene_rank, fgseaRes, gseaParam = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWhich KEGG pathways are upregulated in this cluster?Which KEGG pathways are dowregulated in this cluster?\nChange the pathway source to another gene set (e.g. “CP:WIKIPATHWAYS” or “CP:REACTOME” or “CP:BIOCARTA” or “GO:BP”) and check the if you get similar results?"
  },
  {
    "objectID": "labs/seurat/seurat_05_dge.html#meta-session",
    "href": "labs/seurat/seurat_05_dge.html#meta-session",
    "title": " Differential gene expression",
    "section": "9 Session info",
    "text": "9 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] fgsea_1.28.0                msigdbr_7.5.1              \n [3] lme4_1.1-33                 MAST_1.28.0                \n [5] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [7] Biobase_2.62.0              GenomicRanges_1.54.1       \n [9] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[11] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[13] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n[15] edgeR_4.0.7                 limma_3.58.1               \n[17] Matrix_1.5-4                enrichR_3.2                \n[19] pheatmap_1.0.12             ggplot2_3.4.2              \n[21] patchwork_1.1.2             dplyr_1.1.2                \n[23] SeuratObject_4.1.3          Seurat_4.3.0               \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.20        splines_4.3.0           later_1.3.1            \n  [4] bitops_1.0-7            tibble_3.2.1            polyclip_1.10-4        \n  [7] lifecycle_1.0.3         globals_0.16.2          lattice_0.21-8         \n [10] MASS_7.3-58.4           magrittr_2.0.3          plotly_4.10.2          \n [13] rmarkdown_2.22          yaml_2.3.7              httpuv_1.6.11          \n [16] sctransform_0.3.5       sp_1.6-1                spatstat.sparse_3.0-1  \n [19] reticulate_1.30         cowplot_1.1.1           pbapply_1.7-0          \n [22] minqa_1.2.5             RColorBrewer_1.1-3      abind_1.4-5            \n [25] zlibbioc_1.48.0         Rtsne_0.16              purrr_1.0.1            \n [28] RCurl_1.98-1.12         WriteXLS_6.4.0          GenomeInfoDbData_1.2.11\n [31] ggrepel_0.9.3           irlba_2.3.5.1           listenv_0.9.0          \n [34] spatstat.utils_3.0-3    goftest_1.2-3           spatstat.random_3.1-5  \n [37] fitdistrplus_1.1-11     parallelly_1.36.0       leiden_0.4.3           \n [40] codetools_0.2-19        DelayedArray_0.28.0     tidyselect_1.2.0       \n [43] farver_2.1.1            spatstat.explore_3.2-1  jsonlite_1.8.5         \n [46] ellipsis_0.3.2          progressr_0.13.0        ggridges_0.5.4         \n [49] survival_3.5-5          tools_4.3.0             progress_1.2.2         \n [52] ica_1.0-3               Rcpp_1.0.10             glue_1.6.2             \n [55] gridExtra_2.3           SparseArray_1.2.3       xfun_0.39              \n [58] withr_2.5.0             fastmap_1.1.1           boot_1.3-28.1          \n [61] fansi_1.0.4             digest_0.6.31           R6_2.5.1               \n [64] mime_0.12               colorspace_2.1-0        scattermore_1.2        \n [67] tensor_1.5              spatstat.data_3.0-1     utf8_1.2.3             \n [70] tidyr_1.3.0             generics_0.1.3          data.table_1.14.8      \n [73] prettyunits_1.1.1       httr_1.4.6              htmlwidgets_1.6.2      \n [76] S4Arrays_1.2.0          uwot_0.1.14             pkgconfig_2.0.3        \n [79] gtable_0.3.3            lmtest_0.9-40           XVector_0.42.0         \n [82] htmltools_0.5.5         scales_1.2.1            png_0.1-8              \n [85] knitr_1.43              rstudioapi_0.14         reshape2_1.4.4         \n [88] rjson_0.2.21            nlme_3.1-162            curl_5.0.1             \n [91] nloptr_2.0.3            zoo_1.8-12              stringr_1.5.0          \n [94] KernSmooth_2.23-20      parallel_4.3.0          miniUI_0.1.1.1         \n [97] pillar_1.9.0            grid_4.3.0              vctrs_0.6.2            \n[100] RANN_2.6.1              promises_1.2.0.1        xtable_1.8-4           \n[103] cluster_2.1.4           evaluate_0.21           cli_3.6.1              \n[106] locfit_1.5-9.8          compiler_4.3.0          rlang_1.1.1            \n[109] crayon_1.5.2            future.apply_1.11.0     labeling_0.4.2         \n[112] plyr_1.8.8              stringi_1.7.12          BiocParallel_1.36.0    \n[115] viridisLite_0.4.2       deldir_1.0-9            babelgene_22.9         \n[118] munsell_0.5.0           lazyeval_0.2.2          spatstat.geom_3.2-1    \n[121] hms_1.1.3               future_1.32.0           statmod_1.5.0          \n[124] shiny_1.7.4             ROCR_1.0-11             igraph_1.4.3           \n[127] fastmatch_1.1-3"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html",
    "href": "labs/seurat/seurat_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each celltype.\nWe will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to even if the celltype of that cell is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nHere we will use a reference PBMC dataset from the scPred package which is provided as a Seurat object with counts. And we will test classification based on the scPred and scMap methods. Finally we will use gene set enrichment predict celltype based on the DEGs of each cluster."
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_read",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_read",
    "title": " Celltype prediction",
    "section": "1 Read data",
    "text": "1 Read data\nFirst, lets load required libraries\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(dplyr)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    # remotes::install_github(\"powellgenomicslab/scPred\")\n    library(scPred)\n})\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr_int_cl.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/seurat_covid_qc_dr_int_cl.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)\n\nSubset one patient.\n\nctrl &lt;- alldata[, alldata$orig.ident == \"ctrl_13\"]\n\n# set active assay to RNA and remove the CCA assay\nctrl@active.assay &lt;- \"RNA\"\nctrl[[\"CCA\"]] &lt;- NULL\nctrl\n\nAn object of class Seurat \n18851 features across 1126 samples within 1 assay \nActive assay: RNA (18851 features, 2000 variable features)\n 6 dimensional reductions calculated: umap, tsne, umap_raw, pca_harmony, harmony, umap_harmony"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_ref",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "2 Reference data",
    "text": "2 Reference data\nLoad the reference dataset with annotated labels.\n\nreference &lt;- scPred::pbmc_1\nreference\n\nAn object of class Seurat \n32838 features across 3500 samples within 1 assay \nActive assay: RNA (32838 features, 0 variable features)\n\n\nRerun analysis pipeline. Run normalization, feature selection and dimensionality reduction\nHere, we will run all the steps that we did in previous labs in one go using the magittr package with the pipe-operator %&gt;%.\n\nreference &lt;- reference %&gt;%\n    NormalizeData() %&gt;%\n    FindVariableFeatures() %&gt;%\n    ScaleData() %&gt;%\n    RunPCA(verbose = F) %&gt;%\n    RunUMAP(dims = 1:30)\n\n\nDimPlot(reference, group.by = \"cell_type\", label = TRUE, repel = TRUE) + NoAxes()\n\n\n\n\n\n\n\n\nRun all steps of the analysis for the ctrl sample as well. Use the clustering from the integration lab with resolution 0.5.\n\n# Set the identity as louvain with resolution 0.3\nctrl &lt;- SetIdent(ctrl, value = \"CCA_snn_res.0.5\")\n\nctrl &lt;- ctrl %&gt;%\n    NormalizeData() %&gt;%\n    FindVariableFeatures() %&gt;%\n    ScaleData() %&gt;%\n    RunPCA(verbose = F) %&gt;%\n    RunUMAP(dims = 1:30)\n\n\nDimPlot(ctrl, label = TRUE, repel = TRUE) + NoAxes()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#label-transfer",
    "href": "labs/seurat/seurat_06_celltyping.html#label-transfer",
    "title": " Celltype prediction",
    "section": "3 Label transfer",
    "text": "3 Label transfer\nFirst we will run label transfer using a similar method as in the integration exercise. But, instad of CCA the default for the ’FindTransferAnchors` function is to use “pcaproject”, e.g. the query dataset is projected onto the PCA of the reference dataset. Then, the labels of the reference data are predicted.\n\ntransfer.anchors &lt;- FindTransferAnchors(\n    reference = reference, query = ctrl,\n    dims = 1:30\n)\npredictions &lt;- TransferData(\n    anchorset = transfer.anchors, refdata = reference$cell_type,\n    dims = 1:30\n)\nctrl &lt;- AddMetaData(object = ctrl, metadata = predictions)\n\n\nDimPlot(ctrl, group.by = \"predicted.id\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\nggplot(ctrl@meta.data, aes(x = CCA_snn_res.0.5, fill = predicted.id)) +\n    geom_bar() +\n    theme_classic()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_scpred",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_scpred",
    "title": " Celltype prediction",
    "section": "4 scPred",
    "text": "4 scPred\nscPred will train a classifier based on all principal components. First, getFeatureSpace will create a scPred object stored in the @misc slot where it extracts the PCs that best separates the different celltypes. Then trainModel will do the actual training for each celltype.\n\nreference &lt;- getFeatureSpace(reference, \"cell_type\")\n\n●  Extracting feature space for each cell type...\nDONE!\n\nreference &lt;- trainModel(reference)\n\n●  Training models for each cell type...\nmaximum number of iterations reached 0.0001152056 -0.0001143117DONE!\n\n\nWe can then print how well the training worked for the different celltypes by printing the number of PCs used for each, the ROC value and Sensitivity/Specificity. Which celltypes do you think are harder to classify based on this dataset?\n\nget_scpred(reference)\n\n'scPred' object\n✔  Prediction variable = cell_type \n✔  Discriminant features per cell type\n✔  Training model(s)\nSummary\n\n|Cell type   |    n| Features|Method    |   ROC|  Sens|  Spec|\n|:-----------|----:|--------:|:---------|-----:|-----:|-----:|\n|B cell      |  280|       50|svmRadial | 1.000| 0.964| 1.000|\n|CD4 T cell  | 1620|       50|svmRadial | 0.997| 0.972| 0.975|\n|CD8 T cell  |  945|       50|svmRadial | 0.985| 0.899| 0.978|\n|cDC         |   26|       50|svmRadial | 0.995| 0.547| 1.000|\n|cMono       |  212|       50|svmRadial | 0.994| 0.958| 0.970|\n|ncMono      |   79|       50|svmRadial | 0.998| 0.570| 1.000|\n|NK cell     |  312|       50|svmRadial | 0.999| 0.933| 0.996|\n|pDC         |   20|       50|svmRadial | 1.000| 0.700| 1.000|\n|Plasma cell |    6|       50|svmRadial | 1.000| 0.800| 1.000|\n\n\nYou can optimize parameters for each dataset by chaning parameters and testing different types of models, see more at: https://powellgenomicslab.github.io/scPred/articles/introduction.html. But for now, we will continue with this model. Now, lets predict celltypes on our data, where scPred will align the two datasets with Harmony and then perform classification.\n\nctrl &lt;- scPredict(ctrl, reference)\n\n●  Matching reference with new dataset...\n     ─ 2000 features present in reference loadings\n     ─ 1782 features shared between reference and new dataset\n     ─ 89.1% of features in the reference are present in new dataset\n●  Aligning new data to reference...\n●  Classifying cells...\nDONE!\n\n\n\nDimPlot(ctrl, group.by = \"scpred_prediction\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\nggplot(ctrl@meta.data, aes(x = CCA_snn_res.0.5, fill = scpred_prediction)) +\n    geom_bar() +\n    theme_classic()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_compare",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_compare",
    "title": " Celltype prediction",
    "section": "5 Compare results",
    "text": "5 Compare results\nNow we will compare the output of the two methods using the convenient function in scPred crossTab that prints the overlap between two metadata slots.\n\ncrossTab(ctrl, \"predicted.id\", \"scpred_prediction\")"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_gsea",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_gsea",
    "title": " Celltype prediction",
    "section": "6 GSEA with celltype markers",
    "text": "6 GSEA with celltype markers\nAnother option, where celltype can be classified on cluster level is to use gene set enrichment among the DEGs with known markers for different celltypes. Similar to how we did functional enrichment for the DEGs in the Differential expression exercise. There are some resources for celltype gene sets that can be used. Such as CellMarker, PanglaoDB or celltype gene sets at MSigDB. We can also look at overlap between DEGs in a reference dataset and the dataset you are analysing.\n\n6.1 DEG overlap\nFirst, lets extract top DEGs for our Covid-19 dataset and the reference dataset. When we run differential expression for our dataset, we want to report as many genes as possible, hence we set the cutoffs quite lenient.\n\n# run differential expression in our dataset, using clustering at resolution 0.5\nalldata &lt;- SetIdent(alldata, value = \"CCA_snn_res.0.5\")\nDGE_table &lt;- FindAllMarkers(\n    alldata,\n    logfc.threshold = 0,\n    test.use = \"wilcox\",\n    min.pct = 0.1,\n    min.diff.pct = 0,\n    only.pos = TRUE,\n    max.cells.per.ident = 20,\n    return.thresh = 1,\n    assay = \"RNA\"\n)\n\n# split into a list\nDGE_list &lt;- split(DGE_table, DGE_table$cluster)\n\nunlist(lapply(DGE_list, nrow))\n\n   0    1    2    3    4    5    6    7    8 \n3349 4118 3271 2504 2061 2581 2426 3487 2355 \n\n\n\n# Compute differential gene expression in reference dataset (that has cell annotation)\nreference &lt;- SetIdent(reference, value = \"cell_type\")\nreference_markers &lt;- FindAllMarkers(\n    reference,\n    min.pct = .1,\n    min.diff.pct = .2,\n    only.pos = T,\n    max.cells.per.ident = 20,\n    return.thresh = 1\n)\n\n# Identify the top cell marker genes in reference dataset\n# select top 50 with hihgest foldchange among top 100 signifcant genes.\nreference_markers &lt;- reference_markers[order(reference_markers$avg_log2FC, decreasing = T), ]\nreference_markers %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-100, p_val) %&gt;%\n    top_n(50, avg_log2FC) -&gt; top50_cell_selection\n\n# Transform the markers into a list\nref_list &lt;- split(top50_cell_selection$gene, top50_cell_selection$cluster)\n\nunlist(lapply(ref_list, length))\n\n CD8 T cell  CD4 T cell       cMono      B cell     NK cell         pDC \n         30          15          50          50          50          50 \n     ncMono         cDC Plasma cell \n         50          50          50 \n\n\nNow we can run GSEA for the DEGs from our dataset and check for enrichment of top DEGs in the reference dataset.\n\nsuppressPackageStartupMessages(library(fgsea))\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    gene_rank &lt;- setNames(x$avg_log2FC, x$gene)\n    fgseaRes &lt;- fgsea(pathways = ref_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.1, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 2, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\nres\n\n$`0`\n   pathway       pval        padj        ES      NES nMoreExtreme size\n1:   cMono 0.00009999 0.000299970 0.9594422 2.067666            0   48\n2:  ncMono 0.00009999 0.000299970 0.8385199 1.797428            0   43\n3:     cDC 0.00009999 0.000299970 0.8394045 1.795307            0   41\n4:     pDC 0.00180415 0.004059336 0.7492218 1.535717           17   21\n5: NK cell 0.02711970 0.048815461 0.7545862 1.436992          260   10\n6:  B cell 0.06447382 0.096710725 0.6666689 1.329777          638   15\n                                    leadingEdge\n1:      S100A8,S100A9,LYZ,S100A12,VCAN,FCN1,...\n2:     CTSS,TYMP,CST3,S100A11,AIF1,SERPINA1,...\n3:            LYZ,GRN,TYMP,CST3,AIF1,LGALS2,...\n4:         GRN,MS4A6A,CST3,MPEG1,CTSB,TGFBI,...\n5:      TYROBP,FCER1G,SRGN,CCL3,MYO1F,ITGB2,...\n6: NCF1,LY86,MARCH1,POU2F2,HLA-DMB,HLA-DRB5,...\n\n$`1`\n       pathway         pval         padj        ES      NES nMoreExtreme size\n1:     NK cell 0.0000999900 0.0004007213 0.9459800 2.369826            0   48\n2:  CD8 T cell 0.0001001803 0.0004007213 0.9230826 2.201075            0   25\n3:      ncMono 0.0008014655 0.0016029311 0.9101411 1.755775            6    6\n4:         pDC 0.0078939059 0.0126302494 0.7711439 1.640731           74   10\n5: Plasma cell 0.0007002101 0.0016029311 0.6711407 1.625909            6   30\n                                     leadingEdge\n1:          GNLY,GZMB,FGFBP2,PRF1,NKG7,SPON2,...\n2:           GNLY,GZMB,FGFBP2,PRF1,NKG7,CTSW,...\n3:                            FCGR3A,IFITM2,RHOC\n4: GZMB,C12orf75,HSP90B1,ALOX5AP,PLAC8,RRBP1,...\n5:      FKBP11,CD38,SDF2L1,PRDM1,PPIB,SLAMF7,...\n\n$`2`\n       pathway         pval         padj        ES      NES nMoreExtreme size\n1:  CD8 T cell 0.0001001101 0.0003503854 0.9406368 2.161149            0   29\n2:     NK cell 0.0001000500 0.0003503854 0.8208967 1.898566            0   32\n3:  CD4 T cell 0.0014347202 0.0033476805 0.8706473 1.681457           12    7\n4: Plasma cell 0.0744595677 0.1042433947 0.5638039 1.298014          743   30\n                               leadingEdge\n1:       CD3D,CD8A,CD3G,CCL5,CD8B,GZMH,...\n2:       CCL5,GZMA,CCL4,NKG7,GZMM,CST7,...\n3:        CD3D,CD3G,CD3E,IL7R,PIK3IP1,TCF7\n4: FKBP11,PRDM1,PEBP1,PPIB,SEC11C,SUB1,...\n\n$`3`\n       pathway         pval         padj        ES      NES nMoreExtreme size\n1:      B cell 0.0000999900 0.0002706726 0.9072478 1.989836            0   46\n2:         cDC 0.0001015022 0.0002706726 0.8950426 1.806256            0   14\n3:         pDC 0.0001008878 0.0002706726 0.8292186 1.700818            0   17\n4: Plasma cell 0.0348925962 0.0558281540 0.7900880 1.456388          319    7\n                                            leadingEdge\n1:      CD79A,LINC00926,TCL1A,MS4A1,TNFRSF13C,CD79B,...\n2: CD74,HLA-DQB1,HLA-DRA,HLA-DPB1,HLA-DRB1,HLA-DQA1,...\n3:            CD74,BCL11A,TCF4,IRF8,HERPUD1,TSPAN13,...\n4:                       PLPP5,ISG20,HERPUD1,MZB1,ITM2C\n\n$`4`\n      pathway         pval         padj        ES      NES nMoreExtreme size\n1: CD4 T cell 0.0001015744 0.0003199659 0.9121965 1.771474            0   14\n2: CD8 T cell 0.0001066553 0.0003199659 0.9014219 1.638647            0    8\n                         leadingEdge\n1: IL7R,LTB,LDHB,MAL,RCAN3,NOSIP,...\n2:      CD3D,IL32,CD3G,CD2,CD3E,CD8B\n\n$`5`\n   pathway       pval      padj        ES      NES nMoreExtreme size\n1:  B cell 0.07818977 0.2503001 0.8293407 1.392212          678    5\n2:     pDC 0.04285714 0.2503001 0.7176562 1.385862          425   18\n3:  ncMono 0.08343337 0.2503001 0.6474875 1.279034          833   28\n                              leadingEdge\n1:                   PDLIM1,HLA-DRB5,STX7\n2:   PTCRA,TXN,C12orf75,CST3,CTSB,APP,...\n3: OAZ1,TIMP1,IFITM3,FKBP1A,CD68,CST3,...\n\n$`6`\n       pathway         pval         padj        ES      NES nMoreExtreme size\n1:      B cell 0.0000999900 0.0005417852 0.8919905 1.838712            0   45\n2:         cDC 0.0002031694 0.0005417852 0.8894057 1.705469            1   14\n3:         pDC 0.0002015316 0.0005417852 0.8313241 1.622237            1   17\n4: Plasma cell 0.0232629013 0.0281224853 0.7396460 1.418299          228   14\n                                            leadingEdge\n1:        CD79A,MS4A1,BANK1,HLA-DQA1,CD74,TNFRSF13C,...\n2: HLA-DQA1,CD74,HLA-DRA,HLA-DPB1,HLA-DQB1,HLA-DPA1,...\n3:             CD74,JCHAIN,SPIB,TCF4,CCDC50,HERPUD1,...\n4:                JCHAIN,HERPUD1,ISG20,PEBP1,MZB1,ITM2C\n\n$`7`\n   pathway       pval         padj        ES      NES nMoreExtreme size\n1:  ncMono 0.00009999 0.0002666667 0.9644737 2.033813            0   49\n2:   cMono 0.00010000 0.0002666667 0.8854337 1.838288            0   36\n3:     cDC 0.00009999 0.0002666667 0.8309648 1.730082            0   38\n4: NK cell 0.01025485 0.0205096964 0.7621593 1.478759          100   14\n5:     pDC 0.02631313 0.0421010019 0.7165790 1.398343          259   15\n6:  B cell 0.05732420 0.0764322654 0.6694322 1.321810          568   17\n                                              leadingEdge\n1:                CDKN1C,LST1,FCGR3A,MS4A7,AIF1,COTL1,...\n2:               LST1,AIF1,COTL1,SERPINA1,FCER1G,CST3,...\n3:                   LST1,AIF1,COTL1,FCER1G,CST3,SPI1,...\n4:              FCGR3A,FCER1G,RHOC,TYROBP,IFITM2,CCL3,...\n5:                    CST3,NPC2,CTSB,PLD4,MPEG1,TGFBI,...\n6: HLA-DPA1,POU2F2,HLA-DRB5,HLA-DRB1,HLA-DRA,HLA-DPB1,...\n\n$`8`\n      pathway         pval         padj        ES      NES nMoreExtreme size\n1: CD4 T cell 0.0001015744 0.0006094464 0.9413572 2.012718            0   14\n2: CD8 T cell 0.0234593838 0.0703781513 0.8283043 1.494351          200    5\n                            leadingEdge\n1: IL7R,TCF7,PIK3IP1,LTB,LEF1,TSHZ2,...\n2:                   CD3G,CD3D,CD3E,CD2\n\n\nSelecing top significant overlap per cluster, we can now rename the clusters according to the predicted labels. OBS! Be aware that if you have some clusters that have non-significant p-values for all the gene sets, the cluster label will not be very reliable. Also, the gene sets you are using may not cover all the celltypes you have in your dataset and hence predictions may just be the most similar celltype. Also, some of the clusters have very similar p-values to multiple celltypes, for instance the ncMono and cMono celltypes are equally good for some clusters.\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\n\nalldata$ref_gsea &lt;- new.cluster.ids[as.character(alldata@active.ident)]\n\nwrap_plots(\n    DimPlot(alldata, label = T, group.by = \"CCA_snn_res.0.5\") + NoAxes(),\n    DimPlot(alldata, label = T, group.by = \"ref_gsea\") + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nCompare to results with the other celltype prediction methods in the ctrl_13 sample.\n\nctrl$ref_gsea &lt;- alldata$ref_gsea[alldata$orig.ident == \"ctrl_13\"]\n\nwrap_plots(\n    DimPlot(ctrl, label = T, group.by = \"ref_gsea\") + NoAxes() + ggtitle(\"GSEA\"),\n    DimPlot(ctrl, label = T, group.by = \"predicted.id\") + NoAxes() + ggtitle(\"LabelTransfer\"),\n    DimPlot(ctrl, label = T, group.by = \"scpred_prediction\") + NoAxes() + ggtitle(\"scPred\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n6.2 With annotated gene sets\nWe have dowloaded the celltype gene lists from http://bio-bigdata.hrbmu.edu.cn/CellMarker/CellMarker_download.html and converted the excel file to a csv for you. Read in the gene lists and do some filtering.\n\npath_file &lt;- file.path(\"data/cell_marker_human.csv\")\nif (!file.exists(path_file)) download.file(file.path(path_data, \"cell_marker_human.csv\"), destfile = path_file)\n\n\n# Load the human marker table\nmarkers &lt;- read.delim(\"data/cell_marker_human.csv\", sep = \";\")\nmarkers &lt;- markers[markers$species == \"Human\", ]\nmarkers &lt;- markers[markers$cancer_type == \"Normal\", ]\n\n# Filter by tissue (to reduce computational time and have tissue-specific classification)\nsort(unique(markers$tissue_type))\n\n  [1] \"Abdomen\"                        \"Abdominal adipose tissue\"      \n  [3] \"Abdominal fat pad\"              \"Acinus\"                        \n  [5] \"Adipose tissue\"                 \"Adrenal gland\"                 \n  [7] \"Adventitia\"                     \"Airway\"                        \n  [9] \"Airway epithelium\"              \"Allocortex\"                    \n [11] \"Alveolus\"                       \"Amniotic fluid\"                \n [13] \"Amniotic membrane\"              \"Ampullary\"                     \n [15] \"Anogenital tract\"               \"Antecubital vein\"              \n [17] \"Anterior cruciate ligament\"     \"Anterior presomitic mesoderm\"  \n [19] \"Aorta\"                          \"Aortic valve\"                  \n [21] \"Artery\"                         \"Arthrosis\"                     \n [23] \"Articular Cartilage\"            \"Ascites\"                       \n [25] \"Atrium\"                         \"Auditory cortex\"               \n [27] \"Basilar membrane\"               \"Beige Fat\"                     \n [29] \"Bile duct\"                      \"Biliary tract\"                 \n [31] \"Bladder\"                        \"Blood\"                         \n [33] \"Blood vessel\"                   \"Bone\"                          \n [35] \"Bone marrow\"                    \"Brain\"                         \n [37] \"Breast\"                         \"Bronchial vessel\"              \n [39] \"Bronchiole\"                     \"Bronchoalveolar lavage\"        \n [41] \"Bronchoalveolar system\"         \"Bronchus\"                      \n [43] \"Brown adipose tissue\"           \"Calvaria\"                      \n [45] \"Capillary\"                      \"Cardiac atrium\"                \n [47] \"Cardiovascular system\"          \"Carotid artery\"                \n [49] \"Carotid plaque\"                 \"Cartilage\"                     \n [51] \"Caudal cortex\"                  \"Caudal forebrain\"              \n [53] \"Caudal ganglionic eminence\"     \"Cavernosum\"                    \n [55] \"Central amygdala\"               \"Central nervous system\"        \n [57] \"Central Nervous System\"         \"Cerebellum\"                    \n [59] \"Cerebral organoid\"              \"Cerebrospinal fluid\"           \n [61] \"Choriocapillaris\"               \"Chorionic villi\"               \n [63] \"Chorionic villus\"               \"Choroid\"                       \n [65] \"Choroid plexus\"                 \"Colon\"                         \n [67] \"Colon epithelium\"               \"Colorectum\"                    \n [69] \"Cornea\"                         \"Corneal endothelium\"           \n [71] \"Corneal epithelium\"             \"Coronary artery\"               \n [73] \"Corpus callosum\"                \"Corpus luteum\"                 \n [75] \"Cortex\"                         \"Cortical layer\"                \n [77] \"Cortical thymus\"                \"Decidua\"                       \n [79] \"Deciduous tooth\"                \"Dental pulp\"                   \n [81] \"Dermis\"                         \"Diencephalon\"                  \n [83] \"Distal airway\"                  \"Dorsal forebrain\"              \n [85] \"Dorsal root ganglion\"           \"Dorsolateral prefrontal cortex\"\n [87] \"Ductal tissue\"                  \"Duodenum\"                      \n [89] \"Ectocervix\"                     \"Ectoderm\"                      \n [91] \"Embryo\"                         \"Embryoid body\"                 \n [93] \"Embryonic brain\"                \"Embryonic heart\"               \n [95] \"Embryonic Kidney\"               \"Embryonic prefrontal cortex\"   \n [97] \"Embryonic stem cell\"            \"Endocardium\"                   \n [99] \"Endocrine\"                      \"Endoderm\"                      \n[101] \"Endometrium\"                    \"Endometrium stroma\"            \n[103] \"Entorhinal cortex\"              \"Epidermis\"                     \n[105] \"Epithelium\"                     \"Esophagus\"                     \n[107] \"Eye\"                            \"Fat pad\"                       \n[109] \"Fetal brain\"                    \"Fetal gonad\"                   \n[111] \"Fetal heart\"                    \"Fetal ileums\"                  \n[113] \"Fetal kidney\"                   \"Fetal Leydig\"                  \n[115] \"Fetal liver\"                    \"Fetal lung\"                    \n[117] \"Fetal pancreas\"                 \"Fetal thymus\"                  \n[119] \"Fetal umbilical cord\"           \"Fetus\"                         \n[121] \"Foreskin\"                       \"Frontal cortex\"                \n[123] \"Fundic gland\"                   \"Gall bladder\"                  \n[125] \"Gastric corpus\"                 \"Gastric epithelium\"            \n[127] \"Gastric gland\"                  \"Gastrointestinal tract\"        \n[129] \"Germ\"                           \"Gingiva\"                       \n[131] \"Gonad\"                          \"Gut\"                           \n[133] \"Hair follicle\"                  \"Heart\"                         \n[135] \"Heart muscle\"                   \"Hippocampus\"                   \n[137] \"Ileum\"                          \"Inferior colliculus\"           \n[139] \"Interfollicular epidermis\"      \"Intervertebral disc\"           \n[141] \"Intestinal crypt\"               \"Intestine\"                     \n[143] \"Intrahepatic cholangio\"         \"Jejunum\"                       \n[145] \"Kidney\"                         \"Lacrimal gland\"                \n[147] \"Large intestine\"                \"Laryngeal squamous epithelium\" \n[149] \"Lateral ganglionic eminence\"    \"Ligament\"                      \n[151] \"Limb bud\"                       \"Limbal epithelium\"             \n[153] \"Liver\"                          \"Lumbar vertebra\"               \n[155] \"Lung\"                           \"Lymph\"                         \n[157] \"Lymph node\"                     \"Lymphatic vessel\"              \n[159] \"Lymphoid tissue\"                \"Malignant pleural effusion\"    \n[161] \"Mammary epithelium\"             \"Mammary gland\"                 \n[163] \"Medial ganglionic eminence\"     \"Medullary thymus\"              \n[165] \"Meniscus\"                       \"Mesoblast\"                     \n[167] \"Mesoderm\"                       \"Microvascular endothelium\"     \n[169] \"Microvessel\"                    \"Midbrain\"                      \n[171] \"Middle temporal gyrus\"          \"Milk\"                          \n[173] \"Molar\"                          \"Muscle\"                        \n[175] \"Myenteric plexus\"               \"Myocardium\"                    \n[177] \"Myometrium\"                     \"Nasal concha\"                  \n[179] \"Nasal epithelium\"               \"Nasal mucosa\"                  \n[181] \"Nasal polyp\"                    \"Neocortex\"                     \n[183] \"Nerve\"                          \"Nose\"                          \n[185] \"Nucleus pulposus\"               \"Olfactory neuroepithelium\"     \n[187] \"Optic nerve\"                    \"Oral cavity\"                   \n[189] \"Oral mucosa\"                    \"Osteoarthritic cartilage\"      \n[191] \"Ovarian cortex\"                 \"Ovarian follicle\"              \n[193] \"Ovary\"                          \"Oviduct\"                       \n[195] \"Pancreas\"                       \"Pancreatic acinar tissue\"      \n[197] \"Pancreatic duct\"                \"Pancreatic islet\"              \n[199] \"Periodontal ligament\"           \"Periodontium\"                  \n[201] \"Periosteum\"                     \"Peripheral blood\"              \n[203] \"Peritoneal fluid\"               \"Peritoneum\"                    \n[205] \"Pituitary\"                      \"Placenta\"                      \n[207] \"Plasma\"                         \"Pluripotent stem cell\"         \n[209] \"Polyp\"                          \"Posterior presomitic mesoderm\" \n[211] \"Prefrontal cortex\"              \"Premolar\"                      \n[213] \"Presomitic mesoderm\"            \"Primitive streak\"              \n[215] \"Prostate\"                       \"Pulmonary arteriy\"             \n[217] \"Pyloric gland\"                  \"Rectum\"                        \n[219] \"Renal glomerulus\"               \"Respiratory tract\"             \n[221] \"Retina\"                         \"Retinal organoid\"              \n[223] \"Retinal pigment epithelium\"     \"Right ventricle\"               \n[225] \"Saliva\"                         \"Salivary gland\"                \n[227] \"Scalp\"                          \"Sclerocorneal tissue\"          \n[229] \"Seminal plasma\"                 \"Septum transversum\"            \n[231] \"Serum\"                          \"Sinonasal mucosa\"              \n[233] \"Sinus tissue\"                   \"Skeletal muscle\"               \n[235] \"Skin\"                           \"Small intestinal crypt\"        \n[237] \"Small intestine\"                \"Soft tissue\"                   \n[239] \"Sperm\"                          \"Spinal cord\"                   \n[241] \"Spleen\"                         \"Splenic red pulp\"              \n[243] \"Sputum\"                         \"Stomach\"                       \n[245] \"Subcutaneous adipose tissue\"    \"Submandibular gland\"           \n[247] \"Subpallium\"                     \"Subplate\"                      \n[249] \"Subventricular zone\"            \"Superior frontal gyrus\"        \n[251] \"Sympathetic ganglion\"           \"Synovial fluid\"                \n[253] \"Synovium\"                       \"Taste bud\"                     \n[255] \"Tendon\"                         \"Testis\"                        \n[257] \"Thalamus\"                       \"Thymus\"                        \n[259] \"Thyroid\"                        \"Tonsil\"                        \n[261] \"Tooth\"                          \"Trachea\"                       \n[263] \"Tracheal airway epithelium\"     \"Transformed artery\"            \n[265] \"Trophoblast\"                    \"Umbilical cord\"                \n[267] \"Umbilical cord blood\"           \"Umbilical vein\"                \n[269] \"Undefined\"                      \"Urine\"                         \n[271] \"Urothelium\"                     \"Uterine cervix\"                \n[273] \"Uterus\"                         \"Vagina\"                        \n[275] \"Vein\"                           \"Venous blood\"                  \n[277] \"Ventral thalamus\"               \"Ventricle\"                     \n[279] \"Ventricular and atrial\"         \"Ventricular zone\"              \n[281] \"Visceral adipose tissue\"        \"Vocal fold\"                    \n[283] \"Whartons jelly\"                 \"White adipose tissue\"          \n[285] \"White matter\"                   \"Yolk sac\"                      \n\ngrep(\"blood\", unique(markers$tissue_type), value = T)\n\n[1] \"Peripheral blood\"     \"Umbilical cord blood\" \"Venous blood\"        \n\nmarkers &lt;- markers[markers$tissue_type %in% c(\n    \"Blood\", \"Venous blood\",\n    \"Serum\", \"Plasma\",\n    \"Spleen\", \"Bone marrow\", \"Lymph node\"\n), ]\n\n# remove strange characters etc.\ncelltype_list &lt;- lapply(unique(markers$cell_name), function(x) {\n    x &lt;- paste(markers$Symbol[markers$cell_name == x], sep = \",\")\n    x &lt;- gsub(\"[[]|[]]| |-\", \",\", x)\n    x &lt;- unlist(strsplit(x, split = \",\"))\n    x &lt;- unique(x[!x %in% c(\"\", \"NA\", \"family\")])\n    x &lt;- casefold(x, upper = T)\n})\nnames(celltype_list) &lt;- unique(markers$cell_name)\n\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &lt; 100]\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &gt; 5]\n\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    gene_rank &lt;- setNames(x$avg_log2FC, x$gene)\n    fgseaRes &lt;- fgsea(pathways = celltype_list, stats = gene_rank, nperm = 10000, scoreType = \"pos\")\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.01, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 5, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\n\n# show top 3 for each cluster.\nlapply(res, head, 3)\n\n$`0`\n      pathway      pval        padj        ES      NES nMoreExtreme size\n1: Neutrophil 9.999e-05 0.002274773 0.8596747 1.768180            0   22\n2:   Monocyte 9.999e-05 0.002274773 0.8152552 1.737522            0   40\n3: Eosinophil 9.999e-05 0.002274773 0.8683785 1.723714            0   13\n                                 leadingEdge\n1: S100A8,S100A9,CD14,CSF3R,S100A6,PLAUR,...\n2:   S100A8,S100A9,LYZ,S100A12,VCAN,FCN1,...\n3:    S100A8,S100A9,LYZ,RETN,CSF3R,ICAM1,...\n\n$`1`\n                                                            pathway      pval\n1:                                              Natural killer cell 9.999e-05\n2:                    Finally highly effector (TEMRA) memory T cell 9.999e-05\n3: CD4+ recently activated effector memory or effector T cell (CTL) 9.999e-05\n         padj        ES      NES nMoreExtreme size\n1: 0.00076356 0.9028054 2.222363            0   38\n2: 0.00076356 0.9919728 2.101706            0    7\n3: 0.00076356 0.9500974 2.081966            0   10\n                            leadingEdge\n1: GNLY,GZMB,FGFBP2,PRF1,NKG7,SPON2,...\n2:    GNLY,NKG7,CST7,GZMA,GZMH,CCL5,...\n3:   GNLY,PRF1,NKG7,CTSW,GZMH,S1PR5,...\n\n$`2`\n       pathway      pval       padj        ES      NES nMoreExtreme size\n1: CD8+ T cell 9.999e-05 0.00049995 0.9582694 2.068813            0   12\n2: CD4+ T cell 9.999e-05 0.00049995 0.9437698 2.022236            0   11\n3:      T cell 9.999e-05 0.00049995 0.8614252 2.005057            0   32\n                          leadingEdge\n1: CD3D,CD8A,CD8B,TRGC2,TRAC,CD3E,...\n2:  CD3D,CD8A,TRAC,CD3E,IL32,IL7R,...\n3:  GZMK,CD3D,CD8A,CD3G,CD8B,GZMH,...\n\n$`3`\n             pathway      pval        padj        ES      NES nMoreExtreme size\n1:            B cell 9.999e-05 0.001849815 0.9003237 1.923899            0   29\n2:      Naive B cell 9.999e-05 0.001849815 0.9502942 1.919618            0   13\n3: Follicular B cell 9.999e-05 0.001849815 0.9530874 1.889348            0   10\n                             leadingEdge\n1:  IGHM,IGHD,CD79A,IGKC,TCL1A,MS4A1,...\n2:  IGHM,IGHD,TCL1A,MS4A1,FCER2,YBX3,...\n3: IGHD,CD79A,TCL1A,MS4A1,CD79B,CD74,...\n\n$`4`\n             pathway       pval        padj        ES      NES nMoreExtreme\n1: Naive T(Th0) cell 0.00009999 0.004099590 0.9024674 1.739839            0\n2:       CD8+ T cell 0.00029997 0.006149385 0.8842482 1.716703            2\n3:            B cell 0.00029997 0.006149385 0.8703159 1.677856            2\n   size                       leadingEdge\n1:   11 IL7R,CD3D,IL32,TCF7,CD3E,NPM1,...\n2:   12 IL7R,TRAC,CD3D,IL32,CD28,CD3E,...\n3:   11  IL7R,CD5,CD28,JUNB,CD27,BCL2,...\n\n$`5`\n         pathway       pval       padj        ES      NES nMoreExtreme size\n1: Megakaryocyte 0.00009999 0.00649935 0.9892473 1.865505            0   11\n2:   Plasmablast 0.00209979 0.03412159 0.9327396 1.721114           20    6\n3: Memory B cell 0.00959904 0.11482185 0.8912334 1.644526           95    6\n                        leadingEdge\n1: PPBP,PF4,NRGN,MYL9,GNG11,GP9,...\n2:    IGHA1,IGLC2,TUBA1B,IGKC,GAPDH\n3:                      IGHA1,KLF10\n\n$`6`\n                pathway       pval        padj        ES      NES nMoreExtreme\n1:               B cell 0.00009999 0.002533080 0.8810749 1.800871            0\n2:          Plasma cell 0.00009999 0.002533080 0.9278632 1.783346            0\n3: Marginal zone B cell 0.00029997 0.004559544 0.9495868 1.747841            2\n   size                           leadingEdge\n1:   37  IGKC,CD79A,MS4A1,BANK1,IGHM,CD74,...\n2:   13 IGKC,CD79A,IGLC3,IGLC2,IGHM,IGHG1,...\n3:    6 CD79A,MS4A1,CD79B,TNFRSF13B,CD19,CD27\n\n$`7`\n          pathway       pval      padj        ES      NES nMoreExtreme size\n1: CD16+ monocyte 0.00029997 0.0089991 0.9435730 1.753112            2    6\n2:       Monocyte 0.00009999 0.0089991 0.8135685 1.662756            0   27\n3:     Macrophage 0.00019998 0.0089991 0.8087559 1.641009            1   24\n                              leadingEdge\n1:           FCGR3A,TCF7L2,HES4,LYN,MTSS1\n2: LST1,FCGR3A,MS4A7,CST3,PECAM1,CD68,...\n3:  FCGR3A,MS4A7,FCER1G,CD68,FTL,C1QA,...\n\n$`8`\n                      pathway      pval       padj        ES      NES\n1: Central memory CD8+ T cell 9.999e-05 0.00109989 0.9139722 1.941589\n2:          Naive CD8+ T cell 9.999e-05 0.00109989 0.8685820 1.893681\n3:           Naive CD8 T cell 9.999e-05 0.00109989 0.9024094 1.879507\n   nMoreExtreme size                         leadingEdge\n1:            0   12 CCR7,IL7R,TCF7,LEF1,TSHZ2,RCAN3,...\n2:            0   16  CCR7,TCF7,LEF1,TSHZ2,RCAN3,MAL,...\n3:            0   10  CCR7,TCF7,LEF1,TSHZ2,RCAN3,MAL,...\n\n\n#CT_GSEA8:\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\nalldata$cellmarker_gsea &lt;- new.cluster.ids[as.character(alldata@active.ident)]\n\nwrap_plots(\n    DimPlot(alldata, label = T, group.by = \"ref_gsea\") + NoAxes(),\n    DimPlot(alldata, label = T, group.by = \"cellmarker_gsea\") + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you think that the methods overlap well? Where do you see the most inconsistencies?\n\n\nIn this case we do not have any ground truth, and we cannot say which method performs best. You should keep in mind, that any celltype classification method is just a prediction, and you still need to use your common sense and knowledge of the biological system to judge if the results make sense.\nFinally, lets save the data with predictions.\n\nsaveRDS(ctrl, \"data/covid/results/seurat_covid_qc_dr_int_cl_ct-ctrl13.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-session",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] fgsea_1.28.0       caret_6.0-94       lattice_0.21-8     scPred_1.9.2      \n [5] pheatmap_1.0.12    ggplot2_3.4.2      patchwork_1.1.2    dplyr_1.1.2       \n [9] SeuratObject_4.1.3 Seurat_4.3.0      \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3     rstudioapi_0.14        jsonlite_1.8.5        \n  [4] magrittr_2.0.3         ggbeeswarm_0.7.2       spatstat.utils_3.0-3  \n  [7] farver_2.1.1           rmarkdown_2.22         vctrs_0.6.2           \n [10] ROCR_1.0-11            spatstat.explore_3.2-1 htmltools_0.5.5       \n [13] pROC_1.18.2            sctransform_0.3.5      parallelly_1.36.0     \n [16] KernSmooth_2.23-20     htmlwidgets_1.6.2      ica_1.0-3             \n [19] plyr_1.8.8             lubridate_1.9.2        plotly_4.10.2         \n [22] zoo_1.8-12             igraph_1.4.3           mime_0.12             \n [25] lifecycle_1.0.3        iterators_1.0.14       pkgconfig_2.0.3       \n [28] Matrix_1.5-4           R6_2.5.1               fastmap_1.1.1         \n [31] fitdistrplus_1.1-11    future_1.32.0          shiny_1.7.4           \n [34] digest_0.6.31          colorspace_2.1-0       tensor_1.5            \n [37] irlba_2.3.5.1          labeling_0.4.2         progressr_0.13.0      \n [40] timechange_0.2.0       fansi_1.0.4            spatstat.sparse_3.0-1 \n [43] httr_1.4.6             polyclip_1.10-4        abind_1.4-5           \n [46] compiler_4.3.0         withr_2.5.0            BiocParallel_1.36.0   \n [49] lava_1.7.2.1           MASS_7.3-58.4          ModelMetrics_1.2.2.2  \n [52] tools_4.3.0            vipor_0.4.5            lmtest_0.9-40         \n [55] beeswarm_0.4.0         httpuv_1.6.11          future.apply_1.11.0   \n [58] nnet_7.3-18            goftest_1.2-3          glue_1.6.2            \n [61] nlme_3.1-162           promises_1.2.0.1       grid_4.3.0            \n [64] Rtsne_0.16             cluster_2.1.4          reshape2_1.4.4        \n [67] generics_0.1.3         recipes_1.0.6          gtable_0.3.3          \n [70] spatstat.data_3.0-1    class_7.3-21           tidyr_1.3.0           \n [73] data.table_1.14.8      sp_1.6-1               utf8_1.2.3            \n [76] spatstat.geom_3.2-1    RcppAnnoy_0.0.20       ggrepel_0.9.3         \n [79] RANN_2.6.1             foreach_1.5.2          pillar_1.9.0          \n [82] stringr_1.5.0          limma_3.58.1           later_1.3.1           \n [85] splines_4.3.0          survival_3.5-5         deldir_1.0-9          \n [88] tidyselect_1.2.0       miniUI_0.1.1.1         pbapply_1.7-0         \n [91] knitr_1.43             gridExtra_2.3          scattermore_1.2       \n [94] RhpcBLASctl_0.23-42    stats4_4.3.0           xfun_0.39             \n [97] statmod_1.5.0          hardhat_1.3.0          timeDate_4022.108     \n[100] matrixStats_1.0.0      stringi_1.7.12         lazyeval_0.2.2        \n[103] yaml_2.3.7             evaluate_0.21          codetools_0.2-19      \n[106] kernlab_0.9-32         tibble_3.2.1           cli_3.6.1             \n[109] uwot_0.1.14            rpart_4.1.19           xtable_1.8-4          \n[112] reticulate_1.30        munsell_0.5.0          harmony_1.2.0         \n[115] Rcpp_1.0.10            globals_0.16.2         spatstat.random_3.1-5 \n[118] png_0.1-8              parallel_4.3.0         ellipsis_0.3.2        \n[121] gower_1.0.1            listenv_0.9.0          viridisLite_0.4.2     \n[124] ipred_0.9-14           prodlim_2023.03.31     scales_1.2.1          \n[127] ggridges_0.5.4         crayon_1.5.2           leiden_0.4.3          \n[130] purrr_1.0.1            rlang_1.1.1            fastmatch_1.1-3       \n[133] cowplot_1.1.1"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html",
    "href": "labs/seurat/seurat_07_trajectory.html",
    "title": " Trajectory inference using Slingshot",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#loading-libraries",
    "href": "labs/seurat/seurat_07_trajectory.html#loading-libraries",
    "title": " Trajectory inference using Slingshot",
    "section": "1 Loading libraries",
    "text": "1 Loading libraries\n\nsuppressPackageStartupMessages({\n  library(Seurat)\n  library(plotly)\n  options(rgl.printRglwidget = TRUE)\n  library(Matrix)\n  library(sparseMatrixStats)\n  library(slingshot)\n  library(tradeSeq)\n  library(patchwork)\n})\n\n# Define some color palette\npal &lt;- c(scales::hue_pal()(8), RColorBrewer::brewer.pal(9, \"Set1\"), RColorBrewer::brewer.pal(8, \"Set2\"))\nset.seed(1)\npal &lt;- rep(sample(pal, length(pal)), 200)\n\nNice function to easily draw a graph:\n\n# Add graph to the base R graphics plot\ndraw_graph &lt;- function(layout, graph, lwd = 0.2, col = \"grey\") {\n  res &lt;- rep(x = 1:(length(graph@p) - 1), times = (graph@p[-1] - graph@p[-length(graph@p)]))\n  segments(\n    x0 = layout[graph@i + 1, 1], x1 = layout[res, 1],\n    y0 = layout[graph@i + 1, 2], y1 = layout[res, 2], lwd = lwd, col = col\n  )\n}"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#preparing-data",
    "href": "labs/seurat/seurat_07_trajectory.html#preparing-data",
    "title": " Trajectory inference using Slingshot",
    "section": "2 Preparing data",
    "text": "2 Preparing data\nIn order to speed up the computations during the exercises, we will be using a subset of a bone marrow dataset (originally containing about 100K cells). The bone marrow is the source of adult immune cells, and contains virtually all differentiation stages of cell from the immune system which later circulate in the blood to all other organs.\n\n\n\n\n\nYou can download the files we prepared with these commands:\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/trajectory/trajectory_seurat_filtered.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"trajectory/trajectory_seurat_filtered.rds\"), destfile = path_file)\n\nIf you have been using the Seurat, Bioconductor or Scanpy toolkits with your own data, you need to reach to the point where can find get:\n\nA dimensionality reduction where to perform the trajectory (for example: PCA, ICA, MNN, harmony, Diffusion Maps, UMAP)\nThe cell clustering information (for example: from Louvain, k-means)\nA KNN/SNN graph (this is useful to inspect and sanity-check your trajectories)"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#reading-data",
    "href": "labs/seurat/seurat_07_trajectory.html#reading-data",
    "title": " Trajectory inference using Slingshot",
    "section": "3 Reading data",
    "text": "3 Reading data\nWe already have pre-computed and subsetted the dataset (with 6688 cells and 3585 genes) following the analysis steps in this course. We then saved the objects, so you can use common tools to open and start to work with them (either in R or Python).\n\nobj &lt;- readRDS(\"data/trajectory/trajectory_seurat_filtered.rds\")\n\n# Calculate cluster centroids (for plotting the labels later)\nmm &lt;- sparse.model.matrix(~ 0 + factor(obj$clusters_use))\ncolnames(mm) &lt;- levels(factor(obj$clusters_use))\ncentroids2d &lt;- as.matrix(t(t(obj@reductions$umap@cell.embeddings) %*% mm) / Matrix::colSums(mm))\n\nLets visualize which clusters we have in our dataset:\n\nvars &lt;- c(\"batches\", \"dataset\", \"clusters_use\", \"Phase\")\npl &lt;- list()\n\nfor (i in vars) {\n  pl[[i]] &lt;- DimPlot(obj, group.by = i, label = T) + theme_void() + NoLegend()\n}\nwrap_plots(pl)\n\n\n\n\n\n\n\n\nYou can check, for example how many cells are in each cluster:\n\ntable(obj$clusters)\n\n\n  1   2   5   6   7   8   9  11  12  13  14  15  16  17  18  19  20  21  22  23 \n128  71  90 160 147 120 160 130 132  78  90 150 140  76 141  90  98 149  90  10 \n 25  26  27  28  29  32  33  34  35  36  37  38  41  43  44  45  46  47  49  50 \n 56 154  98  76 125 150 150 146 150 148 135 128 145 134 110 149 140 113 132  85 \n 52  53  54  55  57  58  59  60  61 \n126 129  57 129 147 127 118 120 101"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#exploring-the-data",
    "href": "labs/seurat/seurat_07_trajectory.html#exploring-the-data",
    "title": " Trajectory inference using Slingshot",
    "section": "4 Exploring the data",
    "text": "4 Exploring the data\nIt is crucial that you performing analysis of a dataset understands what is going on, what are the clusters you see in your data and most importantly How are the clusters related to each other?. Well, let’s explore the data a bit. With the help of this table, write down which cluster numbers in your dataset express these key markers.\n\n\n\nMarker\nCell Type\n\n\n\n\nCd34\nHSC progenitor\n\n\nMs4a1\nB cell lineage\n\n\nCd3e\nT cell lineage\n\n\nLtf\nGranulocyte lineage\n\n\nCst3\nMonocyte lineage\n\n\nMcpt8\nMast Cell lineage\n\n\nAlas2\nRBC lineage\n\n\nSiglech\nDendritic cell lineage\n\n\nC1qc\nMacrophage cell lineage\n\n\nPf4\nMegakaryocyte cell lineage\n\n\n\n\nvars &lt;- c(\"Cd34\", \"Ms4a1\", \"Cd3e\", \"Ltf\", \"Cst3\", \"Mcpt8\", \"Alas2\", \"Siglech\", \"C1qc\", \"Pf4\")\npl &lt;- list()\n\npl &lt;- list(DimPlot(obj, group.by = \"clusters_use\", label = T) + theme_void() + NoLegend())\nfor (i in vars) {\n  pl[[i]] &lt;- FeaturePlot(obj, features = i, order = T) + theme_void() + NoLegend()\n}\nwrap_plots(pl)\n\n\n\n\n\n\n\n\nAnother way to better explore your data is to look in higher dimensions, to really get a sense for what is right or wrong. As mentioned in the dimensionality reduction exercises, here we ran UMAP with 3 dimensions.\n\n\n\n\n\n\nImportant\n\n\n\nThe UMAP needs to be computed to results in exactly 3 dimensions\n\n\nSince the steps below are identical to both Seurat and Scran pipelines, we will extract the matrices from both, so it is clear what is being used where and to remove long lines of code used to get those matrices. We will use them all. Plot in 3D with Plotly:\n\ndf &lt;- data.frame(obj@reductions$umap3d@cell.embeddings, variable = factor(obj$clusters_use))\ncolnames(df)[1:3] &lt;- c(\"UMAP_1\", \"UMAP_2\", \"UMAP_3\")\np_State &lt;- plot_ly(df, x = ~UMAP_1, y = ~UMAP_2, z = ~UMAP_3, color = ~variable, colors = pal, size = .5)\np_State\n\n\n\n\n\n\n# to save interactive plot and open in a new tab\ntry(htmlwidgets::saveWidget(p_State, selfcontained = T, \"umap_3d_clustering_plotly.html\"), silent = T)\nutils::browseURL(\"umap_3d_clustering_plotly.html\")\n\nWe can now compute the lineages on these dataset.\n\n# Define lineage ends\nENDS &lt;- c(\"17\", \"27\", \"25\", \"16\", \"26\", \"53\", \"49\")\n\nset.seed(1)\nlineages &lt;- as.SlingshotDataSet(getLineages(\n  data           = obj@reductions$umap3d@cell.embeddings,\n  clusterLabels  = obj$clusters_use,\n  dist.method    = \"mnn\", # It can be: \"simple\", \"scaled.full\", \"scaled.diag\", \"slingshot\" or \"mnn\"\n  end.clus       = ENDS, # You can also define the ENDS!\n  start.clus     = \"34\"\n)) # define where to START the trajectories\n\n\n# IF NEEDED, ONE CAN ALSO MANULALLY EDIT THE LINEAGES, FOR EXAMPLE:\n# sel &lt;- sapply( lineages@lineages, function(x){rev(x)[1]} ) %in% ENDS\n# lineages@lineages &lt;- lineages@lineages[ sel ]\n# names(lineages@lineages) &lt;- paste0(\"Lineage\",1:length(lineages@lineages))\n# lineages\n\n\n# Change the reduction to our \"fixed\" UMAP2d (FOR VISUALISATION ONLY)\nlineages@reducedDim &lt;- obj@reductions$umap@cell.embeddings\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16)\n  lines(lineages, lwd = 1, col = \"black\", cex = 2)\n  text(centroids2d, labels = rownames(centroids2d), cex = 0.8, font = 2, col = \"white\")\n}\n\n\n\n\n\n\n\n\nMuch better!"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#defining-principal-curves",
    "href": "labs/seurat/seurat_07_trajectory.html#defining-principal-curves",
    "title": " Trajectory inference using Slingshot",
    "section": "5 Defining Principal Curves",
    "text": "5 Defining Principal Curves\nOnce the clusters are connected, Slingshot allows you to transform them to a smooth trajectory using principal curves. This is an algorithm that iteratively changes an initial curve to better match the data points. It was developed for linear data. To apply it to single-cell data, slingshot adds two enhancements:\n\nIt will run principal curves for each ‘lineage’, which is a set of clusters that go from a defined start cluster to some end cluster\nLineages with a same set of clusters will be constrained so that their principal curves remain bundled around the overlapping clusters\n\nSince the function getCurves() takes some time to run, we can speed up the convergence of the curve fitting process by reducing the amount of cells to use in each lineage. Ideally you could all cells, but here we had set approx_points to 300 to speed up. Feel free to adjust that for your dataset.\n\n# Define curves\ncurves &lt;- as.SlingshotDataSet(getCurves(\n  data          = lineages,\n  thresh        = 1e-1,\n  stretch       = 1e-1,\n  allow.breaks  = F,\n  approx_points = 100\n))\n\ncurves\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5828          2\n\nlineages: 7 \nLineage1: 34  18  36  33  55  59  44  60  58  29  8  43  47  49  \nLineage2: 34  18  11  15  46  9  1  2  5  13  28  17  \nLineage3: 34  18  11  15  35  7  32  6  54  25  \nLineage4: 34  18  11  15  35  7  32  6  27  \nLineage5: 34  18  36  21  12  20  16  \nLineage6: 34  18  36  33  55  38  53  \nLineage7: 34  18  36  26  \n\ncurves: 7 \nCurve1: Length: 6.7241  Samples: 2161.05\nCurve2: Length: 7.3487  Samples: 2097.02\nCurve3: Length: 3.5349  Samples: 1502.25\nCurve4: Length: 2.5623  Samples: 1387.66\nCurve5: Length: 2.9268  Samples: 979.78\nCurve6: Length: 2.8976  Samples: 1086.34\nCurve7: Length: 2.1323  Samples: 644.86\n\n# Plots\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], pch = 16)\n  lines(curves, lwd = 2, col = \"black\")\n  text(centroids2d, labels = rownames(centroids2d), cex = 1, font = 2)\n}\n\n\n\n\n\n\n\n\nWith those results in hands, we can now compute the differentiation pseudotime.\n\npseudotime &lt;- slingPseudotime(curves, na = FALSE)\ncellWeights &lt;- slingCurveWeights(curves)\n\nx &lt;- rowMeans(pseudotime)\nx &lt;- x / max(x)\no &lt;- order(x)\n\n{\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(\"pseudotime\"), pch = 16, cex = 0.4, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"grey70\", \"orange3\", \"firebrick\", \"purple4\"))(99)[x[o] * 98 + 1]\n  )\n  points(centroids2d, cex = 2.5, pch = 16, col = \"#FFFFFF99\")\n  text(centroids2d, labels = rownames(centroids2d), cex = 1, font = 2)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe pseudotime represents the distance of every cell to the starting cluster!"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#finding-differentially-expressed-genes",
    "href": "labs/seurat/seurat_07_trajectory.html#finding-differentially-expressed-genes",
    "title": " Trajectory inference using Slingshot",
    "section": "6 Finding differentially expressed genes",
    "text": "6 Finding differentially expressed genes\nThe main way to interpret a trajectory is to find genes that change along the trajectory. There are many ways to define differential expression along a trajectory:\n\nExpression changes along a particular path (i.e. change with pseudotime)\nExpression differences between branches\nExpression changes at branch points\nExpression changes somewhere along the trajectory\n…\n\ntradeSeq is a recently proposed algorithm to find trajectory differentially expressed genes. It works by smoothing the gene expression along the trajectory by fitting a smoother using generalized additive models (GAMs), and testing whether certain coefficients are statistically different between points in the trajectory.\n\nBiocParallel::register(BiocParallel::MulticoreParam())\n\nThe fitting of GAMs can take quite a while, so for demonstration purposes we first do a very stringent filtering of the genes.\n\n\n\n\n\n\nCaution\n\n\n\nIn an ideal experiment, you would use all the genes, or at least those defined as being variable.\n\n\n\nsel_cells &lt;- split(colnames(obj@assays$RNA@data), obj$clusters_use)\nsel_cells &lt;- unlist(lapply(sel_cells, function(x) {\n  set.seed(1)\n  return(sample(x, 20))\n}))\n\ngv &lt;- as.data.frame(na.omit(scran::modelGeneVar(obj@assays$RNA@data[, sel_cells])))\ngv &lt;- gv[order(gv$bio, decreasing = T), ]\nsel_genes &lt;- sort(rownames(gv)[1:500])\n\nFitting the model:\n\nsceGAM &lt;- fitGAM(\n  counts = drop0(obj@assays$RNA@data[sel_genes, sel_cells]),\n  pseudotime = pseudotime[sel_cells, ],\n  cellWeights = cellWeights[sel_cells, ],\n  nknots = 5, verbose = T, parallel = T, sce = TRUE,\n  BPPARAM = BiocParallel::MulticoreParam()\n)\n\n\npath_file &lt;- \"data/trajectory/seurat_scegam.rds\"\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"trajectory/results/seurat_scegam.rds\"), destfile = path_file)\nsceGAM &lt;- readRDS(path_file)\n\n\nplotGeneCount(curves, clusters = obj$clusters_use, models = sceGAM)\n\n\n\n\n\n\n\nlineages\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5828          2\n\nlineages: 7 \nLineage1: 34  18  36  33  55  59  44  60  58  29  8  43  47  49  \nLineage2: 34  18  11  15  46  9  1  2  5  13  28  17  \nLineage3: 34  18  11  15  35  7  32  6  54  25  \nLineage4: 34  18  11  15  35  7  32  6  27  \nLineage5: 34  18  36  21  12  20  16  \nLineage6: 34  18  36  33  55  38  53  \nLineage7: 34  18  36  26  \n\ncurves: 0 \n\n\n\nlc &lt;- sapply(lineages@lineages, function(x) {\n  rev(x)[1]\n})\nnames(lc) &lt;- gsub(\"Lineage\", \"L\", names(lc))\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], pch = 16)\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc, ], col = \"black\", pch = 16, cex = 4)\n  text(centroids2d[lc, ], labels = names(lc), cex = 1, font = 2, col = \"white\")\n}\n\n\n\n\n\n\n\n\n\n6.1 Genes that change with pseudotime\nWe can first look at general trends of gene expression across pseudotime.\n\nres &lt;- na.omit(associationTest(sceGAM, contrastType = \"consecutive\"))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, ]\n\n\n\n  \n\n\n\nWe can plot their expression:\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nvars &lt;- rownames(res[1:15, ])\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\n\n\n6.2 Genes that change between two pseudotime points\nWe can define custom pseudotime values of interest if we’re interested in genes that change between particular point in pseudotime. By default, we can look at differences between start and end:\n\nres &lt;- na.omit(startVsEndTest(sceGAM, pseudotimeValues = c(0, 1)))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, 1:6]\n\n\n\n  \n\n\n\nYou can see now that there are several more columns, one for each lineage. This table represents the differential expression within each lineage, to identify which genes go up or down. Let’s check lineage 1:\n\n# Get the top UP and Down regulated in lineage 1\nres_lin1 &lt;- sort(setNames(res$logFClineage1, rownames(res)))\nvars &lt;- names(c(rev(res_lin1)[1:7], res_lin1[1:8]))\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\n\n\n6.3 Genes that are different between lineages\nMore interesting are genes that are different between two branches. We may have seen some of these genes already pop up in previous analyses of pseudotime. There are several ways to define “different between branches”, and each have their own functions:\n\nDifferent at the end points, using diffEndTest\nDifferent at the branching point, using earlyDETest\nDifferent somewhere in pseudotime the branching point, using patternTest\nNote that the last function requires that the pseudotimes between two lineages are aligned.\n\n\nres &lt;- na.omit(diffEndTest(sceGAM))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, ]\n\n\n\n  \n\n\n\nYou can see now that there are even more columns, one for the pair-wise comparison between each lineage. Let’s check lineage 1 vs lineage 2:\n\n# Get the top UP and Down regulated in lineage 1 vs 2\nres_lin1_2 &lt;- sort(setNames(res$logFC1_2, rownames(res)))\nvars &lt;- names(c(rev(res_lin1_2)[1:7], res_lin1_2[1:8]))\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\nCheck out this vignette for a more in-depth overview of tradeSeq and many other differential expression tests."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#references",
    "href": "labs/seurat/seurat_07_trajectory.html#references",
    "title": " Trajectory inference using Slingshot",
    "section": "7 References",
    "text": "7 References\nCannoodt, Robrecht, Wouter Saelens, and Yvan Saeys. 2016. “Computational Methods for Trajectory Inference from Single-Cell Transcriptomics.” European Journal of Immunology 46 (11): 2496–2506. doi.\nSaelens, Wouter, Robrecht Cannoodt, Helena Todorov, and Yvan Saeys. 2019. “A Comparison of Single-Cell Trajectory Inference Methods.” Nature Biotechnology 37 (5): 547–54. doi."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#session-info",
    "href": "labs/seurat/seurat_07_trajectory.html#session-info",
    "title": " Trajectory inference using Slingshot",
    "section": "8 Session info",
    "text": "8 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] patchwork_1.1.2             tradeSeq_1.16.0            \n [3] slingshot_2.10.0            TrajectoryUtils_1.10.0     \n [5] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [7] Biobase_2.62.0              GenomicRanges_1.54.1       \n [9] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[11] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[13] princurve_2.1.6             sparseMatrixStats_1.14.0   \n[15] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n[17] Matrix_1.5-4                plotly_4.10.2              \n[19] ggplot2_3.4.2               SeuratObject_4.1.3         \n[21] Seurat_4.3.0               \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.20          splines_4.3.0            \n  [3] later_1.3.1               bitops_1.0-7             \n  [5] tibble_3.2.1              polyclip_1.10-4          \n  [7] lifecycle_1.0.3           edgeR_4.0.7              \n  [9] globals_0.16.2            lattice_0.21-8           \n [11] MASS_7.3-58.4             crosstalk_1.2.0          \n [13] magrittr_2.0.3            limma_3.58.1             \n [15] rmarkdown_2.22            yaml_2.3.7               \n [17] metapod_1.10.1            httpuv_1.6.11            \n [19] sctransform_0.3.5         sp_1.6-1                 \n [21] spatstat.sparse_3.0-1     reticulate_1.30          \n [23] cowplot_1.1.1             pbapply_1.7-0            \n [25] RColorBrewer_1.1-3        abind_1.4-5              \n [27] zlibbioc_1.48.0           Rtsne_0.16               \n [29] purrr_1.0.1               RCurl_1.98-1.12          \n [31] GenomeInfoDbData_1.2.11   ggrepel_0.9.3            \n [33] irlba_2.3.5.1             listenv_0.9.0            \n [35] spatstat.utils_3.0-3      goftest_1.2-3            \n [37] dqrng_0.3.0               spatstat.random_3.1-5    \n [39] fitdistrplus_1.1-11       parallelly_1.36.0        \n [41] DelayedMatrixStats_1.24.0 leiden_0.4.3             \n [43] codetools_0.2-19          DelayedArray_0.28.0      \n [45] scuttle_1.12.0            tidyselect_1.2.0         \n [47] farver_2.1.1              ScaledMatrix_1.10.0      \n [49] viridis_0.6.3             spatstat.explore_3.2-1   \n [51] jsonlite_1.8.5            BiocNeighbors_1.20.2     \n [53] ellipsis_0.3.2            progressr_0.13.0         \n [55] ggridges_0.5.4            survival_3.5-5           \n [57] tools_4.3.0               ica_1.0-3                \n [59] Rcpp_1.0.10               glue_1.6.2               \n [61] gridExtra_2.3             SparseArray_1.2.3        \n [63] xfun_0.39                 mgcv_1.8-42              \n [65] dplyr_1.1.2               withr_2.5.0              \n [67] fastmap_1.1.1             bluster_1.12.0           \n [69] fansi_1.0.4               digest_0.6.31            \n [71] rsvd_1.0.5                R6_2.5.1                 \n [73] mime_0.12                 colorspace_2.1-0         \n [75] scattermore_1.2           tensor_1.5               \n [77] spatstat.data_3.0-1       utf8_1.2.3               \n [79] tidyr_1.3.0               generics_0.1.3           \n [81] data.table_1.14.8         httr_1.4.6               \n [83] htmlwidgets_1.6.2         S4Arrays_1.2.0           \n [85] uwot_0.1.14               pkgconfig_2.0.3          \n [87] gtable_0.3.3              lmtest_0.9-40            \n [89] XVector_0.42.0            htmltools_0.5.5          \n [91] scales_1.2.1              png_0.1-8                \n [93] scran_1.30.0              knitr_1.43               \n [95] rstudioapi_0.14           reshape2_1.4.4           \n [97] nlme_3.1-162              zoo_1.8-12               \n [99] stringr_1.5.0             KernSmooth_2.23-20       \n[101] parallel_4.3.0            miniUI_0.1.1.1           \n[103] pillar_1.9.0              grid_4.3.0               \n[105] vctrs_0.6.2               RANN_2.6.1               \n[107] promises_1.2.0.1          BiocSingular_1.18.0      \n[109] beachmat_2.18.0           xtable_1.8-4             \n[111] cluster_2.1.4             evaluate_0.21            \n[113] cli_3.6.1                 locfit_1.5-9.8           \n[115] compiler_4.3.0            rlang_1.1.1              \n[117] crayon_1.5.2              future.apply_1.11.0      \n[119] labeling_0.4.2            plyr_1.8.8               \n[121] stringi_1.7.12            viridisLite_0.4.2        \n[123] deldir_1.0-9              BiocParallel_1.36.0      \n[125] munsell_0.5.0             lazyeval_0.2.2           \n[127] spatstat.geom_3.2-1       future_1.32.0            \n[129] statmod_1.5.0             shiny_1.7.4              \n[131] ROCR_1.0-11               igraph_1.4.3"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html",
    "href": "labs/seurat/seurat_08_spatial.html",
    "title": " Spatial Transcriptomics",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nThis tutorial is adapted from the Seurat vignette.\nSpatial transcriptomic data with the Visium platform is in many ways similar to scRNAseq data. It contains UMI counts for 5-20 cells instead of single cells, but is still quite sparse in the same way as scRNAseq data is, but with the additional information about spatial location in the tissue.\nHere we will first run quality control in a similar manner to scRNAseq data, then QC filtering, dimensionality reduction, integration and clustering. Then we will use scRNAseq data from mouse cortex to run LabelTransfer to predict celltypes in the Visium spots.\nWe will use two Visium spatial transcriptomics dataset of the mouse brain (Sagittal), which are publicly available from the 10x genomics website. Note, that these dataset have already been filtered for spots that does not overlap with the tissue."
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_prep",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_prep",
    "title": " Spatial Transcriptomics",
    "section": "1 Preparation",
    "text": "1 Preparation\nLoad packages\n\n# remotes::install_github('satijalab/seurat-data', dependencies=FALSE)\n\nsuppressPackageStartupMessages({\n    library(Matrix)\n    library(dplyr)\n    library(SeuratData)\n    library(Seurat)\n    library(ggplot2)\n    library(patchwork)\n    library(dplyr)\n})\n\nLoad ST data\nThe package SeuratData has some seurat objects for different datasets. Among those are spatial transcriptomics data from mouse brain and kidney. Here we will download and process sections from the mouse brain.\n\noutdir &lt;- \"data/spatial/\"\nif (!dir.exists(outdir)) dir.create(outdir, showWarnings = F)\n\n# to list available datasets in SeuratData you can run AvailableData()\n\n# first we dowload the dataset\nif (!(\"stxBrain.SeuratData\" %in% rownames(SeuratData::InstalledData()))) {\n    InstallData(\"stxBrain\")\n}\n\n# now we can list what datasets we have downloaded\nInstalledData()\n\n\n\n  \n\n\n# now we will load the seurat object for one section\nbrain1 &lt;- LoadData(\"stxBrain\", type = \"anterior1\")\nbrain2 &lt;- LoadData(\"stxBrain\", type = \"posterior1\")\n\nMerge into one seurat object\n\nbrain &lt;- merge(brain1, brain2)\nbrain\n\nAn object of class Seurat \n31053 features across 6049 samples within 1 assay \nActive assay: Spatial (31053 features, 0 variable features)\n 2 images present: anterior1, posterior1\n\n\nAs you can see, now we do not have the assay “RNA”, but instead an assay called “Spatial”."
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_qc",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_qc",
    "title": " Spatial Transcriptomics",
    "section": "2 Quality control",
    "text": "2 Quality control\nSimilar to scRNA-seq we use statistics on number of counts, number of features and percent mitochondria for quality control.\nNow the counts and feature counts are calculated on the Spatial assay, so they are named “nCount_Spatial” and “nFeature_Spatial”.\n\nbrain &lt;- PercentageFeatureSet(brain, \"^mt-\", col.name = \"percent_mito\")\nbrain &lt;- PercentageFeatureSet(brain, \"^Hb.*-\", col.name = \"percent_hb\")\n\nVlnPlot(brain, features = c(\"nCount_Spatial\", \"nFeature_Spatial\", \"percent_mito\", \"percent_hb\"), pt.size = 0.1, ncol = 2) + NoLegend()\n\n\n\n\n\n\n\n\nWe can also plot the same data onto the tissue section.\n\nSpatialFeaturePlot(brain, features = c(\"nCount_Spatial\", \"nFeature_Spatial\", \"percent_mito\", \"percent_hb\"))\n\n\n\n\n\n\n\n\nAs you can see, the spots with low number of counts/features and high mitochondrial content are mainly towards the edges of the tissue. It is quite likely that these regions are damaged tissue. You may also see regions within a tissue with low quality if you have tears or folds in your section.\nBut remember, for some tissue types, the amount of genes expressed and proportion mitochondria may also be a biological features, so bear in mind what tissue you are working on and what these features mean.\n\n2.1 Filter spots\nSelect all spots with less than 25% mitocondrial reads, less than 20% hb-reads and 500 detected genes. You must judge for yourself based on your knowledge of the tissue what are appropriate filtering criteria for your dataset.\n\nbrain &lt;- brain[, brain$nFeature_Spatial &gt; 500 & brain$percent_mito &lt; 25 & brain$percent_hb &lt; 20]\n\nAnd replot onto tissue section:\n\nSpatialFeaturePlot(brain, features = c(\"nCount_Spatial\", \"nFeature_Spatial\", \"percent_mito\"))\n\n\n\n\n\n\n\n\n\n\n2.2 Top expressed genes\nAs for scRNA-seq data, we will look at what the top expressed genes are.\n\nC &lt;- GetAssayData(brain, assay = \"Spatial\", slot = \"counts\")\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p))\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])),\n    cex = 0.1, las = 1, xlab = \"% total count per cell\",\n    col = (scales::hue_pal())(20)[20:1], horizontal = TRUE\n)\n\n\n\n\n\n\n\nrm(C)\ngc()\n\n            used   (Mb) gc trigger   (Mb)  max used   (Mb)\nNcells   3360643  179.5    5248222  280.3   5248222  280.3\nVcells 189921769 1449.0  375078863 2861.7 357748499 2729.5\n\n\nAs you can see, the mitochondrial genes are among the top expressed genes. Also the lncRNA gene Bc1 (brain cytoplasmic RNA 1). Also one hemoglobin gene.\n\n\n2.3 Filter genes\nWe will remove the Bc1 gene, hemoglobin genes (blood contamination) and the mitochondrial genes.\n\ndim(brain)\n\n[1] 31053  5789\n\n# Filter Bl1\nbrain &lt;- brain[!grepl(\"Bc1\", rownames(brain)), ]\n\n# Filter Mitocondrial\nbrain &lt;- brain[!grepl(\"^mt-\", rownames(brain)), ]\n\n# Filter Hemoglobin gene (optional if that is a problem on your data)\nbrain &lt;- brain[!grepl(\"^Hb.*-\", rownames(brain)), ]\n\ndim(brain)\n\n[1] 31031  5789"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_analysis",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_analysis",
    "title": " Spatial Transcriptomics",
    "section": "3 Analysis",
    "text": "3 Analysis\nWe will proceed with the data in a very similar manner to scRNA-seq data.\nFor ST data, the Seurat team recommends to use SCTranform for normalization, so we will do that. SCTransform will select variable genes and normalize in one step.\n\nbrain &lt;- SCTransform(brain, assay = \"Spatial\", method = \"poisson\", verbose = TRUE)\n\nNow we can plot gene expression of individual genes, the gene Hpca is a strong hippocampal marker and Ttr is a marker of the choroid plexus.\n\nSpatialFeaturePlot(brain, features = c(\"Hpca\", \"Ttr\"))\n\n\n\n\n\n\n\n\nIf you want to see the tissue better you can modify point size and transparency of the points.\n\nSpatialFeaturePlot(brain, features = \"Ttr\", pt.size.factor = 1, alpha = c(0.1, 1))\n\n\n\n\n\n\n\n\n\n3.1 Dimensionality reduction and clustering\nWe can then now run dimensionality reduction and clustering using the same workflow as we use for scRNA-seq analysis.\nBut make sure you run it on the SCT assay.\n\nbrain &lt;- RunPCA(brain, assay = \"SCT\", verbose = FALSE)\nbrain &lt;- FindNeighbors(brain, reduction = \"pca\", dims = 1:30)\nbrain &lt;- FindClusters(brain, verbose = FALSE)\nbrain &lt;- RunUMAP(brain, reduction = \"pca\", dims = 1:30)\n\nWe can then plot clusters onto umap or onto the tissue section.\n\nDimPlot(brain, reduction = \"umap\", group.by = c(\"ident\", \"orig.ident\"))\n\n\n\n\n\n\n\n\n\nSpatialDimPlot(brain)\n\n\n\n\n\n\n\n\nWe can also plot each cluster separately\n\nSpatialDimPlot(brain, cells.highlight = CellsByIdentities(brain), facet.highlight = TRUE, ncol = 5)\n\n\n\n\n\n\n\n\n\n\n3.2 Integration\nQuite often there are strong batch effects between different ST sections, so it may be a good idea to integrate the data across sections.\nWe will do a similar integration as in the Data Integration lab, but this time we will use the SCT assay for integration. Therefore we need to run PrepSCTIntegration which will compute the sctransform residuals for all genes in both the datasets.\n\n# create a list of the original data that we loaded to start with\nst.list &lt;- list(anterior1 = brain1, posterior1 = brain2)\n\n# run SCT on both datasets\nst.list &lt;- lapply(st.list, SCTransform, assay = \"Spatial\", method = \"poisson\")\n\n# need to set maxSize for PrepSCTIntegration to work\noptions(future.globals.maxSize = 2000 * 1024^2) # set allowed size to 2K MiB\n\nst.features &lt;- SelectIntegrationFeatures(st.list, nfeatures = 3000, verbose = FALSE)\nst.list &lt;- PrepSCTIntegration(object.list = st.list, anchor.features = st.features, verbose = FALSE)\n\nNow we can perform the actual integration.\n\nint.anchors &lt;- FindIntegrationAnchors(object.list = st.list, normalization.method = \"SCT\", verbose = FALSE, anchor.features = st.features)\nbrain.integrated &lt;- IntegrateData(anchorset = int.anchors, normalization.method = \"SCT\", verbose = FALSE)\n\nrm(int.anchors, st.list)\ngc()\n\n            used   (Mb) gc trigger   (Mb)   max used   (Mb)\nNcells   3530558  188.6    5248222  280.3    5248222  280.3\nVcells 546165898 4167.0 1148293030 8760.8 1147468538 8754.5\n\n\nThen we run dimensionality reduction and clustering as before.\n\nbrain.integrated &lt;- RunPCA(brain.integrated, verbose = FALSE)\nbrain.integrated &lt;- FindNeighbors(brain.integrated, dims = 1:30)\nbrain.integrated &lt;- FindClusters(brain.integrated, verbose = FALSE)\nbrain.integrated &lt;- RunUMAP(brain.integrated, dims = 1:30)\n\n\nDimPlot(brain.integrated, reduction = \"umap\", group.by = c(\"ident\", \"orig.ident\"))\n\n\n\n\n\n\n\n\n\nSpatialDimPlot(brain.integrated)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you see any differences between the integrated and non-integrated clustering? Judge for yourself, which of the clusterings do you think looks best? As a reference, you can compare to brain regions in the Allen brain atlas.\n\n\n\n\n3.3 Spatially Variable Features\nThere are two main workflows to identify molecular features that correlate with spatial location within a tissue. The first is to perform differential expression based on spatially distinct clusters, the other is to find features that have spatial patterning without taking clusters or spatial annotation into account. First, we will do differential expression between clusters just as we did for the scRNAseq data before.\n\n# differential expression between cluster 1 and cluster 6\nde_markers &lt;- FindMarkers(brain.integrated, ident.1 = 5, ident.2 = 6)\n\n# plot top markers\nSpatialFeaturePlot(object = brain.integrated, features = rownames(de_markers)[1:3], alpha = c(0.1, 1), ncol = 3)\n\n\n\n\n\n\n\n\nSpatial transcriptomics allows researchers to investigate how gene expression trends varies in space, thus identifying spatial patterns of gene expression. For this purpose there are multiple methods, such as SpatailDE, SPARK, Trendsceek, HMRF and Splotch.\nIn FindSpatiallyVariables the default method in Seurat (method = ‘markvariogram), is inspired by the Trendsceek, which models spatial transcriptomics data as a mark point process and computes a ’variogram’, which identifies genes whose expression level is dependent on their spatial location. More specifically, this process calculates gamma(r) values measuring the dependence between two spots a certain “r” distance apart. By default, we use an r-value of ‘5’ in these analyses, and only compute these values for variable genes (where variation is calculated independently of spatial location) to save time.\n\n\n\n\n\n\nCaution\n\n\n\nTakes a long time to run, so skip this step for now!\n\n\n\n# brain &lt;- FindSpatiallyVariableFeatures(brain, assay = \"SCT\", features = VariableFeatures(brain)[1:1000],\n#     selection.method = \"markvariogram\")\n\n# We would get top features from SpatiallyVariableFeatures\n# top.features &lt;- head(SpatiallyVariableFeatures(brain, selection.method = \"markvariogram\"), 6)"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_ss",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_ss",
    "title": " Spatial Transcriptomics",
    "section": "4 Single cell data",
    "text": "4 Single cell data\nWe can use a scRNA-seq dataset as a reference to predict the proportion of different celltypes in the Visium spots. Keep in mind that it is important to have a reference that contains all the celltypes you expect to find in your spots. Ideally it should be a scRNA-seq reference from the exact same tissue. We will use a reference scRNA-seq dataset of ~14,000 adult mouse cortical cell taxonomy from the Allen Institute, generated with the SMART-Seq2 protocol.\nFirst download the seurat data:\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\nif (!dir.exists(\"data/spatial/visium\")) dir.create(\"data/spatial/visium\")\npath_file &lt;- \"data/spatial/visium/allen_cortex.rds\"\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"spatial/visium/allen_cortex.rds\"), destfile = path_file)\n\nFor speed, and for a more fair comparison of the celltypes, we will subsample all celltypes to a maximum of 200 cells per class (subclass).\n\nar &lt;- readRDS(\"data/spatial/visium/allen_cortex.rds\")\n\n# check number of cells per subclass\ntable(ar$subclass)\n\n\n     Astro         CR       Endo    L2/3 IT         L4      L5 IT      L5 PT \n       368          7         94        982       1401        880        544 \n     L6 CT      L6 IT        L6b      Lamp5 Macrophage      Meis2         NP \n       960       1872        358       1122         51         45        362 \n     Oligo       Peri      Pvalb   Serpinf1        SMC       Sncg        Sst \n        91         32       1337         27         55        125       1741 \n       Vip       VLMC \n      1728         67 \n\n# select 200 cells per subclass, fist set subclass ass active.ident\nIdents(ar) &lt;- ar$subclass\nar &lt;- subset(ar, cells = WhichCells(ar, downsample = 200))\n\n# check again number of cells per subclass\ntable(ar$subclass)\n\n\n     Astro         CR       Endo    L2/3 IT         L4      L5 IT      L5 PT \n       200          7         94        200        200        200        200 \n     L6 CT      L6 IT        L6b      Lamp5 Macrophage      Meis2         NP \n       200        200        200        200         51         45        200 \n     Oligo       Peri      Pvalb   Serpinf1        SMC       Sncg        Sst \n        91         32        200         27         55        125        200 \n       Vip       VLMC \n       200         67 \n\n\nThen run normalization and dimensionality reduction.\n\n# First run SCTransform and PCA\nar &lt;- SCTransform(ar, ncells = 3000, verbose = FALSE, method = \"poisson\") %&gt;%\n    RunPCA(verbose = FALSE) %&gt;%\n    RunUMAP(dims = 1:30)\n\n# the annotation is stored in the 'subclass' column of object metadata\nDimPlot(ar, label = TRUE)"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_sub",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_sub",
    "title": " Spatial Transcriptomics",
    "section": "5 Subset ST for cortex",
    "text": "5 Subset ST for cortex\nSince the scRNAseq dataset was generated from the mouse cortex, we will subset the visium dataset in order to select mainly the spots part of the cortex. Note that the integration can also be performed on the whole brain slice, but it would give rise to false positive cell type assignments and therefore it should be interpreted with more care.\n\n# subset for the anterior dataset\ncortex &lt;- subset(brain.integrated, subset = orig.ident == \"anterior1\")\n\n# there seems to be an error in the subsetting, so the posterior1 image is not removed, do it manually\ncortex@images$posterior1 &lt;- NULL\n\n# add coordinates to metadata\n# note that this only returns one slide by default\ncortex$imagerow &lt;- GetTissueCoordinates(cortex)$imagerow\ncortex$imagecol &lt;- GetTissueCoordinates(cortex)$imagecol\n\n# subset for a specific region\ncortex &lt;- subset(cortex, subset = imagerow &gt; 400 | imagecol &lt; 150, invert = TRUE)\ncortex &lt;- subset(cortex, subset = imagerow &gt; 275 & imagecol &gt; 370, invert = TRUE)\ncortex &lt;- subset(cortex, subset = imagerow &gt; 250 & imagecol &gt; 440, invert = TRUE)\n\n# also subset for Frontal cortex clusters\ncortex &lt;- subset(cortex, subset = seurat_clusters %in% c(1, 2, 3, 4, 5))\n\np1 &lt;- SpatialDimPlot(cortex, crop = TRUE)\np2 &lt;- SpatialDimPlot(cortex, crop = FALSE, pt.size.factor = 1, label.size = 3)\np1 + p2"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-st_deconv",
    "href": "labs/seurat/seurat_08_spatial.html#meta-st_deconv",
    "title": " Spatial Transcriptomics",
    "section": "6 Deconvolution",
    "text": "6 Deconvolution\nDeconvolution is a method to estimate the abundance (or proportion) of different celltypes in a bulkRNAseq dataset using a single cell reference. As the Visium data can be seen as a small bulk, we can both use methods for traditional bulkRNAseq as well as methods especially developed for Visium data. Some methods for deconvolution are DWLS, cell2location, Tangram, Stereoscope, RCTD, SCDC and many more.\nHere we will use SCDC for deconvolution of celltypes in the Visium spots. For more information on the tool please check their website: https://meichendong.github.io/SCDC/articles/SCDC.html. First, make sure the packages you need are installed.\n\ninst &lt;- installed.packages()\n\nif (!(\"xbioc\" %in% rownames(inst))) {\n    remotes::install_github(\"renozao/xbioc\", dependencies = FALSE)\n}\nif (!(\"SCDC\" %in% rownames(inst))) {\n    remotes::install_github(\"meichendong/SCDC\", dependencies = FALSE)\n}\n\nsuppressPackageStartupMessages(library(SCDC))\nsuppressPackageStartupMessages(library(Biobase))\n\n\n6.1 Select genes for deconvolution\nMost deconvolution methods does a prior gene selection and there are different options that are used: - Use variable genes in the SC data. - Use variable genes in both SC and ST data - DE genes between clusters in the SC data.\nIn this case we will use top DE genes per cluster, so first we have to run DGE detection on the scRNAseq data.\nFor SCDC we want to find unique markers per cluster, so we select top 20 DEGs per cluster. Ideally you should run with a larger set of genes, perhaps 100 genes per cluster to get better results. However, for the sake of speed, we are now selecting only top20 genes and it still takes about 10 minutes to run.\n\nar@active.assay &lt;- \"RNA\"\n\nmarkers_sc &lt;- FindAllMarkers(ar,\n    only.pos = TRUE,\n    logfc.threshold = 0.1,\n    test.use = \"wilcox\",\n    min.pct = 0.05,\n    min.diff.pct = 0.1,\n    max.cells.per.ident = 200,\n    return.thresh = 0.05,\n    assay = \"RNA\"\n)\n\n# Filter for genes that are also present in the ST data\nmarkers_sc &lt;- markers_sc[markers_sc$gene %in% rownames(cortex), ]\n\n\n# Select top 20 genes per cluster, select top by first p-value, then absolute diff in pct, then quota of pct.\nmarkers_sc$pct.diff &lt;- markers_sc$pct.1 - markers_sc$pct.2\nmarkers_sc$log.pct.diff &lt;- log2((markers_sc$pct.1 * 99 + 1) / (markers_sc$pct.2 * 99 + 1))\nmarkers_sc %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-100, p_val) %&gt;%\n    top_n(50, pct.diff) %&gt;%\n    top_n(20, log.pct.diff) -&gt; top20\nm_feats &lt;- unique(as.character(top20$gene))\n\n\n\n6.2 Create Expression Sets\nFor SCDC both the SC and the ST data need to be in the format of an Expression set with the count matrices as AssayData. We also subset the matrices for the genes we selected in the previous step.\n\neset_SC &lt;- ExpressionSet(\n    assayData = as.matrix(ar@assays$RNA@counts[m_feats, ]),\n    phenoData = AnnotatedDataFrame(ar@meta.data)\n)\neset_ST &lt;- ExpressionSet(assayData = as.matrix(cortex@assays$Spatial@counts[m_feats, ]), phenoData = AnnotatedDataFrame(cortex@meta.data))\n\n\n\n6.3 Deconvolve\nWe then run the deconvolution defining the celltype of interest as “subclass” column in the single cell data.\n\ndeconvolution_crc &lt;- SCDC::SCDC_prop(\n    bulk.eset = eset_ST,\n    sc.eset = eset_SC,\n    ct.varname = \"subclass\",\n    ct.sub = as.character(unique(eset_SC$subclass))\n)\nsaveRDS(deconvolution_crc, \"data/spatial/visium/seurat_scdc.rds\")\n\n\npath_file &lt;- \"data/spatial/visium/seurat_scdc.rds\"\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"spatial/visium/results/seurat_scdc.rds\"), destfile = path_file)\ndeconvolution_crc &lt;- readRDS(path_file)\n\nNow we have a matrix with predicted proportions of each celltypes for each visium spot in prop.est.mvw.\n\nhead(deconvolution_crc$prop.est.mvw)\n\n                     Lamp5 Sncg Serpinf1          Vip          Sst      Pvalb\nAAACTCGTGATATAAG-1_1     0    0        0 0.000000e+00 0.0003020068 0.00000000\nAAACTGCTGGCTCCAA-1_1     0    0        0 0.000000e+00 0.1544641392 0.07943494\nAAAGGGATGTAGCAAG-1_1     0    0        0 0.000000e+00 0.2742639441 0.00000000\nAAATACCTATAAGCAT-1_1     0    0        0 0.000000e+00 0.0803576731 0.40436150\nAAATCGTGTACCACAA-1_1     0    0        0 0.000000e+00 0.0692640621 0.00000000\nAAATGATTCGATCAGC-1_1     0    0        0 1.705303e-06 0.0169468859 0.08888082\n                           Endo         Peri        L6 CT          L6b\nAAACTCGTGATATAAG-1_1 0.00000000 0.000000e+00 0.0000000000 1.512806e-01\nAAACTGCTGGCTCCAA-1_1 0.02562850 0.000000e+00 0.0280520546 1.959849e-05\nAAAGGGATGTAGCAAG-1_1 0.01131595 0.000000e+00 0.0000000000 0.000000e+00\nAAATACCTATAAGCAT-1_1 0.07365610 1.399958e-05 0.0036921008 0.000000e+00\nAAATCGTGTACCACAA-1_1 0.02785003 5.235782e-06 0.0002147064 2.458057e-01\nAAATGATTCGATCAGC-1_1 0.01403814 2.633453e-02 0.2657130174 0.000000e+00\n                            L6 IT CR    L2/3 IT        L5 PT NP        L4\nAAACTCGTGATATAAG-1_1 0.000000e+00  0 0.00000000 0.0000000000  0 0.0000000\nAAACTGCTGGCTCCAA-1_1 1.699877e-05  0 0.38974934 0.0000000000  0 0.0000000\nAAAGGGATGTAGCAAG-1_1 2.237113e-04  0 0.00000000 0.0000000000  0 0.1814651\nAAATACCTATAAGCAT-1_1 0.000000e+00  0 0.00000000 0.0000793099  0 0.0000000\nAAATCGTGTACCACAA-1_1 2.755082e-05  0 0.31058665 0.0000000000  0 0.0000000\nAAATGATTCGATCAGC-1_1 1.350970e-01  0 0.01172995 0.1013133001  0 0.1530583\n                           Oligo      L5 IT Meis2      Astro  Macrophage VLMC\nAAACTCGTGATATAAG-1_1 0.606350282 0.00000000     0 0.00000000 0.242067127    0\nAAACTGCTGGCTCCAA-1_1 0.070102264 0.00000000     0 0.20493666 0.047592071    0\nAAAGGGATGTAGCAAG-1_1 0.000000000 0.36553725     0 0.15879807 0.008395941    0\nAAATACCTATAAGCAT-1_1 0.090470397 0.00000000     0 0.32968096 0.017682500    0\nAAATCGTGTACCACAA-1_1 0.205850104 0.00000000     0 0.11515601 0.025239945    0\nAAATGATTCGATCAGC-1_1 0.002151596 0.09261913     0 0.08687805 0.005237623    0\n                              SMC\nAAACTCGTGATATAAG-1_1 0.000000e+00\nAAACTGCTGGCTCCAA-1_1 3.440261e-06\nAAAGGGATGTAGCAAG-1_1 0.000000e+00\nAAATACCTATAAGCAT-1_1 5.461144e-06\nAAATCGTGTACCACAA-1_1 0.000000e+00\nAAATGATTCGATCAGC-1_1 0.000000e+00\n\n\nNow we take the deconvolution output and add it to the Seurat object as a new assay.\n\ncortex@assays[[\"SCDC\"]] &lt;- CreateAssayObject(data = t(deconvolution_crc$prop.est.mvw))\n\n# Seems to be a bug in SeuratData package that the key is not set and any plotting function etc. will throw an error.\nif (length(cortex@assays$SCDC@key) == 0) {\n    cortex@assays$SCDC@key &lt;- \"scdc_\"\n}\n\n\nDefaultAssay(cortex) &lt;- \"SCDC\"\nSpatialFeaturePlot(cortex, features = c(\"L2/3 IT\", \"L4\"), pt.size.factor = 1.6, ncol = 2, crop = TRUE)\n\n\n\n\n\n\n\n\nBased on these prediction scores, we can also predict cell types whose location is spatially restricted. We use the same methods based on marked point processes to define spatially variable features, but use the cell type prediction scores as the “marks” rather than gene expression.\n\n# FindSpatiallyVariableFeatures() does not work with markvariogram or moransi\n# this chunk is disabled\n\ncortex &lt;- FindSpatiallyVariableFeatures(cortex,\n    assay = \"SCDC\", selection.method = \"markvariogram\",\n    features = rownames(cortex), r.metric = 5, slot = \"data\"\n)\ntop.clusters &lt;- head(SpatiallyVariableFeatures(cortex), 4)\nSpatialPlot(object = cortex, features = top.clusters, ncol = 2)\n\nWe can also visualize the scores per cluster in ST data.\n\n# this chunk is disabled\n\nVlnPlot(cortex, group.by = \"seurat_clusters\", features = top.clusters, pt.size = 0, ncol = 2)\n\nKeep in mind that the deconvolution results are just predictions, depending on how well your scRNAseq data covers the celltypes that are present in the ST data and on how parameters, gene selection etc. are tuned you may get different results.\n\n\n\n\n\n\nDiscuss\n\n\n\nSubset for another region that does not contain cortex cells and check what you get from the label transfer. Suggested region is the right end of the posterial section that you can select like this:\n\n# subset for the anterior dataset\nsubregion &lt;- subset(brain.integrated, subset = orig.ident == \"posterior1\")\n\n# there seems to be an error in the subsetting, so the posterior1 image is not removed, do it manually\nsubregion@images$anterior1 &lt;- NULL\n\n# add coordinates to metadata\n# note that this only returns one slide by default\nsubregion$imagerow &lt;- GetTissueCoordinates(subregion)$imagerow\nsubregion$imagecol &lt;- GetTissueCoordinates(subregion)$imagecol\n\n# subset for a specific region\nsubregion &lt;- subset(subregion, subset = imagecol &gt; 400, invert = FALSE)\n\np1 &lt;- SpatialDimPlot(subregion, crop = TRUE, label = TRUE)\np2 &lt;- SpatialDimPlot(subregion, crop = FALSE, label = TRUE, pt.size.factor = 1, label.size = 3)\np1 + p2"
  },
  {
    "objectID": "labs/seurat/seurat_08_spatial.html#meta-session",
    "href": "labs/seurat/seurat_08_spatial.html#meta-session",
    "title": " Spatial Transcriptomics",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] Biobase_2.62.0            BiocGenerics_0.48.1      \n [3] SCDC_0.0.0.9000           patchwork_1.1.2          \n [5] ggplot2_3.4.2             SeuratObject_4.1.3       \n [7] Seurat_4.3.0              stxBrain.SeuratData_0.1.1\n [9] SeuratData_0.2.2          dplyr_1.1.2              \n[11] Matrix_1.5-4             \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3      rstudioapi_0.14         jsonlite_1.8.5         \n  [4] magrittr_2.0.3          spatstat.utils_3.0-3    farver_2.1.1           \n  [7] rmarkdown_2.22          zlibbioc_1.48.0         vctrs_0.6.2            \n [10] ROCR_1.0-11             memoise_2.0.1           spatstat.explore_3.2-1 \n [13] RCurl_1.98-1.12         htmltools_0.5.5         xbioc_0.1.19           \n [16] sctransform_0.3.5       parallelly_1.36.0       KernSmooth_2.23-20     \n [19] htmlwidgets_1.6.2       ica_1.0-3               plyr_1.8.8             \n [22] cachem_1.0.8            plotly_4.10.2           zoo_1.8-12             \n [25] igraph_1.4.3            mime_0.12               lifecycle_1.0.3        \n [28] pkgconfig_2.0.3         R6_2.5.1                fastmap_1.1.1          \n [31] GenomeInfoDbData_1.2.11 fitdistrplus_1.1-11     future_1.32.0          \n [34] shiny_1.7.4             digest_0.6.31           colorspace_2.1-0       \n [37] S4Vectors_0.40.2        AnnotationDbi_1.64.1    tensor_1.5             \n [40] irlba_2.3.5.1           RSQLite_2.3.1           labeling_0.4.2         \n [43] progressr_0.13.0        fansi_1.0.4             spatstat.sparse_3.0-1  \n [46] nnls_1.4                httr_1.4.6              polyclip_1.10-4        \n [49] abind_1.4-5             compiler_4.3.0          bit64_4.0.5            \n [52] withr_2.5.0             backports_1.4.1         DBI_1.1.3              \n [55] pkgmaker_0.32.8         MASS_7.3-58.4           rappdirs_0.3.3         \n [58] tools_4.3.0             lmtest_0.9-40           httpuv_1.6.11          \n [61] future.apply_1.11.0     goftest_1.2-3           glue_1.6.2             \n [64] nlme_3.1-162            promises_1.2.0.1        grid_4.3.0             \n [67] checkmate_2.2.0         Rtsne_0.16              cluster_2.1.4          \n [70] reshape2_1.4.4          generics_0.1.3          gtable_0.3.3           \n [73] spatstat.data_3.0-1     tidyr_1.3.0             data.table_1.14.8      \n [76] XVector_0.42.0          sp_1.6-1                utf8_1.2.3             \n [79] spatstat.geom_3.2-1     RcppAnnoy_0.0.20        ggrepel_0.9.3          \n [82] RANN_2.6.1              pillar_1.9.0            stringr_1.5.0          \n [85] later_1.3.1             splines_4.3.0           lattice_0.21-8         \n [88] bit_4.0.5               survival_3.5-5          deldir_1.0-9           \n [91] tidyselect_1.2.0        registry_0.5-1          Biostrings_2.70.1      \n [94] miniUI_0.1.1.1          pbapply_1.7-0           knitr_1.43             \n [97] gridExtra_2.3           IRanges_2.36.0          scattermore_1.2        \n[100] stats4_4.3.0            xfun_0.39               matrixStats_1.0.0      \n[103] pheatmap_1.0.12         stringi_1.7.12          lazyeval_0.2.2         \n[106] yaml_2.3.7              evaluate_0.21           codetools_0.2-19       \n[109] tibble_3.2.1            BiocManager_1.30.21     cli_3.6.1              \n[112] uwot_0.1.14             xtable_1.8-4            reticulate_1.30        \n[115] munsell_0.5.0           GenomeInfoDb_1.38.5     Rcpp_1.0.10            \n[118] globals_0.16.2          spatstat.random_3.1-5   L1pack_0.41-24         \n[121] png_0.1-8               parallel_4.3.0          ellipsis_0.3.2         \n[124] assertthat_0.2.1        blob_1.2.4              fastmatrix_0.5         \n[127] bitops_1.0-7            listenv_0.9.0           viridisLite_0.4.2      \n[130] scales_1.2.1            ggridges_0.5.4          leiden_0.4.3           \n[133] purrr_1.0.1             crayon_1.5.2            rlang_1.1.1            \n[136] KEGGREST_1.42.0         cowplot_1.1.1"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html",
    "href": "labs/bioc/bioc_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_data",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_covid &lt;- \"./data/covid\"\nif (!dir.exists(path_covid)) dir.create(path_covid, recursive = T)\n\npath_results &lt;- \"data/covid/results\"\nif (!dir.exists(path_results)) dir.create(path_results, recursive = T)\n\n\nfile_list &lt;- c(\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n)\n\nfor (i in file_list) {\n    path_file &lt;- file.path(path_covid, i)\n    if (!file.exists(path_file)) {\n        download.file(url = file.path(file.path(path_data, \"covid\"), i), destfile = path_file)\n    }\n}\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork) # combining figures\n    library(org.Hs.eg.db)\n})\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\n\ncov.15 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_15.h5\"),\n    use.names = T\n)\ncov.1 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_1.h5\"),\n    use.names = T\n)\ncov.16 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_16.h5\"),\n    use.names = T\n)\ncov.17 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_17.h5\"),\n    use.names = T\n)\n\nctrl.5 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_5.h5\"),\n    use.names = T\n)\nctrl.13 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_13.h5\"),\n    use.names = T\n)\nctrl.14 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_14.h5\"),\n    use.names = T\n)\nctrl.19 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_19.h5\"),\n    use.names = T\n)"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_collate",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\nWe can now load the expression matrices and merge them into a single object. Each analysis workflow (Seurat, Scater, Scanpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column Chemistry in the metadata for plotting later on.\n\nsce &lt;- SingleCellExperiment(assays = list(counts = cbind(cov.1, cov.15, cov.17, ctrl.5, ctrl.13, ctrl.14)))\ndim(sce)\n\n[1] 33538  9000\n\n# Adding metadata\nsce@colData$sample &lt;- unlist(sapply(c(\"cov.1\", \"cov.15\", \"cov.17\", \"ctrl.5\", \"ctrl.13\", \"ctrl.14\"), function(x) rep(x, ncol(get(x)))))\nsce@colData$type &lt;- ifelse(grepl(\"cov\", sce@colData$sample), \"Covid\", \"Control\")\n\nOnce you have created the merged Seurat object, the count matrices and individual count matrices and objects are not needed anymore. It is a good idea to remove them and run garbage collect to free up some memory.\n\n# remove all objects that will not be used.\nrm(cov.15, cov.1, cov.17, ctrl.5, ctrl.13, ctrl.14)\n# run garbage collect to free up memory\ngc()\n\n           used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 10216587 545.7   17147474 915.8 13915408 743.2\nVcells 44612623 340.4   94446392 720.6 83350999 636.0\n\n\nHere is how the count matrix and the metadata look like for every cell.\n\nhead(counts(sce)[, 1:10])\n\n6 x 10 sparse Matrix of class \"dgCMatrix\"\n                               \nMIR1302-2HG . . . . . . . . . .\nFAM138A     . . . . . . . . . .\nOR4F5       . . . . . . . . . .\nAL627309.1  . . . . . . . . . .\nAL627309.3  . . . . . . . . . .\nAL627309.2  . . . . . . . . . .\n\nhead(sce@colData, 10)\n\nDataFrame with 10 rows and 2 columns\n                        sample        type\n                   &lt;character&gt; &lt;character&gt;\nAGGTAGGTCGTTGTTT-1       cov.1       Covid\nTAGAGTCGTCCTCCAT-1       cov.1       Covid\nCCCTGATAGCGAACTG-1       cov.1       Covid\nTCATCATTCCACGTAA-1       cov.1       Covid\nATTTACCCAAGCCTGC-1       cov.1       Covid\nGTTGTCCTCTAGAACC-1       cov.1       Covid\nCCTCCAACAAGAGATT-1       cov.1       Covid\nAATAGAGGTGTGAGCA-1       cov.1       Covid\nGGTGGCTAGCGAATGC-1       cov.1       Covid\nTCGGGCACAGTGTGGA-1       cov.1       Covid"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_calqc",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion hemoglobin genes can give an indication of red blood cell contamination. This will be helpful to visualize them across different metadata parameteres (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\n\n# Mitochondrial genes\nmito_genes &lt;- rownames(sce)[grep(\"^MT-\", rownames(sce))]\n# Ribosomal genes\nribo_genes &lt;- rownames(sce)[grep(\"^RP[SL]\", rownames(sce))]\n# Hemoglobin genes - includes all genes starting with HB except HBP.\nhb_genes &lt;- rownames(sce)[grep(\"^HB[^(P)]\", rownames(sce))]\n\nFirst, let Scran calculate some general qc-stats for genes and cells with the function perCellQCMetrics. It can also calculate proportion of counts for specific gene subsets, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.\n\nsce &lt;- addPerCellQC(sce, flatten = T, subsets = list(mt = mito_genes, hb = hb_genes, ribo = ribo_genes))\n\n# Way2: Doing it manually\nsce@colData$percent_mito &lt;- Matrix::colSums(counts(sce)[mito_genes, ]) / sce@colData$total\n\nNow you can see that we have additional data in the metadata slot.\n\nhead(colData(sce))\n\nDataFrame with 6 rows and 15 columns\n                        sample        type       sum  detected subsets_mt_sum\n                   &lt;character&gt; &lt;character&gt; &lt;numeric&gt; &lt;integer&gt;      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1       cov.1       Covid      1396       656             26\nTAGAGTCGTCCTCCAT-1       cov.1       Covid      1613       779            186\nCCCTGATAGCGAACTG-1       cov.1       Covid      9482      2036            761\nTCATCATTCCACGTAA-1       cov.1       Covid      4357       875           2960\nATTTACCCAAGCCTGC-1       cov.1       Covid     12466      3290            686\nGTTGTCCTCTAGAACC-1       cov.1       Covid      5541      1606            707\n                   subsets_mt_detected subsets_mt_percent subsets_hb_sum\n                             &lt;integer&gt;          &lt;numeric&gt;      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                   8            1.86246              1\nTAGAGTCGTCCTCCAT-1                  10           11.53131              0\nCCCTGATAGCGAACTG-1                  11            8.02573              3\nTCATCATTCCACGTAA-1                  13           67.93665              2\nATTTACCCAAGCCTGC-1                  12            5.50297              3\nGTTGTCCTCTAGAACC-1                  12           12.75943              3\n                   subsets_hb_detected subsets_hb_percent subsets_ribo_sum\n                             &lt;integer&gt;          &lt;numeric&gt;        &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                   1          0.0716332               11\nTAGAGTCGTCCTCCAT-1                   0          0.0000000               96\nCCCTGATAGCGAACTG-1                   1          0.0316389             4157\nTCATCATTCCACGTAA-1                   2          0.0459031               99\nATTTACCCAAGCCTGC-1                   2          0.0240655             2281\nGTTGTCCTCTAGAACC-1                   2          0.0541419             1664\n                   subsets_ribo_detected subsets_ribo_percent     total\n                               &lt;integer&gt;            &lt;numeric&gt; &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                     9             0.787966      1396\nTAGAGTCGTCCTCCAT-1                    45             5.951643      1613\nCCCTGATAGCGAACTG-1                    85            43.840962      9482\nTCATCATTCCACGTAA-1                    52             2.272206      4357\nATTTACCCAAGCCTGC-1                    82            18.297770     12466\nGTTGTCCTCTAGAACC-1                    80            30.030680      5541\n                   percent_mito\n                      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1    0.0186246\nTAGAGTCGTCCTCCAT-1    0.1153131\nCCCTGATAGCGAACTG-1    0.0802573\nTCATCATTCCACGTAA-1    0.6793665\nATTTACCCAAGCCTGC-1    0.0550297\nGTTGTCCTCTAGAACC-1    0.1275943"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_plotqc",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\n# total is total UMIs per cell\n# detected is number of detected genes.\n# the different gene subset percentages are listed as subsets_mt_percent etc.\n\nwrap_plots(\n    plotColData(sce, y = \"detected\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"total\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nAs you can see, there is quite some difference in quality for the 4 datasets, with for instance the covid_15 sample having fewer cells with many detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. And we can plot the different QC-measures as scatter plots.\n\nplotColData(sce, x = \"total\", y = \"detected\", colour_by = \"sample\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_filter",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\nIn Scran, we can use the function quickPerCellQC to filter out outliers from distributions of qc stats, such as detected genes, gene subsets etc. But in this case, we will take one setting at a time and run through the steps of filtering cells.\n\ndim(sce)\n\n[1] 33538  9000\n\nselected_c &lt;- colnames(sce)[sce$detected &gt; 200]\nselected_f &lt;- rownames(sce)[Matrix::rowSums(counts(sce)) &gt; 3]\n\nsce.filt &lt;- sce[selected_f, selected_c]\ndim(sce.filt)\n\n[1] 18209  8095\n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip for now and run doublet detection instead...\n\n# high.det.v3 &lt;- sce.filt$nFeatures &gt; 4100\n# high.det.v2 &lt;- (sce.filt$nFeatures &gt; 2000) & (sce.filt$sample_id == \"v2.1k\")\n\n# remove these cells\n# sce.filt &lt;- sce.filt[ , (!high.det.v3) & (!high.det.v2)]\n\n# check number of cells\n# ncol(sce.filt)\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\nIn Scater, you can also use the function plotHighestExprs() to plot the gene contribution, but the function is quite slow.\n\n# Compute the relative expression of each gene per cell\n# Use sparse matrix operations, if your dataset is large, doing matrix devisions the regular way will take a very long time.\nC &lt;- counts(sce)\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p))\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])), cex = .1, las = 1, xlab = \"% total count per cell\", col = scales::hue_pal()(20)[20:1], horizontal = TRUE)\n\n\n\n\n\n\n\nrm(C)\n\n# also, there is the option of running the function \"plotHighestExprs\" in the scater package, however, this function takes very long to execute.\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\nselected_mito &lt;- sce.filt$subsets_mt_percent &lt; 30\nselected_ribo &lt;- sce.filt$subsets_ribo_percent &gt; 5\n\n# and subset the object to only keep those cells\nsce.filt &lt;- sce.filt[, selected_mito & selected_ribo]\ndim(sce.filt)\n\n[1] 18209  6023\n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats another time.\n\nwrap_plots(\n    plotColData(sce, y = \"detected\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"total\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis.\n\ndim(sce.filt)\n\n[1] 18209  6023\n\n# Filter MALAT1\nsce.filt &lt;- sce.filt[!grepl(\"MALAT1\", rownames(sce.filt)), ]\n\n# Filter Mitocondrial\nsce.filt &lt;- sce.filt[!grepl(\"^MT-\", rownames(sce.filt)), ]\n\n# Filter Ribossomal gene (optional if that is a problem on your data)\n# sce.filt &lt;- sce.filt[ ! grepl(\"^RP[SL]\", rownames(sce.filt)), ]\n\n# Filter Hemoglobin gene\nsce.filt &lt;- sce.filt[!grepl(\"^HB[^(P)]\", rownames(sce.filt)), ]\n\ndim(sce.filt)\n\n[1] 18183  6023"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_sex",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain you experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also bee a good way to detect if there has been any sample mixups, if the sample metadata sex does not agree with the computational predictions.\nTo get chromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. R package biomaRt can be used to fetch annotation information. The code to run biomaRt is provided. As the biomart instances quite often are unresponsive, we will download and use a file that was created in advance.\n\n# this code chunk is not executed\nsuppressMessages(library(biomaRt))\n\n# initialize connection to mart, may take some time if the sites are unresponsive.\nmart &lt;- useMart(\"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n\n# fetch chromosome info plus some other annotations\ngenes_table &lt;- try(biomaRt::getBM(attributes = c(\n    \"ensembl_gene_id\", \"external_gene_name\",\n    \"description\", \"gene_biotype\", \"chromosome_name\", \"start_position\"\n), mart = mart, useCache = F))\n\nwrite.csv(genes_table, file = \"data/results/genes_table.csv\")\n\n\ngenes_file &lt;- file.path(path_results, \"genes_table.csv\")\n\nif (!file.exists(genes_file)) download.file(file.path(path_data, \"covid/results/genes_table.csv\"), destfile = genes_file)\ngenes.table &lt;- read.csv(genes_file)\n\ngenes.table &lt;- genes.table[genes.table$external_gene_name %in% rownames(sce.filt), ]\n\nNow that we have the chromosome information, we can calculate per cell the proportion of reads that comes from chromosome Y.\n\nchrY.gene &lt;- genes.table$external_gene_name[genes.table$chromosome_name == \"Y\"]\nsce.filt@colData$pct_chrY &lt;- Matrix::colSums(counts(sce.filt)[chrY.gene, ]) / colSums(counts(sce.filt))\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\n# as plotColData cannot take an expression vs metadata, we need to add in XIST expression to colData\nsce.filt@colData$XIST &lt;- counts(sce.filt)[\"XIST\", ] / colSums(counts(sce.filt)) * 10000\nplotColData(sce.filt, \"XIST\", \"pct_chrY\")\n\n\n\n\n\n\n\n\nPlot as violins.\n\nwrap_plots(\n    plotColData(sce.filt, y = \"XIST\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"pct_chrY\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 2\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nHere, we can see clearly that we have two males and 4 females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_cellcycle",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\nhs.pairs &lt;- readRDS(system.file(\"exdata\", \"human_cycle_markers.rds\", package = \"scran\"))\nanno &lt;- select(org.Hs.eg.db, keys = rownames(sce.filt), keytype = \"SYMBOL\", column = \"ENSEMBL\")\nensembl &lt;- anno$ENSEMBL[match(rownames(sce.filt), anno$SYMBOL)]\n\n# Use only genes related to biological process cell cycle to speed up\n# https://www.ebi.ac.uk/QuickGO/term/GO:0007049 = cell cycle (BP,Biological Process)\nGOs &lt;- na.omit(select(org.Hs.eg.db, keys = na.omit(ensembl), keytype = \"ENSEMBL\", column = \"GO\"))\nGOs &lt;- GOs[GOs$GO == \"GO:0007049\", \"ENSEMBL\"]\nhs.pairs &lt;- lapply(hs.pairs, function(x) {\n    x[rowSums(apply(x, 2, function(i) i %in% GOs)) &gt;= 1, ]\n})\nstr(hs.pairs)\n\nList of 3\n $ G1 :'data.frame':    6592 obs. of  2 variables:\n  ..$ first : chr [1:6592] \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" ...\n  ..$ second: chr [1:6592] \"ENSG00000065135\" \"ENSG00000080345\" \"ENSG00000101266\" \"ENSG00000135679\" ...\n $ S  :'data.frame':    8284 obs. of  2 variables:\n  ..$ first : chr [1:8284] \"ENSG00000255302\" \"ENSG00000119969\" \"ENSG00000179051\" \"ENSG00000127586\" ...\n  ..$ second: chr [1:8284] \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000136856\" ...\n $ G2M:'data.frame':    6200 obs. of  2 variables:\n  ..$ first : chr [1:6200] \"ENSG00000100519\" \"ENSG00000136856\" \"ENSG00000136856\" \"ENSG00000136856\" ...\n  ..$ second: chr [1:6200] \"ENSG00000146457\" \"ENSG00000227268\" \"ENSG00000101265\" \"ENSG00000117676\" ...\n\ncc.ensembl &lt;- ensembl[ensembl %in% GOs] # This is the fastest (less genes), but less accurate too\n# cc.ensembl &lt;- ensembl[ ensembl %in% unique(unlist(hs.pairs))]\n\nassignments &lt;- cyclone(sce.filt[ensembl %in% cc.ensembl, ], hs.pairs, gene.names = ensembl[ensembl %in% cc.ensembl])\nsce.filt$G1.score &lt;- assignments$scores$G1\nsce.filt$G2M.score &lt;- assignments$scores$G2M\nsce.filt$S.score &lt;- assignments$scores$S\n\nWe can now plot a violin plot for the cell cycle scores as well.\n\nwrap_plots(\n    plotColData(sce.filt, y = \"G2M.score\", x = \"G1.score\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"G2M.score\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"G1.score\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"S.score\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 4\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nCyclone predicts most cells as G1, but also quite a lot of cells with high S-Phase scores. Compare to results with Seurat and Scanpy and see how different predictors will give clearly different results."
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_doublet",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\n\n\n\n\n\n\nCaution\n\n\n\nIdeally doublet prediction should be run on each sample separately, especially if your different samples have different proportions of cell types. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs so it is okay to run them together.\n\n\nThere is a method to predict if a cluster consists of mainly doublets findDoubletClusters(), but we can also predict individual cells based on simulations using the function computeDoubletDensity() which we will do here. Doublet detection will be performed using PCA, so we need to first normalize the data and run variable gene detection, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.\n\nsce.filt &lt;- logNormCounts(sce.filt)\ndec &lt;- modelGeneVar(sce.filt, block = sce.filt$sample)\nhvgs &lt;- getTopHVGs(dec, n = 2000)\n\nsce.filt &lt;- runPCA(sce.filt, subset_row = hvgs)\n\nsce.filt &lt;- runUMAP(sce.filt, pca = 10)\n\n\nsuppressPackageStartupMessages(library(scDblFinder))\n\n# run computeDoubletDensity with 10 principal components.\nsce.filt &lt;- scDblFinder(sce.filt, dims = 10)\n\n\nwrap_plots(\n    plotUMAP(sce.filt, colour_by = \"scDblFinder.score\"),\n    plotUMAP(sce.filt, colour_by = \"scDblFinder.class\"),\n    plotUMAP(sce.filt, colour_by = \"sample\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\nsce.filt &lt;- sce.filt[, sce.filt$scDblFinder.score &lt; 2]\ndim(sce.filt)\n\n[1] 18183  6023"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_save",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory results and save data to that folder. This will be used in downstream labs.\n\nsaveRDS(sce.filt, file.path(path_results, \"bioc_covid_qc.rds\"))"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-session",
    "href": "labs/bioc/bioc_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] scDblFinder_1.16.0          org.Hs.eg.db_3.18.0        \n [3] AnnotationDbi_1.64.1        patchwork_1.1.2            \n [5] scran_1.30.0                scater_1.30.1              \n [7] ggplot2_3.4.2               scuttle_1.12.0             \n [9] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n[11] Biobase_2.62.0              GenomicRanges_1.54.1       \n[13] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[15] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[17] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.20          splines_4.3.0            \n  [3] later_1.3.1               BiocIO_1.12.0            \n  [5] bitops_1.0-7              tibble_3.2.1             \n  [7] polyclip_1.10-4           XML_3.99-0.14            \n  [9] lifecycle_1.0.3           edgeR_4.0.7              \n [11] hdf5r_1.3.8               globals_0.16.2           \n [13] lattice_0.21-8            MASS_7.3-58.4            \n [15] magrittr_2.0.3            limma_3.58.1             \n [17] plotly_4.10.2             rmarkdown_2.22           \n [19] yaml_2.3.7                metapod_1.10.1           \n [21] httpuv_1.6.11             Seurat_4.3.0             \n [23] sctransform_0.3.5         sp_1.6-1                 \n [25] spatstat.sparse_3.0-1     reticulate_1.30          \n [27] cowplot_1.1.1             pbapply_1.7-0            \n [29] DBI_1.1.3                 RColorBrewer_1.1-3       \n [31] abind_1.4-5               zlibbioc_1.48.0          \n [33] Rtsne_0.16                purrr_1.0.1              \n [35] RCurl_1.98-1.12           GenomeInfoDbData_1.2.11  \n [37] ggrepel_0.9.3             irlba_2.3.5.1            \n [39] listenv_0.9.0             spatstat.utils_3.0-3     \n [41] goftest_1.2-3             spatstat.random_3.1-5    \n [43] dqrng_0.3.0               fitdistrplus_1.1-11      \n [45] parallelly_1.36.0         DelayedMatrixStats_1.24.0\n [47] leiden_0.4.3              codetools_0.2-19         \n [49] DelayedArray_0.28.0       tidyselect_1.2.0         \n [51] farver_2.1.1              ScaledMatrix_1.10.0      \n [53] viridis_0.6.3             spatstat.explore_3.2-1   \n [55] GenomicAlignments_1.38.1  jsonlite_1.8.5           \n [57] BiocNeighbors_1.20.2      ellipsis_0.3.2           \n [59] progressr_0.13.0          ggridges_0.5.4           \n [61] survival_3.5-5            tools_4.3.0              \n [63] ica_1.0-3                 Rcpp_1.0.10              \n [65] glue_1.6.2                gridExtra_2.3            \n [67] SparseArray_1.2.3         xfun_0.39                \n [69] dplyr_1.1.2               withr_2.5.0              \n [71] fastmap_1.1.1             bluster_1.12.0           \n [73] fansi_1.0.4               digest_0.6.31            \n [75] rsvd_1.0.5                R6_2.5.1                 \n [77] mime_0.12                 colorspace_2.1-0         \n [79] scattermore_1.2           tensor_1.5               \n [81] spatstat.data_3.0-1       RSQLite_2.3.1            \n [83] utf8_1.2.3                tidyr_1.3.0              \n [85] generics_0.1.3            data.table_1.14.8        \n [87] rtracklayer_1.62.0        httr_1.4.6               \n [89] htmlwidgets_1.6.2         S4Arrays_1.2.0           \n [91] uwot_0.1.14               pkgconfig_2.0.3          \n [93] gtable_0.3.3              blob_1.2.4               \n [95] lmtest_0.9-40             XVector_0.42.0           \n [97] htmltools_0.5.5           SeuratObject_4.1.3       \n [99] scales_1.2.1              png_0.1-8                \n[101] knitr_1.43                rstudioapi_0.14          \n[103] rjson_0.2.21              reshape2_1.4.4           \n[105] nlme_3.1-162              cachem_1.0.8             \n[107] zoo_1.8-12                stringr_1.5.0            \n[109] KernSmooth_2.23-20        parallel_4.3.0           \n[111] miniUI_0.1.1.1            vipor_0.4.5              \n[113] restfulr_0.0.15           pillar_1.9.0             \n[115] grid_4.3.0                vctrs_0.6.2              \n[117] RANN_2.6.1                promises_1.2.0.1         \n[119] BiocSingular_1.18.0       beachmat_2.18.0          \n[121] xtable_1.8-4              cluster_2.1.4            \n[123] beeswarm_0.4.0            evaluate_0.21            \n[125] Rsamtools_2.18.0          cli_3.6.1                \n[127] locfit_1.5-9.8            compiler_4.3.0           \n[129] rlang_1.1.1               crayon_1.5.2             \n[131] future.apply_1.11.0       labeling_0.4.2           \n[133] plyr_1.8.8                ggbeeswarm_0.7.2         \n[135] stringi_1.7.12            deldir_1.0-9             \n[137] viridisLite_0.4.2         BiocParallel_1.36.0      \n[139] munsell_0.5.0             Biostrings_2.70.1        \n[141] lazyeval_0.2.2            spatstat.geom_3.2-1      \n[143] Matrix_1.5-4              sparseMatrixStats_1.14.0 \n[145] bit64_4.0.5               future_1.32.0            \n[147] KEGGREST_1.42.0           statmod_1.5.0            \n[149] shiny_1.7.4               ROCR_1.0-11              \n[151] igraph_1.4.3              memoise_2.0.1            \n[153] xgboost_1.7.5.1           bit_4.0.5"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html",
    "href": "labs/bioc/bioc_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_prep",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(umap)\n})\n\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/bioc_covid_qc.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/bioc_covid_qc.rds\"), destfile = path_file)\nsce &lt;- readRDS(path_file)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_fs",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nNext, we first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\n\nsce &lt;- computeSumFactors(sce, sizes = c(20, 40, 60, 80))\nsce &lt;- logNormCounts(sce)\nvar.out &lt;- modelGeneVar(sce, method = \"loess\")\nhvgs &lt;- getTopHVGs(var.out, n = 2000)\n\npar(mfrow = c(1, 2))\n# plot mean over TOTAL variance\n# Visualizing the fit:\nfit.var &lt;- metadata(var.out)\n{\n    plot(fit.var$mean, fit.var$var,\n        xlab = \"Mean of log-expression\",\n        ylab = \"Variance of log-expression\"\n    )\n    curve(fit.var$trend(x), col = \"dodgerblue\", add = TRUE, lwd = 2)\n\n    # Select 1000 top variable genes\n    hvg.out &lt;- getTopHVGs(var.out, n = 1000)\n\n    # highligt those cells in the plot\n    cutoff &lt;- rownames(var.out) %in% hvg.out\n    points(fit.var$mean[cutoff], fit.var$var[cutoff], col = \"red\", pch = 16, cex = .6)\n}\n\n{\n    # plot mean over BIOLOGICAL variance\n    plot(var.out$mean, var.out$bio, pch = 16, cex = 0.4, xlab = \"Mean log-expression\", ylab = \"Variance of log-expression\")\n    lines(c(min(var.out$mean), max(var.out$mean)), c(0, 0), col = \"dodgerblue\", lwd = 2)\n    points(var.out$mean[cutoff], var.out$bio[cutoff], col = \"red\", pch = 16, cex = .6)\n}"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_zs",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the data is prepared, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling is called Z-score normalization it is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\nHowever, unlike the Seurat, this step is implemented inside the PCA function below. Here we will show you how to add the scaledData back to the object.\n\n# sce@assays$data@listData$scaled.data &lt;- apply(exprs(sce)[rownames(hvg.out),,drop=FALSE],2,function(x) scale(x,T,T))\n# rownames(sce@assays$data@listData$scaled.data) &lt;- rownames(hvg.out)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_pca",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of life sciences, we want to segregate samples based on gene expression patterns in the data.\nWe use the logcounts and then set scale_features to TRUE in order to scale each gene.\n\n# runPCA and specify the variable genes to use for dim reduction with subset_row\nsce &lt;- runPCA(sce, exprs_values = \"logcounts\", ncomponents = 50, subset_row = hvg.out, scale = TRUE)\n\nWe then plot the first principal components.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 1:2, point_size = 0.6),\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 3:4, point_size = 0.6),\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 5:6, point_size = 0.6),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nTo identify which genes (Seurat) or metadata parameters (Scater/Scran) contribute the most to each PC, one can retrieve the loading matrix information. Unfortunately, this is not implemented in Scater/Scran, so you will need to compute PCA using logcounts.\n\nplotExplanatoryPCs(sce)\n\n\n\n\n\n\n\n\nWe can also plot the amount of variance explained by each PC.\n\nplot(attr(reducedDim(sce, \"PCA\"), \"percentVar\")[1:50] * 100, type = \"l\", ylab = \"% variance\", xlab = \"Principal component #\")\npoints(attr(reducedDim(sce, \"PCA\"), \"percentVar\")[1:50] * 100, pch = 21, bg = \"grey\", cex = .5)\n\n\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_tsne",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe can now run BH-tSNE.\n\nset.seed(42)\nsce &lt;- runTSNE(sce, dimred = \"PCA\", n_dimred = 30, perplexity = 30, name = \"tSNE_on_PCA\")\n\nWe can now plot the tSNE colored per dataset. We can clearly see the effect of batches present in the dataset.\n\nplotReducedDim(sce, dimred = \"tSNE_on_PCA\", colour_by = \"sample\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_umap",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nWe can now run UMAP for cell embeddings.\n\nsce &lt;- runUMAP(sce, dimred = \"PCA\", n_dimred = 30, ncomponents = 2, name = \"UMAP_on_PCA\")\n# see ?umap and ?runUMAP for more info\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\nsce &lt;- runUMAP(sce, dimred = \"PCA\", n_dimred = 30, ncomponents = 10, name = \"UMAP10_on_PCA\")\n# see ?umap and ?runUMAP for more info\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE, what similarities/differences do you see, can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP10_on_PCA\", colour_by = \"sample\", ncomponents = 1:2) +\n        ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP10_on_PCA\", colour_by = \"sample\", ncomponents = 3:4) +\n        ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_zsg",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_zsg",
    "title": " Dimensionality Reduction",
    "section": "7 Z-scores & DR graphs",
    "text": "7 Z-scores & DR graphs\nAlthough running a second dimensionality reduction (i.e tSNE or UMAP) on PCA would be a standard approach (because it allows higher computation efficiency), the options are actually limitless. Below we will show a couple of other common options such as running directly on the scaled data (z-scores) (which was used for PCA) or on a graph built from scaled data. We will show from now on only UMAP, but the same applies for tSNE.\n\n7.1 UMAP from z-scores\nTo run tSNE or UMAP on the scaled data, one first needs to select the number of variables to use. This is because including dimensions that do contribute to the separation of your cell types will in the end mask those differences. Another reason for it is because running with all genes/features also will take longer or might be computationally unfeasible. Therefore we will use the scaled data of the highly variable genes.\n\nsce &lt;- runUMAP(sce, exprs_values = \"logcounts\", name = \"UMAP_on_ScaleData\")\n\n\n\n7.2 UMAP from graph\nTo run tSNE or UMAP on the a graph, we first need to build a graph from the data. In fact, both tSNE and UMAP first build a graph from the data using a specified distance matrix and then optimize the embedding. Since a graph is just a matrix containing distances from cell to cell and as such, you can run either UMAP or tSNE using any other distance metric desired. Euclidean and Correlation are usually the most commonly used.\n\n# Build Graph\nnn &lt;- RANN::nn2(reducedDim(sce, \"PCA\"), k = 30)\nnames(nn) &lt;- c(\"idx\", \"dist\")\ng &lt;- buildKNNGraph(sce, k = 30, use.dimred = \"PCA\")\nreducedDim(sce, \"KNN\") &lt;- igraph::as_adjacency_matrix(g)\n\n# Run UMAP and rename it for comparisson\n# temp &lt;- umap::umap.defaults\ntry(reducedDim(sce, \"UMAP_on_Graph\") &lt;- NULL)\nreducedDim(sce, \"UMAP_on_Graph\") &lt;- uwot::umap(X = NULL, n_components = 2, nn_method = nn)\n\nWe can now plot the UMAP comparing both on PCA vs ScaledSata vs Graph.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_ScaleData\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_ScaleData\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Graph\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_Graph\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "8 Genes of interest",
    "text": "8 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nplotlist &lt;- list()\nfor (i in c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")) {\n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = i, by_exprs_values = \"logcounts\") +\n        scale_fill_gradientn(colours = colorRampPalette(c(\"grey90\", \"orange3\", \"firebrick\", \"firebrick\", \"red\", \"red\"))(10)) +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_save",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "9 Save data",
    "text": "9 Save data\nWe can finally save the object for use in future steps.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-session",
    "href": "labs/bioc/bioc_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] umap_0.2.10.0               patchwork_1.1.2            \n [3] scran_1.30.0                scater_1.30.1              \n [5] ggplot2_3.4.2               scuttle_1.12.0             \n [7] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [9] Biobase_2.62.0              GenomicRanges_1.54.1       \n[11] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[13] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[15] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-7              gridExtra_2.3            \n [3] rlang_1.1.1               magrittr_2.0.3           \n [5] RcppAnnoy_0.0.20          compiler_4.3.0           \n [7] DelayedMatrixStats_1.24.0 png_0.1-8                \n [9] vctrs_0.6.2               pkgconfig_2.0.3          \n[11] crayon_1.5.2              fastmap_1.1.1            \n[13] XVector_0.42.0            labeling_0.4.2           \n[15] utf8_1.2.3                rmarkdown_2.22           \n[17] ggbeeswarm_0.7.2          xfun_0.39                \n[19] bluster_1.12.0            zlibbioc_1.48.0          \n[21] beachmat_2.18.0           jsonlite_1.8.5           \n[23] DelayedArray_0.28.0       BiocParallel_1.36.0      \n[25] irlba_2.3.5.1             parallel_4.3.0           \n[27] cluster_2.1.4             R6_2.5.1                 \n[29] limma_3.58.1              reticulate_1.30          \n[31] Rcpp_1.0.10               knitr_1.43               \n[33] Matrix_1.5-4              igraph_1.4.3             \n[35] tidyselect_1.2.0          rstudioapi_0.14          \n[37] abind_1.4-5               yaml_2.3.7               \n[39] viridis_0.6.3             codetools_0.2-19         \n[41] lattice_0.21-8            tibble_3.2.1             \n[43] withr_2.5.0               askpass_1.1              \n[45] evaluate_0.21             Rtsne_0.16               \n[47] pillar_1.9.0              generics_0.1.3           \n[49] RCurl_1.98-1.12           sparseMatrixStats_1.14.0 \n[51] munsell_0.5.0             scales_1.2.1             \n[53] glue_1.6.2                metapod_1.10.1           \n[55] tools_4.3.0               BiocNeighbors_1.20.2     \n[57] ScaledMatrix_1.10.0       RSpectra_0.16-1          \n[59] locfit_1.5-9.8            RANN_2.6.1               \n[61] cowplot_1.1.1             grid_4.3.0               \n[63] edgeR_4.0.7               colorspace_2.1-0         \n[65] GenomeInfoDbData_1.2.11   beeswarm_0.4.0           \n[67] BiocSingular_1.18.0       vipor_0.4.5              \n[69] cli_3.6.1                 rsvd_1.0.5               \n[71] fansi_1.0.4               S4Arrays_1.2.0           \n[73] viridisLite_0.4.2         dplyr_1.1.2              \n[75] uwot_0.1.14               gtable_0.3.3             \n[77] digest_0.6.31             SparseArray_1.2.3        \n[79] ggrepel_0.9.3             dqrng_0.3.0              \n[81] htmlwidgets_1.6.2         farver_2.1.1             \n[83] htmltools_0.5.5           lifecycle_1.0.3          \n[85] statmod_1.5.0             openssl_2.0.6"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html",
    "href": "labs/bioc/bioc_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-int_prep",
    "href": "labs/bioc/bioc_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(batchelor)\n    library(harmony)\n    library(reticulate)\n})\n\n# Activate scanorama Python venv\nreticulate::use_virtualenv(\"/opt/venv/scanorama\")\nreticulate::py_discover_config()\n\npython:         /opt/venv/scanorama/bin/python\nlibpython:      /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so\npythonhome:     /opt/venv/scanorama:/opt/venv/scanorama\nversion:        3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\nnumpy:          /opt/venv/scanorama/lib/python3.10/site-packages/numpy\nnumpy_version:  1.26.3\n\nNOTE: Python version was forced by use_python function\n\n\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/bioc_covid_qc_dr.rds\"), destfile = path_file)\nsce &lt;- readRDS(path_file)\nprint(reducedDims(sce))\n\nList of length 8\nnames(8): PCA UMAP tSNE_on_PCA ... UMAP_on_ScaleData KNN UMAP_on_Graph\n\n\nWe split the combined object into a list, with each dataset as an element. We perform standard preprocessing (log-normalization), and identify variable features individually for each dataset based on a variance stabilizing transformation (vst).\n\nsce.list &lt;- lapply(unique(sce$sample), function(x) {\n    x &lt;- sce[, sce$sample == x]\n})\n\nhvgs_per_dataset &lt;- lapply(sce.list, function(x) {\n    x &lt;- computeSumFactors(x, sizes = c(20, 40, 60, 80))\n    x &lt;- logNormCounts(x)\n    var.out &lt;- modelGeneVar(x, method = \"loess\")\n    hvg.out &lt;- var.out[which(var.out$FDR &lt;= 0.05 & var.out$bio &gt;= 0.2), ]\n    hvg.out &lt;- hvg.out[order(hvg.out$bio, decreasing = TRUE), ]\n    return(rownames(hvg.out))\n})\nnames(hvgs_per_dataset) &lt;- unique(sce$sample)\n\n# venn::venn(hvgs_per_dataset,opacity = .4,zcolor = scales::hue_pal()(3),cexsn = 1,cexil = 1,lwd=1,col=\"white\",borders = NA)\n\ntemp &lt;- unique(unlist(hvgs_per_dataset))\noverlap &lt;- sapply(hvgs_per_dataset, function(x) {\n    temp %in% x\n})\n\n\npheatmap::pheatmap(t(overlap * 1), cluster_rows = F, color = c(\"grey90\", \"grey20\")) ## MNN\n\n\n\n\n\n\n\n\nThe mutual nearest neighbors (MNN) approach within the scran package utilizes a novel approach to adjust for batch effects. The fastMNN() function returns a representation of the data with reduced dimensionality, which can be used in a similar fashion to other lower-dimensional representations such as PCA. In particular, this representation can be used for downstream methods such as clustering. The BNPARAM can be used to specify the specific nearest neighbors method to use from the BiocNeighbors package. Here we make use of the Annoy library via the BiocNeighbors::AnnoyParam() argument. We save the reduced-dimension MNN representation into the reducedDims slot of our sce object.\n\nmnn_out &lt;- batchelor::fastMNN(sce, subset.row = unique(unlist(hvgs_per_dataset)), batch = factor(sce$sample), k = 20, d = 50)\n\n\n\n\n\n\n\nCaution\n\n\n\nfastMNN() does not produce a batch-corrected expression matrix.\n\n\n\nmnn_out &lt;- t(reducedDim(mnn_out, \"corrected\"))\ncolnames(mnn_out) &lt;- unlist(lapply(sce.list, function(x) {\n    colnames(x)\n}))\nmnn_out &lt;- mnn_out[, colnames(sce)]\nrownames(mnn_out) &lt;- paste0(\"dim\", 1:50)\nreducedDim(sce, \"MNN\") &lt;- t(mnn_out)\n\nWe can observe that a new assay slot is now created under the name MNN.\n\nreducedDims(sce)\n\nList of length 9\nnames(9): PCA UMAP tSNE_on_PCA UMAP_on_PCA ... KNN UMAP_on_Graph MNN\n\n\nThus, the result from fastMNN() should solely be treated as a reduced dimensionality representation, suitable for direct plotting, TSNE/UMAP, clustering, and trajectory analysis that relies on such results.\n\nset.seed(42)\nsce &lt;- runTSNE(sce, dimred = \"MNN\", n_dimred = 50, perplexity = 30, name = \"tSNE_on_MNN\")\nsce &lt;- runUMAP(sce, dimred = \"MNN\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_MNN\")\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"PCA\"),\n    plotReducedDim(sce, dimred = \"tSNE_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"tSNE_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"MNN\"),\n    plotReducedDim(sce, dimred = \"tSNE_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"tSNE_on_MNN\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_MNN\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nplotlist &lt;- list()\nfor (i in c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")) {\n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = i, by_exprs_values = \"logcounts\", point_size = 0.6) +\n        scale_fill_gradientn(colours = colorRampPalette(c(\"grey90\", \"orange3\", \"firebrick\", \"firebrick\", \"red\", \"red\"))(10)) +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist = plotlist, ncol = 3)\n\n\n\n\n\n\n\n\nINTEG_R1:\nINTEG_R2:\n\nlibrary(harmony)\n\nreducedDimNames(sce)\n\n [1] \"PCA\"               \"UMAP\"              \"tSNE_on_PCA\"      \n [4] \"UMAP_on_PCA\"       \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\"\n [7] \"KNN\"               \"UMAP_on_Graph\"     \"MNN\"              \n[10] \"tSNE_on_MNN\"       \"UMAP_on_MNN\"      \n\nsce &lt;- RunHarmony(\n    sce,\n    group.by.vars = \"sample\",\n    reduction.save = \"harmony\",\n    reduction = \"PCA\",\n    dims.use = 1:50\n)\n\n# Here we use all PCs computed from Harmony for UMAP calculation\nsce &lt;- runUMAP(sce, dimred = \"harmony\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_Harmony\")\n\nINTEG_R3:\nINTEG_R4:\n\nhvgs &lt;- unique(unlist(hvgs_per_dataset))\n\nscelist &lt;- list()\ngenelist &lt;- list()\nfor (i in 1:length(sce.list)) {\n    scelist[[i]] &lt;- t(as.matrix(logcounts(sce.list[[i]])[hvgs, ]))\n    genelist[[i]] &lt;- hvgs\n}\n\nlapply(scelist, dim)\n\n[[1]]\n[1] 923 454\n\n[[2]]\n[1] 611 454\n\n[[3]]\n[1] 1111  454\n\n[[4]]\n[1] 1067  454\n\n[[5]]\n[1] 1203  454\n\n[[6]]\n[1] 1108  454\n\n\nINTEG_R5:\n\nscanorama &lt;- reticulate::import(\"scanorama\")\n\nintegrated.data &lt;- scanorama$integrate(datasets_full = scelist, genes_list = genelist)\n\nintdimred &lt;- do.call(rbind, integrated.data[[1]])\ncolnames(intdimred) &lt;- paste0(\"PC_\", 1:100)\nrownames(intdimred) &lt;- colnames(logcounts(sce))\n\n# Add standard deviations in order to draw Elbow Plots in Seurat\nstdevs &lt;- apply(intdimred, MARGIN = 2, FUN = sd)\nattr(intdimred, \"varExplained\") &lt;- stdevs\n\nreducedDim(sce, \"Scanorama_PCA\") &lt;- intdimred\n\n# Here we use all PCs computed from Scanorama for UMAP calculation\nsce &lt;- runUMAP(sce, dimred = \"Scanorama_PCA\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_Scanorama\")\n\nINTEG_R6:\n\np1 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_PCA\")\np2 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_MNN\")\np3 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Harmony\")\np4 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_Scanorama\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Scanorama\")\n\nwrap_plots(p1, p2, p3, p4, nrow = 2) +\n    plot_layout(guides = \"collect\")\n\nINTEG_R7:\nLet’s save the integrated data for further analysis.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr_int.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-session",
    "href": "labs/bioc/bioc_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "2 Session info",
    "text": "2 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] reticulate_1.30             harmony_1.2.0              \n [3] Rcpp_1.0.10                 batchelor_1.18.1           \n [5] patchwork_1.1.2             scran_1.30.0               \n [7] scater_1.30.1               ggplot2_3.4.2              \n [9] scuttle_1.12.0              SingleCellExperiment_1.24.0\n[11] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[13] GenomicRanges_1.54.1        GenomeInfoDb_1.38.5        \n[15] IRanges_2.36.0              S4Vectors_0.40.2           \n[17] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[19] matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-7              gridExtra_2.3            \n [3] rlang_1.1.1               magrittr_2.0.3           \n [5] RcppAnnoy_0.0.20          compiler_4.3.0           \n [7] DelayedMatrixStats_1.24.0 png_0.1-8                \n [9] vctrs_0.6.2               pkgconfig_2.0.3          \n[11] crayon_1.5.2              fastmap_1.1.1            \n[13] XVector_0.42.0            labeling_0.4.2           \n[15] utf8_1.2.3                rmarkdown_2.22           \n[17] ggbeeswarm_0.7.2          xfun_0.39                \n[19] bluster_1.12.0            zlibbioc_1.48.0          \n[21] beachmat_2.18.0           jsonlite_1.8.5           \n[23] DelayedArray_0.28.0       BiocParallel_1.36.0      \n[25] irlba_2.3.5.1             parallel_4.3.0           \n[27] cluster_2.1.4             R6_2.5.1                 \n[29] RColorBrewer_1.1-3        limma_3.58.1             \n[31] knitr_1.43                Matrix_1.5-4             \n[33] igraph_1.4.3              tidyselect_1.2.0         \n[35] rstudioapi_0.14           abind_1.4-5              \n[37] yaml_2.3.7                viridis_0.6.3            \n[39] codetools_0.2-19          lattice_0.21-8           \n[41] tibble_3.2.1              withr_2.5.0              \n[43] evaluate_0.21             Rtsne_0.16               \n[45] pillar_1.9.0              generics_0.1.3           \n[47] rprojroot_2.0.3           RCurl_1.98-1.12          \n[49] sparseMatrixStats_1.14.0  munsell_0.5.0            \n[51] scales_1.2.1              RhpcBLASctl_0.23-42      \n[53] glue_1.6.2                metapod_1.10.1           \n[55] pheatmap_1.0.12           tools_4.3.0              \n[57] BiocNeighbors_1.20.2      ScaledMatrix_1.10.0      \n[59] locfit_1.5-9.8            cowplot_1.1.1            \n[61] grid_4.3.0                edgeR_4.0.7              \n[63] colorspace_2.1-0          GenomeInfoDbData_1.2.11  \n[65] beeswarm_0.4.0            BiocSingular_1.18.0      \n[67] vipor_0.4.5               cli_3.6.1                \n[69] rsvd_1.0.5                fansi_1.0.4              \n[71] S4Arrays_1.2.0            viridisLite_0.4.2        \n[73] dplyr_1.1.2               uwot_0.1.14              \n[75] ResidualMatrix_1.12.0     gtable_0.3.3             \n[77] digest_0.6.31             SparseArray_1.2.3        \n[79] ggrepel_0.9.3             dqrng_0.3.0              \n[81] farver_2.1.1              htmlwidgets_1.6.2        \n[83] htmltools_0.5.5           lifecycle_1.0.3          \n[85] here_1.0.1                statmod_1.5.0"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html",
    "href": "labs/bioc/bioc_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will continue the analysis of the integrated dataset. We will use the integrated PCA to perform the clustering. First we will construct a \\(k\\)-nearest neighbor graph in order to perform a clustering on the graph. We will also show how to perform hierarchical clustering and k-means clustering on PCA space.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(igraph)\n    library(clustree)\n})\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr_int.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/bioc_covid_qc_dr_int.rds\"), destfile = path_file)\nsce &lt;- readRDS(path_file)\nprint(reducedDims(sce))\n\nList of length 13\nnames(13): PCA UMAP tSNE_on_PCA ... UMAP_on_MNN harmony UMAP_on_Harmony"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_graphclust",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps: 1) Build a kNN graph from the data. 2) Prune spurious connections from kNN graph (optional step). This is a SNN graph. 3) Find groups of cells that maximizes the connections within the group compared other groups.\n\n1.1 Building kNN / SNN graph\nThe first step into graph clustering is to construct a k-nn graph, in case you don’t have one. For this, we will use the PCA space. Thus, as done for dimensionality reduction, we will use ony the top N PCA dimensions for this purpose (the same used for computing UMAP / tSNE).\n\n# These 2 lines are for demonstration purposes only\ng &lt;- buildKNNGraph(sce, k = 30, use.dimred = \"MNN\")\nreducedDim(sce, \"KNN\") &lt;- igraph::as_adjacency_matrix(g)\n\n# These 2 lines are the most recommended\ng &lt;- buildSNNGraph(sce, k = 30, use.dimred = \"MNN\")\nreducedDim(sce, \"SNN\") &lt;- as_adjacency_matrix(g, attr = \"weight\")\n\nWe can take a look at the kNN and SNN graphs. The kNN graph is a matrix where every connection between cells is represented as \\(1\\)s. This is called a unweighted graph (default in Seurat). In the SNN graph on the other hand, Some cell connections have more importance than others, in that case the scale of the graph from \\(0\\) to a maximum distance (in this case \\(1\\)). Usually, the smaller the distance, the closer two points are, and stronger is their connection. This is called a weighted graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (&gt; 100k cells).\n\n# plot the KNN graph\npheatmap(reducedDim(sce, \"KNN\")[1:200, 1:200],\n    col = c(\"white\", \"black\"), border_color = \"grey90\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n# or the SNN graph\npheatmap(reducedDim(sce, \"SNN\")[1:200, 1:200],\n    col = colorRampPalette(c(\"white\", \"yellow\", \"red\", \"black\"))(20),\n    border_color = \"grey90\",\n    legend = T, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n\nAs you can see, the way Scran computes the SNN graph is different to Seurat. It gives edges to all cells that shares a neighbor, but weights the edges by how similar the neighbors are. Hence, the SNN graph has more edges than the KNN graph.\n\n\n1.2 Clustering on a graph\nOnce the graph is built, we can now perform graph clustering. The clustering is done respective to a resolution which can be interpreted as how coarse you want your cluster to be. Higher resolution means higher number of clusters.\n\ng &lt;- buildSNNGraph(sce, k = 5, use.dimred = \"MNN\")\nsce$louvain_SNNk5 &lt;- factor(cluster_louvain(g)$membership)\n\ng &lt;- buildSNNGraph(sce, k = 10, use.dimred = \"MNN\")\nsce$louvain_SNNk10 &lt;- factor(cluster_louvain(g)$membership)\n\ng &lt;- buildSNNGraph(sce, k = 15, use.dimred = \"MNN\")\nsce$louvain_SNNk15 &lt;- factor(cluster_louvain(g)$membership)\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"louvain_SNNk5\") +\n        ggplot2::ggtitle(label = \"louvain_SNNk5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"louvain_SNNk10\") +\n        ggplot2::ggtitle(label = \"louvain_SNNk10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"louvain_SNNk15\") +\n        ggplot2::ggtitle(label = \"louvain_SNNk15\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe can now use the clustree package to visualize how cells are distributed between clusters depending on resolution.\n\nsuppressPackageStartupMessages(library(clustree))\nclustree(sce, prefix = \"louvain_SNNk\")"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_kmean",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\nsce$kmeans_5 &lt;- factor(kmeans(x = reducedDim(sce, \"MNN\"), centers = 5)$cluster)\nsce$kmeans_10 &lt;- factor(kmeans(x = reducedDim(sce, \"MNN\"), centers = 10)$cluster)\nsce$kmeans_15 &lt;- factor(kmeans(x = reducedDim(sce, \"MNN\"), centers = 15)$cluster)\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"kmeans_5\") +\n        ggplot2::ggtitle(label = \"KMeans5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"kmeans_10\") +\n        ggplot2::ggtitle(label = \"KMeans10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"kmeans_15\") +\n        ggplot2::ggtitle(label = \"KMeans15\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\n\nclustree(sce, prefix = \"kmeans_\")"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_hier",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\n\n3.1 Defining distance between cells\nThe base R stats package already contains a function dist that calculates distances between all pairs of samples. Since we want to compute distances between samples, rather than among genes, we need to transpose the data before applying it to the dist function. This can be done by simply adding the transpose function t() to the data. The distance methods available in dist are: ‘euclidean’, ‘maximum’, ‘manhattan’, ‘canberra’, ‘binary’ or ‘minkowski’.\n\nd &lt;- dist(reducedDim(sce, \"MNN\"), method = \"euclidean\")\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n[adj = ]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\n\n# Compute sample correlations\nsample_cor &lt;- cor(Matrix::t(reducedDim(sce, \"MNN\")))\n\n# Transform the scale from correlations\nsample_cor &lt;- (1 - sample_cor) / 2\n\n# Convert it to a distance object\nd2 &lt;- as.dist(sample_cor)\n\n\n\n3.2 Clustering cells\nAfter having calculated the distances between samples calculated, we can now proceed with the hierarchical clustering per-se. We will use the function hclust for this purpose, in which we can simply run it with the distance objects created above. The methods available are: ‘ward.D’, ‘ward.D2’, ‘single’, ‘complete’, ‘average’, ‘mcquitty’, ‘median’ or ‘centroid’. It is possible to plot the dendrogram for all cells, but this is very time consuming and we will omit for this tutorial.\n\n# euclidean\nh_euclidean &lt;- hclust(d, method = \"ward.D2\")\n\n# correlation\nh_correlation &lt;- hclust(d2, method = \"ward.D2\")\n\nOnce your dendrogram is created, the next step is to define which samples belong to a particular cluster. After identifying the dendrogram, we can now literally cut the tree at a fixed threshold (with cutree) at different levels to define the clusters. We can either define the number of clusters or decide on a height. We can simply try different clustering levels.\n\n# euclidean distance\nsce$hc_euclidean_5 &lt;- factor(cutree(h_euclidean, k = 5))\nsce$hc_euclidean_10 &lt;- factor(cutree(h_euclidean, k = 10))\nsce$hc_euclidean_15 &lt;- factor(cutree(h_euclidean, k = 15))\n\n# correlation distance\nsce$hc_corelation_5 &lt;- factor(cutree(h_correlation, k = 5))\nsce$hc_corelation_10 &lt;- factor(cutree(h_correlation, k = 10))\nsce$hc_corelation_15 &lt;- factor(cutree(h_correlation, k = 15))\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_euclidean_5\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_euclidean_10\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_euclidean_15\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_15\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_corelation_5\") +\n        ggplot2::ggtitle(label = \"HC_correlation_5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_corelation_10\") +\n        ggplot2::ggtitle(label = \"HC_correlation_10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"hc_corelation_15\") +\n        ggplot2::ggtitle(label = \"HC_correlation_15\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr_int_cl.rds\")\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated due to quality metrics. Could it be explained biologically, or could you have technical bias there?"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-session",
    "href": "labs/bioc/bioc_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "4 Session info",
    "text": "4 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] clustree_0.5.0              ggraph_2.1.0               \n [3] igraph_1.4.3                pheatmap_1.0.12            \n [5] patchwork_1.1.2             scran_1.30.0               \n [7] scater_1.30.1               ggplot2_3.4.2              \n [9] scuttle_1.12.0              SingleCellExperiment_1.24.0\n[11] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[13] GenomicRanges_1.54.1        GenomeInfoDb_1.38.5        \n[15] IRanges_2.36.0              S4Vectors_0.40.2           \n[17] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[19] matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-7              gridExtra_2.3            \n [3] rlang_1.1.1               magrittr_2.0.3           \n [5] compiler_4.3.0            DelayedMatrixStats_1.24.0\n [7] vctrs_0.6.2               pkgconfig_2.0.3          \n [9] crayon_1.5.2              fastmap_1.1.1            \n[11] backports_1.4.1           XVector_0.42.0           \n[13] labeling_0.4.2            utf8_1.2.3               \n[15] rmarkdown_2.22            ggbeeswarm_0.7.2         \n[17] purrr_1.0.1               xfun_0.39                \n[19] bluster_1.12.0            zlibbioc_1.48.0          \n[21] beachmat_2.18.0           jsonlite_1.8.5           \n[23] DelayedArray_0.28.0       BiocParallel_1.36.0      \n[25] tweenr_2.0.2              irlba_2.3.5.1            \n[27] parallel_4.3.0            cluster_2.1.4            \n[29] R6_2.5.1                  RColorBrewer_1.1-3       \n[31] limma_3.58.1              Rcpp_1.0.10              \n[33] knitr_1.43                Matrix_1.5-4             \n[35] tidyselect_1.2.0          rstudioapi_0.14          \n[37] abind_1.4-5               yaml_2.3.7               \n[39] viridis_0.6.3             codetools_0.2-19         \n[41] lattice_0.21-8            tibble_3.2.1             \n[43] withr_2.5.0               evaluate_0.21            \n[45] polyclip_1.10-4           pillar_1.9.0             \n[47] checkmate_2.2.0           generics_0.1.3           \n[49] RCurl_1.98-1.12           sparseMatrixStats_1.14.0 \n[51] munsell_0.5.0             scales_1.2.1             \n[53] glue_1.6.2                metapod_1.10.1           \n[55] tools_4.3.0               BiocNeighbors_1.20.2     \n[57] ScaledMatrix_1.10.0       locfit_1.5-9.8           \n[59] graphlayouts_1.0.0        cowplot_1.1.1            \n[61] tidygraph_1.2.3           grid_4.3.0               \n[63] tidyr_1.3.0               edgeR_4.0.7              \n[65] colorspace_2.1-0          GenomeInfoDbData_1.2.11  \n[67] beeswarm_0.4.0            BiocSingular_1.18.0      \n[69] ggforce_0.4.1             vipor_0.4.5              \n[71] cli_3.6.1                 rsvd_1.0.5               \n[73] fansi_1.0.4               S4Arrays_1.2.0           \n[75] viridisLite_0.4.2         dplyr_1.1.2              \n[77] gtable_0.3.3              digest_0.6.31            \n[79] SparseArray_1.2.3         ggrepel_0.9.3            \n[81] dqrng_0.3.0               htmlwidgets_1.6.2        \n[83] farver_2.1.1              htmltools_0.5.5          \n[85] lifecycle_1.0.3           statmod_1.5.0            \n[87] MASS_7.3-58.4"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html",
    "href": "labs/bioc/bioc_05_dge.html",
    "title": " Differential gene expression",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will cover about Differetial gene expression, which comprises an extensive range of topics and methods. In single cell, differential expresison can have multiple functionalities such as of identifying marker genes for cell populations, as well as differentially regulated genes across conditions (healthy vs control). We will also exercise on how to account the batch information in your test.\nWe can first load the data from the clustering session. Moreover, we can already decide which clustering resolution to use. First let’s define using the louvain clustering to identifying differentially expressed genes.\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    # library(venn)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(igraph)\n    library(dplyr)\n})\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr_int_cl.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/bioc_covid_qc_dr_int_cl.rds\"), destfile = path_file)\nsce &lt;- readRDS(path_file)\nprint(reducedDims(sce))\n\nList of length 14\nnames(14): PCA UMAP tSNE_on_PCA UMAP_on_PCA ... harmony UMAP_on_Harmony SNN"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html#meta-dge_cmg",
    "href": "labs/bioc/bioc_05_dge.html#meta-dge_cmg",
    "title": " Differential gene expression",
    "section": "1 Cell marker genes",
    "text": "1 Cell marker genes\nLet us first compute a ranking for the highly differential genes in each cluster. There are many different tests and parameters to be chosen that can be used to refine your results. When looking for marker genes, we want genes that are positivelly expressed in a cell type and possibly not expressed in the others.\n\n# Compute differentiall expression\nmarkers_genes &lt;- scran::findMarkers(\n    x = sce,\n    groups = as.character(sce$louvain_SNNk15),\n    lfc = .5,\n    pval.type = \"all\",\n    direction = \"up\"\n)\n\n# List of dataFrames with the results for each cluster\nmarkers_genes\n\nList of length 9\nnames(9): 1 2 3 4 5 6 7 8 9\n\n# Visualizing the expression of one\nmarkers_genes[[\"1\"]]\n\nDataFrame with 18183 rows and 11 columns\n               p.value         FDR summary.logFC     logFC.2      logFC.3\n             &lt;numeric&gt;   &lt;numeric&gt;     &lt;numeric&gt;   &lt;numeric&gt;    &lt;numeric&gt;\nS100A8     5.01536e-64 9.11942e-60      6.628056     7.76621     2.340367\nS100A12    5.88901e-53 5.35399e-49      1.787072     4.27763     1.787072\nS100A9     2.54322e-28 1.54144e-24      1.421390     7.39019     1.421390\nCXCL8      5.98014e-15 2.71842e-11      1.102967     1.58992     1.102967\nPLBD1      2.42988e-14 8.83649e-11      0.987264     2.43642     0.987264\n...                ...         ...           ...         ...          ...\nAC007325.4           1           1    0.01104654  0.01104654 -0.004812566\nAL354822.1           1           1   -0.00785244 -0.00785244  0.000868684\nAC004556.1           1           1    0.02294381 -0.02462402 -0.124791403\nAC233755.1           1           1   -0.00670799 -0.00670799  0.000000000\nAC240274.1           1           1   -0.00724362 -0.00724362 -0.007032607\n               logFC.4     logFC.5     logFC.6     logFC.7    logFC.8\n             &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;  &lt;numeric&gt;\nS100A8         7.89619     7.78462     7.94406     7.88144    6.62806\nS100A12        4.31600     4.28998     4.31586     4.31295    4.26648\nS100A9         7.50841     7.42086     7.55250     7.55379    6.29102\nCXCL8          1.68719     1.54233     1.63129     1.63792    1.53139\nPLBD1          2.43135     2.44121     2.44252     2.44082    2.40550\n...                ...         ...         ...         ...        ...\nAC007325.4 -0.00271371  0.00667792  0.00417983  0.00809222  0.0110465\nAL354822.1 -0.01036855 -0.00936705 -0.00928158 -0.01539009 -0.0490755\nAC004556.1 -0.04927666 -0.01090129 -0.05200271 -0.04487633  0.0229438\nAC233755.1  0.00000000  0.00000000  0.00000000  0.00000000  0.0000000\nAC240274.1 -0.01510737 -0.01125536 -0.00103067 -0.00380232 -0.0143902\n               logFC.9\n             &lt;numeric&gt;\nS100A8         6.27635\nS100A12        3.88182\nS100A9         4.81815\nCXCL8          1.54518\nPLBD1          1.81260\n...                ...\nAC007325.4 -0.00652380\nAL354822.1 -0.00783011\nAC004556.1 -0.14233685\nAC233755.1  0.00000000\nAC240274.1 -0.01826009\n\n\nWe can now select the top 25 up regulated genes for plotting.\n\n# Colect the top 25 genes for each cluster and put the into a single table\ntop25 &lt;- lapply(names(markers_genes), function(x) {\n    temp &lt;- markers_genes[[x]][1:25, 1:2]\n    temp$gene &lt;- rownames(markers_genes[[x]])[1:25]\n    temp$cluster &lt;- x\n    return(temp)\n})\ntop25 &lt;- as_tibble(do.call(rbind, top25))\ntop25$p.value[top25$p.value == 0] &lt;- 1e-300\ntop25\n\n\n\n  \n\n\n\n\npar(mfrow = c(1, 5), mar = c(4, 6, 3, 1))\nfor (i in unique(top25$cluster)) {\n    barplot(sort(setNames(-log10(top25$p.value), top25$gene)[top25$cluster == i], F),\n        horiz = T, las = 1, main = paste0(i, \" vs. rest\"), border = \"white\", yaxs = \"i\", xlab = \"-log10FC\"\n    )\n    abline(v = c(0, -log10(0.05)), lty = c(1, 2))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can visualize them as a heatmap. Here we are selecting the top 5.\n\nas_tibble(top25) %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-5, p.value) -&gt; top5\n\nscater::plotHeatmap(sce[, order(sce$louvain_SNNk15)],\n    features = unique(top5$gene),\n    center = T, zlim = c(-3, 3),\n    colour_columns_by = \"louvain_SNNk15\",\n    show_colnames = F, cluster_cols = F,\n    fontsize_row = 6,\n    color = colorRampPalette(c(\"purple\", \"black\", \"yellow\"))(90)\n)\n\n\n\n\n\n\n\n\nWe can also plot a violin plot for each gene.\n\nscater::plotExpression(sce, features = unique(top5$gene), x = \"louvain_SNNk15\", ncol = 5, colour_by = \"louvain_SNNk15\", scales = \"free\")"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html#meta-dge_cond",
    "href": "labs/bioc/bioc_05_dge.html#meta-dge_cond",
    "title": " Differential gene expression",
    "section": "2 DGE across conditions",
    "text": "2 DGE across conditions\nThe second way of computing differential expression is to answer which genes are differentially expressed within a cluster. For example, in our case we have libraries comming from patients and controls and we would like to know which genes are influenced the most in a particular cell type. For this end, we will first subset our data for the desired cell cluster, then change the cell identities to the variable of comparison (which now in our case is the “type”, e.g. Covid/Ctrl).\n\n# Filter cells from that cluster\ncell_selection &lt;- sce[, sce$louvain_SNNk15 == 8]\n\n# Compute differentiall expression\nDGE_cell_selection &lt;- findMarkers(\n    x = cell_selection,\n    groups = cell_selection@colData$type,\n    lfc = .25,\n    pval.type = \"all\",\n    direction = \"any\"\n)\ntop5_cell_selection &lt;- lapply(names(DGE_cell_selection), function(x) {\n    temp &lt;- DGE_cell_selection[[x]][1:5, 1:2]\n    temp$gene &lt;- rownames(DGE_cell_selection[[x]])[1:5]\n    temp$cluster &lt;- x\n    return(temp)\n})\ntop5_cell_selection &lt;- as_tibble(do.call(rbind, top5_cell_selection))\ntop5_cell_selection\n\n\n\n  \n\n\n\nWe can now plot the expression across the type.\n\nscater::plotExpression(cell_selection, features = unique(top5_cell_selection$gene), x = \"type\", ncol = 5, colour_by = \"type\")\n\n\n\n\n\n\n\n\n#DGE_ALL6.2:\n\nplotlist &lt;- list()\nfor (i in unique(top5_cell_selection$gene)) {\n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = i, by_exprs_values = \"logcounts\") +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist, ncol = 3)"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html#meta-dge_gsa",
    "href": "labs/bioc/bioc_05_dge.html#meta-dge_gsa",
    "title": " Differential gene expression",
    "section": "3 Gene Set Analysis (GSA)",
    "text": "3 Gene Set Analysis (GSA)\n\n3.1 Hypergeometric enrichment test\nHaving a defined list of differentially expressed genes, you can now look for their combined function using hypergeometric test.\n\n# Load additional packages\nlibrary(enrichR)\n\n# Check available databases to perform enrichment (then choose one)\nenrichR::listEnrichrDbs()\n\n\n\n  \n\n\n# Perform enrichment\ntop_DGE &lt;- DGE_cell_selection$Covid[(DGE_cell_selection$Covid$p.value &lt; 0.01) & (abs(DGE_cell_selection$Covid[, grep(\"logFC.C\", colnames(DGE_cell_selection$Covid))]) &gt; 0.25), ]\n\nenrich_results &lt;- enrichr(\n    genes     = rownames(top_DGE),\n    databases = \"GO_Biological_Process_2017b\"\n)[[1]]\n\nUploading data to Enrichr... Done.\n  Querying GO_Biological_Process_2017b... Done.\nParsing results... Done.\n\n\nSome databases of interest:\nGO_Biological_Process_2017bKEGG_2019_HumanKEGG_2019_MouseWikiPathways_2019_HumanWikiPathways_2019_Mouse\nYou visualize your results using a simple barplot, for example:\n\n{\n    par(mfrow = c(1, 1), mar = c(3, 25, 2, 1))\n    barplot(\n        height = -log10(enrich_results$P.value)[10:1],\n        names.arg = enrich_results$Term[10:1],\n        horiz = TRUE,\n        las = 1,\n        border = FALSE,\n        cex.names = .6\n    )\n    abline(v = c(-log10(0.05)), lty = 2)\n    abline(v = 0, lty = 1)\n}"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html#meta-dge_gsea",
    "href": "labs/bioc/bioc_05_dge.html#meta-dge_gsea",
    "title": " Differential gene expression",
    "section": "4 Gene Set Enrichment Analysis (GSEA)",
    "text": "4 Gene Set Enrichment Analysis (GSEA)\nBesides the enrichment using hypergeometric test, we can also perform gene set enrichment analysis (GSEA), which scores ranked genes list (usually based on fold changes) and computes permutation test to check if a particular gene set is more present in the Up-regulated genes, among the DOWN_regulated genes or not differentially regulated.\n\n# Create a gene rank based on the gene expression fold change\ngene_rank &lt;- setNames(DGE_cell_selection$Covid[, grep(\"logFC.C\", colnames(DGE_cell_selection$Covid))], casefold(rownames(DGE_cell_selection$Covid), upper = T))\n\nOnce our list of genes are sorted, we can proceed with the enrichment itself. We can use the package to get gene set from the Molecular Signature Database (MSigDB) and select KEGG pathways as an example.\n\nlibrary(msigdbr)\n\n# Download gene sets\nmsigdbgmt &lt;- msigdbr::msigdbr(\"Homo sapiens\")\nmsigdbgmt &lt;- as.data.frame(msigdbgmt)\n\n# List available gene sets\nunique(msigdbgmt$gs_subcat)\n\n [1] \"MIR:MIR_Legacy\"  \"TFT:TFT_Legacy\"  \"CGP\"             \"TFT:GTRD\"       \n [5] \"\"                \"VAX\"             \"CP:BIOCARTA\"     \"CGN\"            \n [9] \"GO:BP\"           \"GO:CC\"           \"IMMUNESIGDB\"     \"GO:MF\"          \n[13] \"HPO\"             \"CP:KEGG\"         \"MIR:MIRDB\"       \"CM\"             \n[17] \"CP\"              \"CP:PID\"          \"CP:REACTOME\"     \"CP:WIKIPATHWAYS\"\n\n# Subset which gene set you want to use.\nmsigdbgmt_subset &lt;- msigdbgmt[msigdbgmt$gs_subcat == \"CP:WIKIPATHWAYS\", ]\ngmt &lt;- lapply(unique(msigdbgmt_subset$gs_name), function(x) {\n    msigdbgmt_subset[msigdbgmt_subset$gs_name == x, \"gene_symbol\"]\n})\nnames(gmt) &lt;- unique(paste0(msigdbgmt_subset$gs_name, \"_\", msigdbgmt_subset$gs_exact_source))\n\nNext, we will be using the GSEA. This will result in a table containing information for several pathways. We can then sort and filter those pathways to visualize only the top ones. You can select/filter them by either p-value or normalized enrichment score (NES).\n\nlibrary(fgsea)\n\n# Perform enrichemnt analysis\nfgseaRes &lt;- fgsea(pathways = gmt, stats = gene_rank, minSize = 15, maxSize = 500, nperm = 10000)\nfgseaRes &lt;- fgseaRes[order(fgseaRes$NES, decreasing = T), ]\n\n# Filter the results table to show only the top 10 UP or DOWN regulated processes (optional)\ntop10_UP &lt;- fgseaRes$pathway[1:10]\n\n# Nice summary table (shown as a plot)\nplotGseaTable(gmt[top10_UP], gene_rank, fgseaRes, gseaParam = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWhich KEGG pathways are upregulated in this cluster?Which KEGG pathways are dowregulated in this cluster?\nChange the pathway source to another gene set (e.g. “CP:WIKIPATHWAYS” or “CP:REACTOME” or “CP:BIOCARTA” or “GO:BP”) and check the if you get similar results?\n\n\nFinally, lets save the integrated data for further analysis.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr_int_cl_dge.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_05_dge.html#meta-session",
    "href": "labs/bioc/bioc_05_dge.html#meta-session",
    "title": " Differential gene expression",
    "section": "5 Session info",
    "text": "5 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] fgsea_1.28.0                msigdbr_7.5.1              \n [3] enrichR_3.2                 dplyr_1.1.2                \n [5] igraph_1.4.3                pheatmap_1.0.12            \n [7] patchwork_1.1.2             scran_1.30.0               \n [9] scater_1.30.1               ggplot2_3.4.2              \n[11] scuttle_1.12.0              SingleCellExperiment_1.24.0\n[13] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[15] GenomicRanges_1.54.1        GenomeInfoDb_1.38.5        \n[17] IRanges_2.36.0              S4Vectors_0.40.2           \n[19] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[21] matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-7              gridExtra_2.3            \n [3] rlang_1.1.1               magrittr_2.0.3           \n [5] compiler_4.3.0            DelayedMatrixStats_1.24.0\n [7] vctrs_0.6.2               pkgconfig_2.0.3          \n [9] crayon_1.5.2              fastmap_1.1.1            \n[11] XVector_0.42.0            labeling_0.4.2           \n[13] utf8_1.2.3                rmarkdown_2.22           \n[15] ggbeeswarm_0.7.2          xfun_0.39                \n[17] bluster_1.12.0            WriteXLS_6.4.0           \n[19] zlibbioc_1.48.0           beachmat_2.18.0          \n[21] jsonlite_1.8.5            DelayedArray_0.28.0      \n[23] BiocParallel_1.36.0       irlba_2.3.5.1            \n[25] parallel_4.3.0            cluster_2.1.4            \n[27] R6_2.5.1                  RColorBrewer_1.1-3       \n[29] limma_3.58.1              Rcpp_1.0.10              \n[31] knitr_1.43                Matrix_1.5-4             \n[33] tidyselect_1.2.0          rstudioapi_0.14          \n[35] abind_1.4-5               yaml_2.3.7               \n[37] viridis_0.6.3             codetools_0.2-19         \n[39] curl_5.0.1                lattice_0.21-8           \n[41] tibble_3.2.1              withr_2.5.0              \n[43] evaluate_0.21             pillar_1.9.0             \n[45] generics_0.1.3            RCurl_1.98-1.12          \n[47] sparseMatrixStats_1.14.0  munsell_0.5.0            \n[49] scales_1.2.1              glue_1.6.2               \n[51] metapod_1.10.1            tools_4.3.0              \n[53] data.table_1.14.8         BiocNeighbors_1.20.2     \n[55] ScaledMatrix_1.10.0       locfit_1.5-9.8           \n[57] babelgene_22.9            fastmatch_1.1-3          \n[59] cowplot_1.1.1             grid_4.3.0               \n[61] edgeR_4.0.7               colorspace_2.1-0         \n[63] GenomeInfoDbData_1.2.11   beeswarm_0.4.0           \n[65] BiocSingular_1.18.0       vipor_0.4.5              \n[67] cli_3.6.1                 rsvd_1.0.5               \n[69] fansi_1.0.4               S4Arrays_1.2.0           \n[71] viridisLite_0.4.2         gtable_0.3.3             \n[73] digest_0.6.31             SparseArray_1.2.3        \n[75] ggrepel_0.9.3             dqrng_0.3.0              \n[77] rjson_0.2.21              htmlwidgets_1.6.2        \n[79] farver_2.1.1              htmltools_0.5.5          \n[81] lifecycle_1.0.3           httr_1.4.6               \n[83] statmod_1.5.0"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html",
    "href": "labs/bioc/bioc_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each celltype.\nWe will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to even if the celltype of that cell is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nHere we will use a reference PBMC dataset from the scPred package which is provided as a Seurat object with counts. And we will test classification based on the scPred and scMap methods. Finally we will use gene set enrichment predict celltype based on the DEGs of each cluster."
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_read",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_read",
    "title": " Celltype prediction",
    "section": "1 Read data",
    "text": "1 Read data\nFirst, lets load required libraries\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(dplyr)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(scPred)\n    library(scmap)\n})\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr_int_cl.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results/bioc_covid_qc_dr_int_cl.rds\"), destfile = path_file)\nalldata &lt;- readRDS(path_file)\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\nctrl.sce &lt;- alldata[, alldata@colData$sample == \"ctrl.13\"]\n\n# remove all old dimensionality reductions as they will mess up the analysis further down\nreducedDims(ctrl.sce) &lt;- NULL"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_ref",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "2 Reference data",
    "text": "2 Reference data\nLoad the reference dataset with annotated labels.\n\nreference &lt;- scPred::pbmc_1\nreference\n\nAn object of class Seurat \n32838 features across 3500 samples within 1 assay \nActive assay: RNA (32838 features, 0 variable features)\n\n\nConvert to a SCE object.\n\nref.sce &lt;- Seurat::as.SingleCellExperiment(reference)\n\nRerun analysis pipeline. Run normalization, feature selection and dimensionality reduction\n\n# Normalize\nref.sce &lt;- computeSumFactors(ref.sce)\nref.sce &lt;- logNormCounts(ref.sce)\n\n# Variable genes\nvar.out &lt;- modelGeneVar(ref.sce, method = \"loess\")\nhvg.ref &lt;- getTopHVGs(var.out, n = 1000)\n\n# Dim reduction\nref.sce &lt;- runPCA(ref.sce,\n    exprs_values = \"logcounts\", scale = T,\n    ncomponents = 30, subset_row = hvg.ref\n)\nref.sce &lt;- runUMAP(ref.sce, dimred = \"PCA\")\n\n\nplotReducedDim(ref.sce, dimred = \"UMAP\", colour_by = \"cell_type\")\n\n\n\n\n\n\n\n\nRun all steps of the analysis for the ctrl sample as well. Use the clustering from the integration lab with resolution 0.5.\n\n# Normalize\nctrl.sce &lt;- computeSumFactors(ctrl.sce)\nctrl.sce &lt;- logNormCounts(ctrl.sce)\n\n# Variable genes\nvar.out &lt;- modelGeneVar(ctrl.sce, method = \"loess\")\nhvg.ctrl &lt;- getTopHVGs(var.out, n = 1000)\n\n# Dim reduction\nctrl.sce &lt;- runPCA(ctrl.sce, exprs_values = \"logcounts\", scale = T, ncomponents = 30, subset_row = hvg.ctrl)\nctrl.sce &lt;- runUMAP(ctrl.sce, dimred = \"PCA\")\n\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"louvain_SNNk15\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#scmap",
    "href": "labs/bioc/bioc_06_celltyping.html#scmap",
    "title": " Celltype prediction",
    "section": "3 scMap",
    "text": "3 scMap\nThe scMap package is one method for projecting cells from a scRNA-seq experiment on to the cell-types or individual cells identified in a different experiment. It can be run on different levels, either projecting by cluster or by single cell, here we will try out both.\nFor scmap cell type labels must be stored in the cell_type1 column of the colData slots, and gene ids that are consistent across both datasets must be stored in the feature_symbol column of the rowData slots.\n\n3.1 scMap cluster\n\n# add in slot cell_type1\nref.sce@colData$cell_type1 &lt;- ref.sce@colData$cell_type\n# create a rowData slot with feature_symbol\nrd &lt;- data.frame(feature_symbol = rownames(ref.sce))\nrownames(rd) &lt;- rownames(ref.sce)\nrowData(ref.sce) &lt;- rd\n\n# same for the ctrl dataset\n# create a rowData slot with feature_symbol\nrd &lt;- data.frame(feature_symbol = rownames(ctrl.sce))\nrownames(rd) &lt;- rownames(ctrl.sce)\nrowData(ctrl.sce) &lt;- rd\n\nThen we can select variable features in both datasets.\n\n# select features\ncounts(ctrl.sce) &lt;- as.matrix(counts(ctrl.sce))\nlogcounts(ctrl.sce) &lt;- as.matrix(logcounts(ctrl.sce))\nctrl.sce &lt;- selectFeatures(ctrl.sce, suppress_plot = TRUE)\n\ncounts(ref.sce) &lt;- as.matrix(counts(ref.sce))\nlogcounts(ref.sce) &lt;- as.matrix(logcounts(ref.sce))\nref.sce &lt;- selectFeatures(ref.sce, suppress_plot = TRUE)\n\nThen we need to index the reference dataset by cluster, default is the clusters in cell_type1.\n\nref.sce &lt;- indexCluster(ref.sce)\n\nNow we project the Covid-19 dataset onto that index.\n\nproject_cluster &lt;- scmapCluster(\n    projection = ctrl.sce,\n    index_list = list(\n        ref = metadata(ref.sce)$scmap_cluster_index\n    )\n)\n\n# projected labels\ntable(project_cluster$scmap_cluster_labs)\n\n\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n         70         104         125          38         215         160 \n    NK cell         pDC Plasma cell  unassigned \n        294           2           1         194 \n\n\nThen add the predictions to metadata and plot UMAP.\n\n# add in predictions\nctrl.sce@colData$scmap_cluster &lt;- project_cluster$scmap_cluster_labs\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cluster\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#scmap-cell",
    "href": "labs/bioc/bioc_06_celltyping.html#scmap-cell",
    "title": " Celltype prediction",
    "section": "4 scMap cell",
    "text": "4 scMap cell\nWe can instead index the refernce data based on each single cell and project our data onto the closest neighbor in that dataset.\n\nref.sce &lt;- indexCell(ref.sce)\n\nAgain we need to index the reference dataset.\n\nproject_cell &lt;- scmapCell(\n    projection = ctrl.sce,\n    index_list = list(\n        ref = metadata(ref.sce)$scmap_cell_index\n    )\n)\n\nWe now get a table with index for the 5 nearest neigbors in the reference dataset for each cell in our dataset. We will select the celltype of the closest neighbor and assign it to the data.\n\ncell_type_pred &lt;- colData(ref.sce)$cell_type1[project_cell$ref[[1]][1, ]]\ntable(cell_type_pred)\n\ncell_type_pred\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n        101         161         293          37         241         164 \n    NK cell         pDC Plasma cell \n        203           2           1 \n\n\nThen add the predictions to metadata and plot umap.\n\n# add in predictions\nctrl.sce@colData$scmap_cell &lt;- cell_type_pred\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\")\n\n\n\n\n\n\n\n\nPlot both:\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cluster\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\"),\n    ncol = 2\n)"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_scpred",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_scpred",
    "title": " Celltype prediction",
    "section": "5 scPred",
    "text": "5 scPred\nscPred will train a classifier based on all principal components. First, getFeatureSpace will create a scPred object stored in the @misc slot where it extracts the PCs that best separates the different celltypes. Then trainModel will do the actual training for each celltype.\nscPred works with Seurat objects, so we will convert both objects to seurat objects. You may see a lot of warnings about renaming things, but as long as you do not see an Error, you should be fine.\n\nsuppressPackageStartupMessages(library(Seurat))\n\nreference &lt;- Seurat::as.Seurat(ref.sce)\nctrl &lt;- Seurat::as.Seurat(ctrl.sce)\n\nThe loadings matrix is lost when converted to Seurat object, and scPred needs that information. So we need to rerun PCA with Seurat and the same hvgs.\n\nVariableFeatures(reference) &lt;- hvg.ref\nreference &lt;- reference %&gt;%\n    ScaleData(verbose = F) %&gt;%\n    RunPCA(verbose = F)\n\nVariableFeatures(ctrl) &lt;- hvg.ctrl\nctrl &lt;- ctrl %&gt;%\n    ScaleData(verbose = F) %&gt;%\n    RunPCA(verbose = F)\n\n\nreference &lt;- getFeatureSpace(reference, \"cell_type\")\n\n●  Extracting feature space for each cell type...\nDONE!\n\nreference &lt;- trainModel(reference)\n\n●  Training models for each cell type...\nDONE!\n\n\nscPred will train a classifier based on all principal components. First, getFeatureSpace will create a scPred object stored in the @misc slot where it extracts the PCs that best separates the different celltypes. Then trainModel will do the actual training for each celltype.\n\nget_scpred(reference)\n\n'scPred' object\n✔  Prediction variable = cell_type \n✔  Discriminant features per cell type\n✔  Training model(s)\nSummary\n\n|Cell type   |    n| Features|Method    |   ROC|  Sens|  Spec|\n|:-----------|----:|--------:|:---------|-----:|-----:|-----:|\n|B cell      |  280|       50|svmRadial | 1.000| 1.000| 1.000|\n|CD4 T cell  | 1620|       50|svmRadial | 0.994| 0.972| 0.963|\n|CD8 T cell  |  945|       50|svmRadial | 0.973| 0.859| 0.971|\n|cDC         |   26|       50|svmRadial | 0.994| 0.727| 0.999|\n|cMono       |  212|       50|svmRadial | 1.000| 0.957| 0.997|\n|ncMono      |   79|       50|svmRadial | 1.000| 0.962| 0.999|\n|NK cell     |  312|       50|svmRadial | 0.998| 0.926| 0.995|\n|pDC         |   20|       50|svmRadial | 1.000| 0.950| 1.000|\n|Plasma cell |    6|       50|svmRadial | 1.000| 1.000| 1.000|\n\n\nYou can optimize parameters for each dataset by chaning parameters and testing different types of models, see more at: https://powellgenomicslab.github.io/scPred/articles/introduction.html. But for now, we will continue with this model. Now, lets predict celltypes on our data, where scPred will align the two datasets with Harmony and then perform classification.\n\nctrl &lt;- scPredict(ctrl, reference)\n\n●  Matching reference with new dataset...\n     ─ 1000 features present in reference loadings\n     ─ 937 features shared between reference and new dataset\n     ─ 93.7% of features in the reference are present in new dataset\n●  Aligning new data to reference...\n●  Classifying cells...\nDONE!\n\n\n\nDimPlot(ctrl, group.by = \"scpred_prediction\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\nggplot(ctrl@meta.data, aes(x = louvain_SNNk15, fill = scpred_prediction)) +\n    geom_bar() +\n    theme_classic()\n\n\n\n\n\n\n\n\nAdd the predictions into the SCE object\n\nctrl.sce@colData$scpred_prediction &lt;- ctrl$scpred_prediction"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_compare",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_compare",
    "title": " Celltype prediction",
    "section": "6 Compare results",
    "text": "6 Compare results\nNow we will compare the output of the two methods using the convenient function in scPred crossTab that prints the overlap between two metadata slots.\n\ncrossTab(ctrl, \"scmap_cell\", \"scpred_prediction\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_gsea",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_gsea",
    "title": " Celltype prediction",
    "section": "7 GSEA with celltype markers",
    "text": "7 GSEA with celltype markers\nAnother option, where celltype can be classified on cluster level is to use gene set enrichment among the DEGs with known markers for different celltypes. Similar to how we did functional enrichment for the DEGs in the Differential expression exercise. There are some resources for celltype gene sets that can be used. Such as CellMarker, PanglaoDB or celltype gene sets at MSigDB. We can also look at overlap between DEGs in a reference dataset and the dataset you are analysing.\n\n7.1 DEG overlap\nFirst, lets extract top DEGs for our Covid-19 dataset and the reference dataset. When we run differential expression for our dataset, we want to report as many genes as possible, hence we set the cutoffs quite lenient.\n\n# run differential expression in our dataset, using clustering at resolution 0.3\nDGE_list &lt;- scran::findMarkers(\n    x = alldata,\n    groups = as.character(alldata@colData$louvain_SNNk15),\n    pval.type = \"all\",\n    min.prop = 0\n)\n\n\n# Compute differential gene expression in reference dataset (that has cell annotation)\nref_DGE &lt;- scran::findMarkers(\n    x = ref.sce,\n    groups = as.character(ref.sce@colData$cell_type),\n    pval.type = \"all\",\n    direction = \"up\"\n)\n\n# Identify the top cell marker genes in reference dataset\n# select top 50 with hihgest foldchange among top 100 signifcant genes.\nref_list &lt;- lapply(ref_DGE, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    x %&gt;%\n        as.data.frame() %&gt;%\n        filter(p.value &lt; 0.01) %&gt;%\n        top_n(-100, p.value) %&gt;%\n        top_n(50, logFC) %&gt;%\n        rownames()\n})\n\nunlist(lapply(ref_list, length))\n\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n         50          50          19          17          50          50 \n    NK cell         pDC Plasma cell \n         50          50          24 \n\n\nNow we can run GSEA for the DEGs from our dataset and check for enrichment of top DEGs in the reference dataset.\n\nsuppressPackageStartupMessages(library(fgsea))\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    gene_rank &lt;- setNames(x$logFC, rownames(x))\n    fgseaRes &lt;- fgsea(pathways = ref_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.1, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 2, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\nres\n\n$`1`\n       pathway         pval         padj         ES       NES nMoreExtreme size\n1:       cMono 0.0001612123 0.0005946089  0.9477365  1.935642            0   47\n2:      ncMono 0.0001611344 0.0005946089  0.8883004  1.824343            0   49\n3:         cDC 0.0581929556 0.0654670750 -0.7642090 -1.413663          265   17\n4: Plasma cell 0.0263583815 0.0338893476 -0.7559870 -1.492311          113   24\n5:     NK cell 0.0018440464 0.0027660695 -0.7327226 -1.663502            6   49\n6:  CD8 T cell 0.0011008366 0.0019815059 -0.8963974 -1.673679            4   18\n7:      B cell 0.0002632272 0.0005946089 -0.9032392 -2.032917            0   47\n8:  CD4 T cell 0.0002642706 0.0005946089 -0.9254862 -2.108715            0   50\n                                                leadingEdge\n1:                  S100A8,S100A9,LYZ,S100A12,VCAN,FCN1,...\n2:             S100A11,AIF1,S100A4,FCER1G,MAFB,SERPINA1,...\n3: HLA-DPB1,HLA-DPA1,HLA-DQB1,HLA-DRB1,HLA-DMA,HLA-DRB5,...\n4:                    ISG20,PEBP1,CYCS,MIF,FKBP11,SPCS2,...\n5:                       GNLY,NKG7,B2M,CTSW,GZMA,FGFBP2,...\n6:                         IL32,CCL5,GZMH,CD3D,CD2,CD8A,...\n7:                 RPS5,CXCR4,RPL23A,CD52,RPL18A,RPL13A,...\n8:                  RPL3,RPS4X,RPS27A,RPL5,EEF1A1,RPL14,...\n\n$`2`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1:     B cell 0.0002041650 0.0003700658  0.9650595  2.060454            0   47\n2: CD4 T cell 0.0002055921 0.0003700658  0.8591045  1.846955            0   50\n3:        cDC 0.0004203447 0.0006305170  0.9445632  1.709807            1   17\n4: CD8 T cell 0.0021048603 0.0027062490 -0.8921894 -1.641239           10   18\n5:      cMono 0.0001959248 0.0003700658 -0.8185447 -1.761319            0   47\n6:     ncMono 0.0001940994 0.0003700658 -0.8829761 -1.915489            0   49\n7:    NK cell 0.0001940994 0.0003700658 -0.9127279 -1.980031            0   49\n                                               leadingEdge\n1:              MS4A1,CD37,TNFRSF13C,CXCR4,BANK1,CD79B,...\n2:                   RPS6,RPL13,RPL32,RPS3A,RPS29,RPL3,...\n3: HLA-DRA,HLA-DPB1,HLA-DQB1,HLA-DRB1,HLA-DPA1,HLA-DMA,...\n4:                        CCL5,IL32,GZMH,CD3D,CD2,LYAR,...\n5:                S100A6,S100A9,LYZ,S100A8,TYROBP,FCN1,...\n6:              S100A4,FCER1G,S100A11,AIF1,IFITM3,LST1,...\n7:                     HCST,NKG7,ITGB2,GNLY,MYO1F,CST7,...\n\n$`3`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1:     ncMono 0.0001041124 0.0004694836  0.9309715  1.625137            0   49\n2:      cMono 0.0001043297 0.0004694836  0.9315183  1.624154            0   47\n3:        cDC 0.0168105930 0.0216136195  0.8590261  1.386413          145   17\n4: CD4 T cell 0.0026666667 0.0040000000 -0.7020776 -1.886878            0   50\n5:    NK cell 0.0025188917 0.0040000000 -0.7120017 -1.914447            0   49\n6: CD8 T cell 0.0007980846 0.0023942538 -0.9359176 -2.017558            0   18\n7:     B cell 0.0023980815 0.0040000000 -0.8774013 -2.326466            0   47\n                                               leadingEdge\n1:            AIF1,PSAP,S100A11,FCER1G,S100A4,SERPINA1,...\n2:                S100A9,LYZ,S100A8,FCN1,TYROBP,S100A6,...\n3: HLA-DRA,HLA-DRB1,HLA-DRB5,HLA-DQB1,HLA-DPA1,HLA-DMA,...\n4:                 RPL3,PIK3IP1,IL7R,RPS29,RPS3,RPS27A,...\n5:                       NKG7,GNLY,CST7,GZMA,CTSW,GZMM,...\n6:                        CCL5,IL32,GZMH,CD3D,CD2,CD8A,...\n7:              CXCR4,MS4A1,TNFRSF13C,CD79B,BANK1,RPS5,...\n\n$`4`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1: CD4 T cell 0.0001930875 0.0004653568  0.9803622  2.131622            0   50\n2:    NK cell 0.0275077559 0.0412616339 -0.6668272 -1.466630          132   49\n3:        cDC 0.0001991239 0.0004653568 -0.9322686 -1.728863            0   17\n4:        pDC 0.0006202191 0.0011163945 -0.8171519 -1.789912            2   47\n5:      cMono 0.0002067397 0.0004653568 -0.9186945 -2.012333            0   47\n6:     ncMono 0.0002068252 0.0004653568 -0.9263802 -2.037495            0   49\n                                               leadingEdge\n1:                  IL7R,LDHB,PIK3IP1,NOSIP,RPL3,RPS12,...\n2:                    NKG7,GNLY,FGFBP2,MYO1F,CST7,GZMA,...\n3: HLA-DRA,HLA-DRB1,HLA-DPA1,HLA-DPB1,HLA-DQB1,HLA-DMA,...\n4:                     PLEK,NPC2,IRF8,PLAC8,PTPRE,CTSB,...\n5:                 S100A9,S100A8,LYZ,TYROBP,FCN1,APLP2,...\n6:                    FCER1G,PSAP,IFITM3,LYN,SAT1,LST1,...\n\n$`5`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1:     B cell 0.0001818182 0.0004016064  0.9624502  2.052882            0   47\n2: CD4 T cell 0.0001812251 0.0004016064  0.8762641  1.886926            0   50\n3:        cDC 0.0001904399 0.0004016064  0.9538608  1.738185            0   17\n4: CD8 T cell 0.0004203447 0.0006305170 -0.9046911 -1.711837            1   18\n5:      cMono 0.0008884940 0.0011423494 -0.7954796 -1.765723            3   47\n6:     ncMono 0.0002231147 0.0004016064 -0.8859954 -1.977394            0   49\n7:    NK cell 0.0002231147 0.0004016064 -0.9087684 -2.028219            0   49\n                                               leadingEdge\n1:          MS4A1,CD37,CXCR4,TNFRSF13C,BANK1,LINC00926,...\n2:                    RPS6,RPL13,RPL32,RPS3A,RPL9,RPL3,...\n3: HLA-DRA,HLA-DQB1,HLA-DRB1,HLA-DPB1,HLA-DPA1,HLA-DMA,...\n4:                        CCL5,IL32,GZMH,CD3D,CD2,LYAR,...\n5:                S100A6,S100A9,LYZ,S100A8,TYROBP,FCN1,...\n6:              S100A4,FCER1G,S100A11,AIF1,PSAP,IFITM3,...\n7:                     HCST,NKG7,ITGB2,GNLY,MYO1F,CST7,...\n\n$`6`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1:    NK cell 0.0001968117 0.0003660024  0.9357367  2.012182            0   49\n2: CD4 T cell 0.0001970443 0.0003660024  0.8648575  1.865254            0   50\n3: CD8 T cell 0.0002002804 0.0003660024  0.9667190  1.776197            0   18\n4:        cDC 0.0047732697 0.0071599045 -0.8811814 -1.612760           23   17\n5:     ncMono 0.0002032107 0.0003660024 -0.8655401 -1.895657            0   49\n6:      cMono 0.0002033347 0.0003660024 -0.9182094 -1.999151            0   47\n                                            leadingEdge\n1:                    NKG7,GNLY,CST7,GZMA,CTSW,GZMM,...\n2:                IL7R,RPS3,RPS29,RPL3,MGAT4A,RPS4X,...\n3:                    CCL5,IL32,GZMH,CD3D,LYAR,CD8A,...\n4: HLA-DRA,HLA-DMA,HLA-DQB1,HLA-DRB5,BASP1,HLA-DRB1,...\n5:                 FCER1G,AIF1,LST1,FTH1,COTL1,PSAP,...\n6:               S100A9,S100A8,LYZ,TYROBP,FCN1,VCAN,...\n\n$`7`\n      pathway         pval         padj         ES       NES nMoreExtreme size\n1:    NK cell 0.0002246686 0.0006740058  0.9822433  2.117581            0   49\n2: CD8 T cell 0.0052356021 0.0067314884  0.8934917  1.648012           23   18\n3:        cDC 0.0007408779 0.0016233766 -0.9096050 -1.649017            3   17\n4:     ncMono 0.0025220681 0.0037831021 -0.7690981 -1.653101           13   49\n5: CD4 T cell 0.0009018759 0.0016233766 -0.8069090 -1.736711            4   50\n6:      cMono 0.0001806685 0.0006740058 -0.8740244 -1.867198            0   47\n7:     B cell 0.0001806685 0.0006740058 -0.8943406 -1.910600            0   47\n                                               leadingEdge\n1:                     GNLY,NKG7,FGFBP2,CST7,PRF1,CTSW,...\n2:                   CCL5,GZMH,IL32,LYAR,CD2,LINC01871,...\n3: HLA-DRA,HLA-DRB1,HLA-DQB1,HLA-DPA1,HLA-DMA,HLA-DRB5,...\n4:                      COTL1,FTH1,AIF1,LST1,SAT1,SPI1,...\n5:              TMEM123,RPS13,RPL22,RPS28,RPL35A,RPL36,...\n6:                     S100A9,S100A8,LYZ,FCN1,TKT,VCAN,...\n7:               CD37,RPS11,MS4A1,CD52,BANK1,TNFRSF13C,...\n\n$`8`\n      pathway         pval        padj         ES       NES nMoreExtreme size\n1:     ncMono 0.0021600605 0.003240091 -0.7537958 -1.411206           19   49\n2:    NK cell 0.0006480181 0.001166433 -0.7784508 -1.457363            5   49\n3:     B cell 0.0004329004 0.001166433 -0.7863661 -1.466871            3   47\n4:        cDC 0.0005745145 0.001166433 -0.8884593 -1.499586            4   17\n5:      cMono 0.0001082251 0.000487013 -0.8319138 -1.551835            0   47\n6: CD4 T cell 0.0001077702 0.000487013 -0.9066494 -1.701390            0   50\n                                               leadingEdge\n1:           S100A4,S100A11,AIF1,IFITM2,CEBPB,SERPINA1,...\n2:                   ITGB2,NKG7,GNLY,MYO1F,IFITM1,JAK1,...\n3:                   CD52,RPS23,RPL13A,RPS11,RPL12,FAU,...\n4: HLA-DRA,HLA-DRB1,HLA-DPB1,HLA-DPA1,HLA-DQB1,HLA-DMA,...\n5:                   JUND,S100A6,NFKBIA,TYROBP,LYZ,FOS,...\n6:                RPL34,RPS13,RPL13,EEF1A1,RPS3A,RPL32,...\n\n$`9`\n       pathway         pval        padj         ES       NES nMoreExtreme size\n1:      ncMono 0.0001191611 0.001072450  0.9705242  1.879820            0   49\n2:         cDC 0.0061555680 0.011080022  0.8911415  1.525520           43   17\n3:       cMono 0.0129496403 0.016649538  0.7656658  1.476902          107   47\n4: Plasma cell 0.0330511890 0.037182588 -0.7002547 -1.547523           81   24\n5:     NK cell 0.0105590062 0.015838509 -0.6315449 -1.603456           16   49\n6:  CD8 T cell 0.0007165890 0.001612325 -0.8974765 -1.869886            1   18\n7:  CD4 T cell 0.0006422608 0.001612325 -0.8507977 -2.161552            0   50\n8:      B cell 0.0006016847 0.001612325 -0.8721690 -2.198723            0   47\n                                               leadingEdge\n1:                  AIF1,LST1,COTL1,FCER1G,PSAP,FCGR3A,...\n2: HLA-DPA1,HLA-DRA,HLA-DPB1,HLA-DRB1,HLA-DRB5,HLA-DMA,...\n3:                   LYZ,TYROBP,S100A6,FCN1,TKT,S100A9,...\n4:                 ISG20,CYCS,FKBP11,PEBP1,JCHAIN,MZB1,...\n5:                    CST7,IFITM1,GZMM,CCL4,CD247,HOPX,...\n6:                        CCL5,IL32,CD3D,GZMH,CD2,LYAR,...\n7:                   RPL31,RPS29,IL7R,RPS3,RPS27A,CCR7,...\n8:       CXCR4,MS4A1,BANK1,TNFRSF13C,LINC00926,RALGPS2,...\n\n\nSelecing top significant overlap per cluster, we can now rename the clusters according to the predicted labels. OBS! Be aware that if you have some clusters that have non-significant p-values for all the gene sets, the cluster label will not be very reliable. Also, the gene sets you are using may not cover all the celltypes you have in your dataset and hence predictions may just be the most similar celltype. Also, some of the clusters have very similar p-values to multiple celltypes, for instance the ncMono and cMono celltypes are equally good for some clusters.\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\n\nalldata@colData$ref_gsea &lt;- new.cluster.ids[as.character(alldata@colData$louvain_SNNk15)]\n\nwrap_plots(\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"louvain_SNNk15\"),\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nCompare to results with the other celltype prediction methods in the ctrl_13 sample.\n\nctrl.sce@colData$ref_gsea &lt;- alldata@colData$ref_gsea[alldata@colData$sample == \"ctrl.13\"]\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scpred_prediction\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\n\n\n7.2 With annotated gene sets\nWe have dowloaded the celltype gene lists from http://bio-bigdata.hrbmu.edu.cn/CellMarker/CellMarker_download.html and converted the excel file to a csv for you. Read in the gene lists and do some filtering.\n\npath_file &lt;- file.path(\"data/human_cell_markers.txt\")\nif (!file.exists(path_file)) download.file(file.path(path_data, \"human_cell_markers.txt\"), destfile = path_file)\n\n\nmarkers &lt;- read.delim(\"data/human_cell_markers.txt\")\nmarkers &lt;- markers[markers$speciesType == \"Human\", ]\nmarkers &lt;- markers[markers$cancerType == \"Normal\", ]\n\n# Filter by tissue (to reduce computational time and have tissue-specific classification)\n# sort(unique(markers$tissueType))\n# grep(\"blood\",unique(markers$tissueType),value = T)\n# markers &lt;- markers [ markers$tissueType %in% c(\"Blood\",\"Venous blood\",\n#                                                \"Serum\",\"Plasma\",\n#                                                \"Spleen\",\"Bone marrow\",\"Lymph node\"), ]\n\n\n# remove strange characters etc.\ncelltype_list &lt;- lapply(unique(markers$cellName), function(x) {\n    x &lt;- paste(markers$geneSymbol[markers$cellName == x], sep = \",\")\n    x &lt;- gsub(\"[[]|[]]| |-\", \",\", x)\n    x &lt;- unlist(strsplit(x, split = \",\"))\n    x &lt;- unique(x[!x %in% c(\"\", \"NA\", \"family\")])\n    x &lt;- casefold(x, upper = T)\n})\nnames(celltype_list) &lt;- unique(markers$cellName)\n# celltype_list &lt;- lapply(celltype_list , function(x) {x[1:min(length(x),50)]} )\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &lt; 100]\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &gt; 5]\n\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    gene_rank &lt;- setNames(x$logFC, rownames(x))\n    fgseaRes &lt;- fgsea(pathways = celltype_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.01, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 5, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\n\n# show top 3 for each cluster.\nlapply(res, head, 3)\n\n$`1`\n                  pathway         pval       padj        ES      NES\n1:             Neutrophil 0.0001507613 0.01493723 0.9197310 2.010307\n2: CD1C+_B dendritic cell 0.0001589067 0.01493723 0.9293164 1.931839\n3:           Stromal cell 0.0013311148 0.05004992 0.8544544 1.696909\n   nMoreExtreme size                                  leadingEdge\n1:            0   80 S100A8,S100A9,S100A12,MNDA,S100A11,NAMPT,...\n2:            0   53      S100A8,S100A9,LYZ,S100A12,VCAN,FCN1,...\n3:            7   38          VIM,TIMP2,BST1,TIMP1,ANPEP,CD44,...\n\n$`2`\n                       pathway        pval       padj         ES       NES\n1:           Follicular B cell 0.006354586 0.05430282  0.8587199  1.627043\n2:              Pyramidal cell 0.003853565 0.04168250 -0.9722789 -1.490874\n3: CD4+CD25+ regulatory T cell 0.001541426 0.02414900 -0.9799548 -1.502644\n   nMoreExtreme size                         leadingEdge\n1:           29   22 MS4A1,CD69,CD22,FCER2,CD40,PAX5,...\n2:           19    6                           NRGN,CD3E\n3:            7    6            CD3E,CD3D,CD3G,PTPRC,CD4\n\n$`3`\n                           pathway         pval        padj        ES      NES\n1:                      Neutrophil 0.0001011327 0.007217168 0.8809821 1.569285\n2:          CD1C+_B dendritic cell 0.0001033271 0.007217168 0.8836167 1.550651\n3: Monocyte derived dendritic cell 0.0001151676 0.007217168 0.9481164 1.532539\n   nMoreExtreme size                              leadingEdge\n1:            0   80 S100A9,S100A8,S100A11,CD14,LST1,MNDA,...\n2:            0   53     S100A9,LYZ,S100A8,FCN1,VCAN,CD14,...\n3:            0   17   S100A9,S100A8,CST3,CD14,CD33,ITGAX,...\n\n$`4`\n             pathway         pval        padj        ES      NES nMoreExtreme\n1: Naive CD8+ T cell 0.0001888218 0.005616299 0.8620656 2.045525            0\n2: Naive CD4+ T cell 0.0002017756 0.005616299 0.9214751 1.879833            0\n3:       CD4+ T cell 0.0002022654 0.005616299 0.9193037 1.787130            0\n   size                            leadingEdge\n1:   91 LDHB,PIK3IP1,NOSIP,TCF7,RCAN3,NPM1,...\n2:   34    IL7R,NOSIP,TCF7,EEF1B2,RPS5,MAL,...\n3:   25        IL7R,LTB,CD3E,CD3D,CD3G,CD2,...\n\n$`5`\n                        pathway        pval       padj         ES       NES\n1:            Follicular B cell 0.005346572 0.04188148  0.8501224  1.610208\n2: Hematopoietic precursor cell 0.008534851 0.06171354 -0.9521366 -1.493451\n3:               Pyramidal cell 0.003048161 0.03581589 -0.9725160 -1.525417\n   nMoreExtreme size                         leadingEdge\n1:           27   22 MS4A1,CD69,CD22,CD40,FCER2,PAX5,...\n2:           41    6                          CD14,PTPRC\n3:           14    6                           CD3E,NRGN\n\n$`6`\n                             pathway         pval        padj        ES\n1:             CD4+ cytotoxic T cell 0.0001908761 0.007875995 0.8929282\n2:               Natural killer cell 0.0003821899 0.009483454 0.7967208\n3: Effector CD8+ memory T (Tem) cell 0.0003824092 0.009483454 0.7969411\n        NES nMoreExtreme size                           leadingEdge\n1: 2.063730            0   86     CCL5,NKG7,GZMH,GNLY,CST7,GZMA,...\n2: 1.835585            1   84     NKG7,GNLY,CD3D,CD3E,GZMA,CD3G,...\n3: 1.824241            1   79 GZMH,GNLY,ARL4C,GZMB,FGFBP2,KLRD1,...\n\n$`7`\n                             pathway         pval       padj        ES      NES\n1:             CD4+ cytotoxic T cell 0.0002165909 0.01025753 0.9480244 2.205220\n2: Effector CD8+ memory T (Tem) cell 0.0002165909 0.01025753 0.8968211 2.068348\n3:               Natural killer cell 0.0002182453 0.01025753 0.8507701 1.972715\n   nMoreExtreme size                           leadingEdge\n1:            0   86   GNLY,NKG7,GZMB,FGFBP2,CCL5,CST7,...\n2:            0   79 GNLY,GZMB,FGFBP2,KLRD1,SPON2,GZMH,...\n3:            0   84   GNLY,NKG7,GZMB,GZMA,CD247,KLRD1,...\n\n$`8`\n            pathway        pval       padj         ES       NES nMoreExtreme\n1:    Megakaryocyte 0.002577320 0.08490323  0.7934901  1.757021            2\n2:       Neutrophil 0.008846794 0.11600655 -0.6842598 -1.340588           84\n3: Mesenchymal cell 0.009494346 0.11600655 -0.7144618 -1.363128           88\n   size                                 leadingEdge\n1:   25         PPBP,PF4,GP9,ITGA2B,CD9,RASGRP2,...\n2:   80 PTPRC,ITGB2,S100A11,CD44,IFITM2,S100A12,...\n3:   58         S100A4,PTPRC,VIM,CD44,ZEB2,CTSC,...\n\n$`9`\n                 pathway         pval       padj        ES      NES\n1:      Mesenchymal cell 0.0001175917 0.02210724 0.8495970 1.678997\n2:          Stromal cell 0.0007528231 0.04569762 0.8602790 1.630578\n3: Endometrial stem cell 0.0029594138 0.06821588 0.9013667 1.560572\n   nMoreExtreme size                           leadingEdge\n1:            0   58   COTL1,S100A4,VIM,CTSC,HES4,ZEB2,...\n2:            5   38 VIM,PECAM1,TIMP1,CD44,TIMP2,ICAM3,...\n3:           20   18 PECAM1,CD44,PTPRC,ITGA4,ITGB1,ENG,...\n\n\n#CT_GSEA8:\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\nalldata@colData$cellmarker_gsea &lt;- new.cluster.ids[as.character(alldata@colData$louvain_SNNk15)]\n\nwrap_plots(\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"cellmarker_gsea\"),\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you think that the methods overlap well? Where do you see the most inconsistencies?\n\n\nIn this case we do not have any ground truth, and we cannot say which method performs best. You should keep in mind, that any celltype classification method is just a prediction, and you still need to use your common sense and knowledge of the biological system to judge if the results make sense.\nFinally, lets save the data with predictions.\n\nsaveRDS(ctrl.sce, \"data/covid/results/bioc_covid_qc_dr_int_cl_ct-ctrl13.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-session",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "8 Session info",
    "text": "8 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] fgsea_1.28.0                caret_6.0-94               \n [3] lattice_0.21-8              SeuratObject_4.1.3         \n [5] Seurat_4.3.0                scmap_1.24.0               \n [7] scPred_1.9.2                pheatmap_1.0.12            \n [9] patchwork_1.1.2             dplyr_1.1.2                \n[11] scran_1.30.0                scater_1.30.1              \n[13] ggplot2_3.4.2               scuttle_1.12.0             \n[15] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n[17] Biobase_2.62.0              GenomicRanges_1.54.1       \n[19] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[21] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[23] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.0-1     bitops_1.0-7             \n  [3] lubridate_1.9.2           httr_1.4.6               \n  [5] RColorBrewer_1.1-3        tools_4.3.0              \n  [7] sctransform_0.3.5         utf8_1.2.3               \n  [9] R6_2.5.1                  lazyeval_0.2.2           \n [11] uwot_0.1.14               withr_2.5.0              \n [13] sp_1.6-1                  gridExtra_2.3            \n [15] progressr_0.13.0          cli_3.6.1                \n [17] spatstat.explore_3.2-1    labeling_0.4.2           \n [19] spatstat.data_3.0-1       randomForest_4.7-1.1     \n [21] proxy_0.4-27              ggridges_0.5.4           \n [23] pbapply_1.7-0             harmony_1.2.0            \n [25] parallelly_1.36.0         limma_3.58.1             \n [27] rstudioapi_0.14           FNN_1.1.3.2              \n [29] generics_0.1.3            ica_1.0-3                \n [31] spatstat.random_3.1-5     Matrix_1.5-4             \n [33] ggbeeswarm_0.7.2          fansi_1.0.4              \n [35] abind_1.4-5               lifecycle_1.0.3          \n [37] yaml_2.3.7                edgeR_4.0.7              \n [39] recipes_1.0.6             SparseArray_1.2.3        \n [41] Rtsne_0.16                grid_4.3.0               \n [43] promises_1.2.0.1          dqrng_0.3.0              \n [45] crayon_1.5.2              miniUI_0.1.1.1           \n [47] beachmat_2.18.0           cowplot_1.1.1            \n [49] pillar_1.9.0              knitr_1.43               \n [51] metapod_1.10.1            future.apply_1.11.0      \n [53] codetools_0.2-19          fastmatch_1.1-3          \n [55] leiden_0.4.3              googleVis_0.7.1          \n [57] glue_1.6.2                data.table_1.14.8        \n [59] vctrs_0.6.2               png_0.1-8                \n [61] gtable_0.3.3              kernlab_0.9-32           \n [63] gower_1.0.1               xfun_0.39                \n [65] S4Arrays_1.2.0            mime_0.12                \n [67] prodlim_2023.03.31        survival_3.5-5           \n [69] timeDate_4022.108         iterators_1.0.14         \n [71] hardhat_1.3.0             lava_1.7.2.1             \n [73] statmod_1.5.0             bluster_1.12.0           \n [75] ellipsis_0.3.2            fitdistrplus_1.1-11      \n [77] ROCR_1.0-11               ipred_0.9-14             \n [79] nlme_3.1-162              RcppAnnoy_0.0.20         \n [81] irlba_2.3.5.1             vipor_0.4.5              \n [83] KernSmooth_2.23-20        rpart_4.1.19             \n [85] colorspace_2.1-0          nnet_7.3-18              \n [87] tidyselect_1.2.0          compiler_4.3.0           \n [89] BiocNeighbors_1.20.2      DelayedArray_0.28.0      \n [91] plotly_4.10.2             scales_1.2.1             \n [93] lmtest_0.9-40             stringr_1.5.0            \n [95] digest_0.6.31             goftest_1.2-3            \n [97] spatstat.utils_3.0-3      rmarkdown_2.22           \n [99] XVector_0.42.0            RhpcBLASctl_0.23-42      \n[101] htmltools_0.5.5           pkgconfig_2.0.3          \n[103] sparseMatrixStats_1.14.0  fastmap_1.1.1            \n[105] rlang_1.1.1               htmlwidgets_1.6.2        \n[107] shiny_1.7.4               DelayedMatrixStats_1.24.0\n[109] farver_2.1.1              zoo_1.8-12               \n[111] jsonlite_1.8.5            BiocParallel_1.36.0      \n[113] ModelMetrics_1.2.2.2      BiocSingular_1.18.0      \n[115] RCurl_1.98-1.12           magrittr_2.0.3           \n[117] GenomeInfoDbData_1.2.11   munsell_0.5.0            \n[119] Rcpp_1.0.10               viridis_0.6.3            \n[121] reticulate_1.30           stringi_1.7.12           \n[123] pROC_1.18.2               zlibbioc_1.48.0          \n[125] MASS_7.3-58.4             plyr_1.8.8               \n[127] parallel_4.3.0            listenv_0.9.0            \n[129] ggrepel_0.9.3             deldir_1.0-9             \n[131] splines_4.3.0             tensor_1.5               \n[133] locfit_1.5-9.8            igraph_1.4.3             \n[135] spatstat.geom_3.2-1       reshape2_1.4.4           \n[137] ScaledMatrix_1.10.0       evaluate_0.21            \n[139] foreach_1.5.2             httpuv_1.6.11            \n[141] RANN_2.6.1                tidyr_1.3.0              \n[143] purrr_1.0.1               polyclip_1.10-4          \n[145] future_1.32.0             scattermore_1.2          \n[147] rsvd_1.0.5                xtable_1.8-4             \n[149] e1071_1.7-13              later_1.3.1              \n[151] viridisLite_0.4.2         class_7.3-21             \n[153] tibble_3.2.1              beeswarm_0.4.0           \n[155] cluster_2.1.4             timechange_0.2.0         \n[157] globals_0.16.2"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html",
    "href": "labs/bioc/bioc_08_spatial.html",
    "title": " Spatial Transcriptomics",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nSpatial transcriptomic data with the Visium platform is in many ways similar to scRNAseq data. It contains UMI counts for 5-20 cells instead of single cells, but is still quite sparse in the same way as scRNAseq data is, but with the additional information about spatial location in the tissue.\nHere we will first run quality control in a similar manner to scRNAseq data, then QC filtering, dimensionality reduction, integration and clustering. Then we will use scRNAseq data from mouse cortex to run LabelTransfer to predict celltypes in the Visium spots.\nWe will use two Visium spatial transcriptomics dataset of the mouse brain (Sagittal), which are publicly available from the 10x genomics website. Note, that these dataset have already been filtered for spots that does not overlap with the tissue."
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-st_prep",
    "href": "labs/bioc/bioc_08_spatial.html#meta-st_prep",
    "title": " Spatial Transcriptomics",
    "section": "1 Preparation",
    "text": "1 Preparation\nLoad packages\n\n# BiocManager::install('DropletUtils',update = F)\n# BiocManager::install(\"Spaniel\",update = F)\n# remotes::install_github(\"RachelQueen1/Spaniel\", ref = \"Development\" ,upgrade = F,dependencies = F)\n# remotes::install_github(\"renozao/xbioc\")\n# remotes::install_github(\"meichendong/SCDC\")\n\nsuppressPackageStartupMessages({\n    library(Spaniel)\n    # library(biomaRt)\n    library(SingleCellExperiment)\n    library(Matrix)\n    library(dplyr)\n    library(scran)\n    library(SingleR)\n    library(scater)\n    library(ggplot2)\n    library(patchwork)\n})\n\nLoad ST data\n\npath_data &lt;- \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\n\nif (!dir.exists(\"data/spatial/visium/Anterior\")) dir.create(\"data/spatial/visium/Anterior\", recursive = T)\nif (!dir.exists(\"data/spatial/visium/Posterior\")) dir.create(\"data/spatial/visium/Posterior\", recursive = T)\n\nfile_list &lt;- c(\n    \"spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_filtered_feature_bc_matrix.tar.gz\",\n    \"spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_spatial.tar.gz\",\n    \"spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_filtered_feature_bc_matrix.tar.gz\",\n    \"spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_spatial.tar.gz\"\n)\n\nfor (i in file_list) {\n    if (!file.exists(file.path(\"data\", i))) {\n        cat(paste0(\"Downloading \", file.path(path_data, i), \" to \", file.path(\"data\", i), \"\\n\"))\n        download.file(url = file.path(path_data, i), destfile = file.path(\"data\", i))\n    }\n    cat(paste0(\"Uncompressing \", file.path(\"data\", i), \"\\n\"))\n    system(paste0(\"tar -xvzf \", file.path(\"data\", i), \" -C \", dirname(file.path(\"data\", i))))\n}\n\nDownloading https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_filtered_feature_bc_matrix.tar.gz to data/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_filtered_feature_bc_matrix.tar.gz\nUncompressing data/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_filtered_feature_bc_matrix.tar.gz\nDownloading https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_spatial.tar.gz to data/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_spatial.tar.gz\nUncompressing data/spatial/visium/Anterior/V1_Mouse_Brain_Sagittal_Anterior_spatial.tar.gz\nDownloading https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_filtered_feature_bc_matrix.tar.gz to data/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_filtered_feature_bc_matrix.tar.gz\nUncompressing data/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_filtered_feature_bc_matrix.tar.gz\nDownloading https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_spatial.tar.gz to data/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_spatial.tar.gz\nUncompressing data/spatial/visium/Posterior/V1_Mouse_Brain_Sagittal_Posterior_spatial.tar.gz\n\n\nMerge the objects into one SCE object.\n\nsce.a &lt;- Spaniel::createVisiumSCE(tenXDir = \"data/spatial/visium/Anterior\", resolution = \"Low\")\nsce.p &lt;- Spaniel::createVisiumSCE(tenXDir = \"data/spatial/visium/Posterior\", resolution = \"Low\")\nsce &lt;- cbind(sce.a, sce.p)\n\nsce$Sample &lt;- basename(sub(\"/filtered_feature_bc_matrix\", \"\", sce$Sample))\n\nlll &lt;- list(sce.a, sce.p)\nlll &lt;- lapply(lll, function(x) x@metadata)\nnames(lll) &lt;- c(\"Anterior\", \"Posterior\")\nsce@metadata &lt;- lll\n\nWe can further convert the gene ensembl IDs to gene names using biomaRt.\n\nmart &lt;- biomaRt::useMart(biomart = \"ENSEMBL_MART_ENSEMBL\", dataset = \"mmusculus_gene_ensembl\")\nannot &lt;- biomaRt::getBM(attributes = c(\"ensembl_gene_id\", \"external_gene_name\", \"gene_biotype\"), mart = mart, useCache = F)\nsaveRDS(annot, \"data/spatial/visium/annot.rds\")\n\nWe will use a file that was created in advance.\n\npath_file &lt;- \"data/spatial/visium/annot.rds\"\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"spatial/visium/annot.rds\"), destfile = path_file)\nannot &lt;- readRDS(path_file)\n\n\ngene_names &lt;- as.character(annot[match(rownames(sce), annot[, \"ensembl_gene_id\"]), \"external_gene_name\"])\ngene_names[is.na(gene_names)] &lt;- \"\"\n\nsce &lt;- sce[gene_names != \"\", ]\nrownames(sce) &lt;- gene_names[gene_names != \"\"]\ndim(sce)\n\n[1] 32053  6050"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-st_qc",
    "href": "labs/bioc/bioc_08_spatial.html#meta-st_qc",
    "title": " Spatial Transcriptomics",
    "section": "2 Quality control",
    "text": "2 Quality control\nSimilar to scRNA-seq we use statistics on number of counts, number of features and percent mitochondria for quality control.\nNow the counts and feature counts are calculated on the Spatial assay, so they are named nCount_Spatial and nFeature_Spatial.\n\n# Mitochondrial genes\nmito_genes &lt;- rownames(sce)[grep(\"^mt-\", rownames(sce))]\n\n# Ribosomal genes\nribo_genes &lt;- rownames(sce)[grep(\"^Rp[sl]\", rownames(sce))]\n\n# Hemoglobin genes - includes all genes starting with HB except HBP.\nhb_genes &lt;- rownames(sce)[grep(\"^Hb[^(p)]\", rownames(sce))]\n\nsce &lt;- addPerCellQC(sce, flatten = T, subsets = list(mt = mito_genes, hb = hb_genes, ribo = ribo_genes))\n\nhead(colData(sce))\n\nDataFrame with 6 rows and 24 columns\n       Sample            Barcode   Section    Spot_Y    Spot_X   Image_Y\n  &lt;character&gt;        &lt;character&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt;\n1    Anterior AAACAAGTATCTCCCA-1         1        50       102      7474\n2    Anterior AAACACCAATAACTGC-1         1        59        19      8552\n3    Anterior AAACAGAGCGACTCCT-1         1        14        94      3163\n4    Anterior AAACAGCTTTCAGAAG-1         1        43         9      6636\n5    Anterior AAACAGGGTCTATATT-1         1        47        13      7115\n6    Anterior AAACATGGTGAGAGGA-1         1        62         0      8912\n    Image_X   pixel_x   pixel_y       sum  detected     total       sum\n  &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt;\n1      8500   438.898   214.079     13991      4462     13991     13960\n2      2788   143.959   158.417     39797      8126     39797     39742\n3      7950   410.499   436.678     29951      6526     29951     29905\n4      2100   108.434   257.349     42333      8190     42333     42262\n5      2375   122.633   232.616     35700      8090     35700     35660\n6      1480    76.420   139.828     22148      6518     22148     22096\n   detected subsets_mt_sum subsets_mt_detected subsets_mt_percent\n  &lt;integer&gt;      &lt;numeric&gt;           &lt;integer&gt;          &lt;numeric&gt;\n1      4458           1521                  12           10.89542\n2      8116           3977                  12           10.00705\n3      6520           4265                  12           14.26183\n4      8181           2870                  12            6.79097\n5      8083           1831                  13            5.13460\n6      6509           2390                  12           10.81644\n  subsets_hb_sum subsets_hb_detected subsets_hb_percent subsets_ribo_sum\n       &lt;numeric&gt;           &lt;integer&gt;          &lt;numeric&gt;        &lt;numeric&gt;\n1             60                   4           0.429799              826\n2            831                   6           2.090987             2199\n3            111                   5           0.371175             1663\n4            117                   5           0.276844             3129\n5             73                   5           0.204711             2653\n6            134                   5           0.606445             1478\n  subsets_ribo_detected subsets_ribo_percent     total\n              &lt;integer&gt;            &lt;numeric&gt; &lt;numeric&gt;\n1                    85              5.91691     13960\n2                    89              5.53319     39742\n3                    88              5.56094     29905\n4                    88              7.40381     42262\n5                    90              7.43971     35660\n6                    84              6.68899     22096\n\nwrap_plots(plotColData(sce, y = \"detected\", x = \"Sample\", colour_by = \"Sample\"),\n    plotColData(sce, y = \"total\", x = \"Sample\", colour_by = \"Sample\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"Sample\", colour_by = \"Sample\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"Sample\", colour_by = \"Sample\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"Sample\", colour_by = \"Sample\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe can also plot the same data onto the tissue section.\n\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- c(\"detected\", \"total\", \"subsets_mt_percent\", \"subsets_ribo_percent\", \"subsets_hb_percent\")\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Cluster\",\n            clusterRes = j, customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\n\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\nAs you can see, the spots with low number of counts/features and high mitochondrial content are mainly towards the edges of the tissue. It is quite likely that these regions are damaged tissue. You may also see regions within a tissue with low quality if you have tears or folds in your section.\nBut remember, for some tissue types, the amount of genes expressed and proportion mitochondria may also be a biological features, so bear in mind what tissue you are working on and what these features mean.\n\n2.1 Filter spots\nSelect all spots with less than 25% mitocondrial reads, less than 20% hb-reads and 500 detected genes. You must judge for yourself based on your knowledge of the tissue what are appropriate filtering criteria for your dataset.\n\nsce &lt;- sce[, sce$detected &gt; 500 &\n    sce$subsets_mt_percent &lt; 25 &\n    sce$subsets_hb_percent &lt; 20]\ndim(sce)\n\n[1] 32053  5804\n\n\nAnd replot onto tissue section:\n\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- c(\"detected\", \"total\", \"subsets_mt_percent\", \"subsets_mt_percent\", \"subsets_hb_percent\")\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Cluster\",\n            clusterRes = j, customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\n\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n2.2 Top expressed genes\nAs for scRNA-seq data, we will look at what the top expressed genes are.\n\nC &lt;- counts(sce)\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p))\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])), cex = .1, las = 1, xlab = \"% total count per cell\", col = scales::hue_pal()(20)[20:1], horizontal = TRUE)\n\n\n\n\n\n\n\nrm(C)\n\nAs you can see, the mitochondrial genes are among the top expressed genes. Also the lncRNA gene Bc1 (brain cytoplasmic RNA 1). Also one hemoglobin gene.\n\n\n2.3 Filter genes\nWe will remove the Bc1 gene, hemoglobin genes (blood contamination) and the mitochondrial genes.\n\ndim(sce)\n\n[1] 32053  5804\n\n# Filter Bl1\nsce &lt;- sce[!grepl(\"Bc1\", rownames(sce)), ]\n\n# Filter Mitocondrial\nsce &lt;- sce[!grepl(\"^mt-\", rownames(sce)), ]\n\n# Filter Hemoglobin gene (optional if that is a problem on your data)\nsce &lt;- sce[!grepl(\"^Hb.*-\", rownames(sce)), ]\n\ndim(sce)\n\n[1] 32031  5804"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-st_analysis",
    "href": "labs/bioc/bioc_08_spatial.html#meta-st_analysis",
    "title": " Spatial Transcriptomics",
    "section": "3 Analysis",
    "text": "3 Analysis\nWe will proceed with the data in a very similar manner to scRNA-seq data.\n\nsce &lt;- computeSumFactors(sce, sizes = c(20, 40, 60, 80))\nsce &lt;- logNormCounts(sce)\n\nNow we can plot gene expression of individual genes, the gene Hpca is a strong hippocampal marker and Ttr is a marker of the choroid plexus.\n\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- c(\"Hpca\", \"Ttr\")\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Gene\",\n            gene = j,\n            customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\n\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\n\n3.1 Dimensionality reduction and clustering\nWe can then now run dimensionality reduction and clustering using the same workflow as we use for scRNA-seq analysis.\nBut make sure you run it on the SCT assay.\n\nvar.out &lt;- modelGeneVar(sce, method = \"loess\")\nhvgs &lt;- getTopHVGs(var.out, n = 2000)\nsce &lt;- runPCA(sce,\n    exprs_values = \"logcounts\",\n    subset_row = hvgs,\n    ncomponents = 50,\n    ntop = 100,\n    scale = T\n)\ng &lt;- buildSNNGraph(sce, k = 5, use.dimred = \"PCA\")\nsce$louvain_SNNk5 &lt;- factor(igraph::cluster_louvain(g)$membership)\nsce &lt;- runUMAP(sce,\n    dimred = \"PCA\", n_dimred = 50, ncomponents = 2, min_dist = 0.1, spread = .3,\n    metric = \"correlation\", name = \"UMAP_on_PCA\"\n)\n\nWe can then plot clusters onto umap or onto the tissue section.\n\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- c(\"louvain_SNNk5\")\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Cluster\", clusterRes = j,\n            customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\n\nplist[[3]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"louvain_SNNk5\")\nplist[[4]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"Sample\")\n\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n3.2 Integration\nQuite often there are strong batch effects between different ST sections, so it may be a good idea to integrate the data across sections.\nWe will do a similar integration as in the Data Integration lab.\n\nmnn_out &lt;- batchelor::fastMNN(sce, subset.row = hvgs, batch = factor(sce$Sample), k = 20, d = 50)\n\nreducedDim(sce, \"MNN\") &lt;- reducedDim(mnn_out, \"corrected\")\nrm(mnn_out)\ngc()\n\n            used   (Mb) gc trigger   (Mb)  max used   (Mb)\nNcells  10071341  537.9   14514548  775.2  14514548  775.2\nVcells 191849982 1463.7  373707381 2851.2 373703568 2851.2\n\n\nThen we run dimensionality reduction and clustering as before.\n\ng &lt;- buildSNNGraph(sce, k = 5, use.dimred = \"MNN\")\nsce$louvain_SNNk5 &lt;- factor(igraph::cluster_louvain(g)$membership)\nsce &lt;- runUMAP(sce,\n    dimred = \"MNN\", n_dimred = 50, ncomponents = 2, min_dist = 0.1, spread = .3,\n    metric = \"correlation\", name = \"UMAP_on_MNN\"\n)\n\n\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- c(\"louvain_SNNk5\")\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Cluster\", clusterRes = j,\n            customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\n\nplist[[3]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"louvain_SNNk5\")\nplist[[4]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"Sample\")\n\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you see any differences between the integrated and non-integrated clustering? Judge for yourself, which of the clusterings do you think looks best? As a reference, you can compare to brain regions in the Allen brain atlas.\n\n\n\n\n3.3 Spatially Variable Features\nThere are two main workflows to identify molecular features that correlate with spatial location within a tissue. The first is to perform differential expression based on spatially distinct clusters, the other is to find features that have spatial patterning without taking clusters or spatial annotation into account. First, we will do differential expression between clusters just as we did for the scRNAseq data before.\n\n# differential expression between cluster 4 and cluster 6\ncell_selection &lt;- sce[, sce$louvain_SNNk5 %in% c(4, 6)]\ncell_selection$louvain_SNNk5 &lt;- factor(cell_selection$louvain_SNNk5)\n\nmarkers_genes &lt;- scran::findMarkers(\n    x = cell_selection,\n    groups = cell_selection$louvain_SNNk5,\n    lfc = .25,\n    pval.type = \"all\",\n    direction = \"up\"\n)\n\n# List of dataFrames with the results for each cluster\ntop5_cell_selection &lt;- lapply(names(markers_genes), function(x) {\n    temp &lt;- markers_genes[[x]][1:5, 1:2]\n    temp$gene &lt;- rownames(markers_genes[[x]])[1:5]\n    temp$cluster &lt;- x\n    return(temp)\n})\ntop5_cell_selection &lt;- as_tibble(do.call(rbind, top5_cell_selection))\ntop5_cell_selection\n\n\n\n  \n\n\n# plot top markers\nsamples &lt;- c(\"Anterior\", \"Posterior\")\nto_plot &lt;- top5_cell_selection$gene[1:5]\n\nplist &lt;- list()\nn &lt;- 1\nfor (j in to_plot) {\n    for (i in samples) {\n        temp &lt;- sce[, sce$Sample == i]\n        temp@metadata &lt;- temp@metadata[[i]]\n        plist[[n]] &lt;- spanielPlot(\n            object = temp,\n            plotType = \"Gene\",\n            gene = j,\n            customTitle = j,\n            techType = \"Visium\",\n            ptSizeMax = 1, ptSizeMin = .1\n        )\n        n &lt;- n + 1\n    }\n}\nwrap_plots(plist, ncol = 2)"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-st_ss",
    "href": "labs/bioc/bioc_08_spatial.html#meta-st_ss",
    "title": " Spatial Transcriptomics",
    "section": "4 Single cell data",
    "text": "4 Single cell data\nWe can use a scRNA-seq dataset as a reference to predict the proportion of different celltypes in the Visium spots. Keep in mind that it is important to have a reference that contains all the celltypes you expect to find in your spots. Ideally it should be a scRNA-seq reference from the exact same tissue. We will use a reference scRNA-seq dataset of ~14,000 adult mouse cortical cell taxonomy from the Allen Institute, generated with the SMART-Seq2 protocol.\nFirst dowload the seurat data:\n\npath_file &lt;- \"data/spatial/visium/allen_cortex.rds\"\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"spatial/visium/allen_cortex.rds\"), destfile = path_file)\n\nFor speed, and for a more fair comparison of the celltypes, we will subsample all celltypes to a maximum of 200 cells per class (subclass).\n\nar &lt;- readRDS(path_file)\nar_sce &lt;- Seurat::as.SingleCellExperiment(ar)\nrm(ar)\ngc()\n\n            used   (Mb) gc trigger   (Mb)  max used   (Mb)\nNcells  10176004  543.5   18544292  990.4  18544292  990.4\nVcells 577825608 4408.5  833436874 6358.7 578228452 4411.6\n\n# check number of cells per subclass\nar_sce$subclass &lt;- sub(\"/\", \"_\", sub(\" \", \"_\", ar_sce$subclass))\ntable(ar_sce$subclass)\n\n\n     Astro         CR       Endo    L2_3_IT         L4      L5_IT      L5_PT \n       368          7         94        982       1401        880        544 \n     L6_CT      L6_IT        L6b      Lamp5 Macrophage      Meis2         NP \n       960       1872        358       1122         51         45        362 \n     Oligo       Peri      Pvalb   Serpinf1        SMC       Sncg        Sst \n        91         32       1337         27         55        125       1741 \n       Vip       VLMC \n      1728         67 \n\n# select 20 cells per subclass, fist set subclass as active.ident\nsubset_cells &lt;- lapply(unique(ar_sce$subclass), function(x) {\n    if (sum(ar_sce$subclass == x) &gt; 20) {\n        temp &lt;- sample(colnames(ar_sce)[ar_sce$subclass == x], size = 20)\n    } else {\n        temp &lt;- colnames(ar_sce)[ar_sce$subclass == x]\n    }\n})\nar_sce &lt;- ar_sce[, unlist(subset_cells)]\n\n# check again number of cells per subclass\ntable(ar_sce$subclass)\n\n\n     Astro         CR       Endo    L2_3_IT         L4      L5_IT      L5_PT \n        20          7         20         20         20         20         20 \n     L6_CT      L6_IT        L6b      Lamp5 Macrophage      Meis2         NP \n        20         20         20         20         20         20         20 \n     Oligo       Peri      Pvalb   Serpinf1        SMC       Sncg        Sst \n        20         20         20         20         20         20         20 \n       Vip       VLMC \n        20         20 \n\n\nThen run normalization and dimensionality reduction.\n\nar_sce &lt;- computeSumFactors(ar_sce, sizes = c(20, 40, 60, 80))\nar_sce &lt;- logNormCounts(ar_sce)\nallen.var.out &lt;- modelGeneVar(ar_sce, method = \"loess\")\nallen.hvgs &lt;- getTopHVGs(allen.var.out, n = 2000)"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-st_sub",
    "href": "labs/bioc/bioc_08_spatial.html#meta-st_sub",
    "title": " Spatial Transcriptomics",
    "section": "5 Subset ST for cortex",
    "text": "5 Subset ST for cortex\nSince the scRNAseq dataset was generated from the mouse cortex, we will subset the visium dataset in order to select mainly the spots part of the cortex. Note that the integration can also be performed on the whole brain slice, but it would give rise to false positive cell type assignments and therefore it should be interpreted with more care.\n\n5.1 Integrate with scRNAseq\nHere, will use SingleR for prediciting which cell types are present in the dataset. We can first select the anterior part as an example (to speed up predictions).\n\nsce.anterior &lt;- sce[, sce$Sample == \"Anterior\"]\nsce.anterior@metadata &lt;- sce.anterior@metadata[[\"Anterior\"]]\n\nNext, we select the highly variable genes that are present in both datasets.\n\n# Find common highly variable genes\ncommon_hvgs &lt;- intersect(allen.hvgs, hvgs)\n\n# Predict cell classes\npred.grun &lt;- SingleR(\n    test = sce.anterior[common_hvgs, ],\n    ref = ar_sce[common_hvgs, ],\n    labels = ar_sce$subclass\n)\n\n# Transfer the classes to the SCE object\nsce.anterior$cell_prediction &lt;- pred.grun$labels\nsce.anterior@colData &lt;- cbind(\n    sce.anterior@colData,\n    as.data.frame.matrix(table(list(1:ncol(sce.anterior), sce.anterior$cell_prediction)))\n)\n\nThen we can plot the predicted cell populations back to tissue.\n\n# Plot cell predictions\nspanielPlot(\n    object = sce.anterior,\n    plotType = \"Cluster\",\n    clusterRes = \"cell_prediction\",\n    customTitle = \"cell_prediction\",\n    techType = \"Visium\",\n    ptSizeMax = 1, ptSizeMin = .1\n)\n\n\n\n\n\n\n\n\n\nplist &lt;- list()\nn &lt;- 1\nfor (i in c(\"L2_3_IT\", \"L4\", \"L5_IT\", \"L6_IT\")) {\n    plist[[n]] &lt;- spanielPlot(\n        object = sce.anterior,\n        plotType = \"Cluster\",\n        clusterRes = i,\n        customTitle = i,\n        techType = \"Visium\", ptSize = .3,\n        ptSizeMax = 1, ptSizeMin = .1\n    )\n    n &lt;- n + 1\n}\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\n\nKeep in mind, that the scores are “just” prediction scores, and do not correspond to proportion of cells that are of a certain celltype or similar. It mainly tell you that gene expression in a certain spot is hihgly similar/dissimilar to gene expression of a celltype. If we look at the scores, we see that some spots got really clear predictions by celltype, while others did not have high scores for any of the celltypes.\nWe can also plot the gene expression and add filters together, too:\n\nspanielPlot(\n    object = sce.anterior,\n    plotType = \"Gene\",\n    gene = \"Wfs1\",\n    showFilter = sce.anterior$L4,\n    customTitle = \"\",\n    techType = \"Visium\",\n    ptSize = 0, ptSizeMin = -.3, ptSizeMax = 1\n)"
  },
  {
    "objectID": "labs/bioc/bioc_08_spatial.html#meta-session",
    "href": "labs/bioc/bioc_08_spatial.html#meta-session",
    "title": " Spatial Transcriptomics",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] patchwork_1.1.2             scater_1.30.1              \n [3] ggplot2_3.4.2               SingleR_2.4.1              \n [5] scran_1.30.0                scuttle_1.12.0             \n [7] dplyr_1.1.2                 Matrix_1.5-4               \n [9] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n[11] Biobase_2.62.0              GenomicRanges_1.54.1       \n[13] GenomeInfoDb_1.38.5         IRanges_2.36.0             \n[15] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[17] MatrixGenerics_1.14.0       matrixStats_1.0.0          \n[19] Spaniel_1.16.0             \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.20          batchelor_1.18.1         \n  [3] splines_4.3.0             later_1.3.1              \n  [5] bitops_1.0-7              R.oo_1.25.0              \n  [7] tibble_3.2.1              polyclip_1.10-4          \n  [9] lifecycle_1.0.3           edgeR_4.0.7              \n [11] globals_0.16.2            lattice_0.21-8           \n [13] MASS_7.3-58.4             magrittr_2.0.3           \n [15] limma_3.58.1              plotly_4.10.2            \n [17] rmarkdown_2.22            yaml_2.3.7               \n [19] metapod_1.10.1            httpuv_1.6.11            \n [21] Seurat_4.3.0              sctransform_0.3.5        \n [23] sp_1.6-1                  spatstat.sparse_3.0-1    \n [25] reticulate_1.30           cowplot_1.1.1            \n [27] pbapply_1.7-0             RColorBrewer_1.1-3       \n [29] ResidualMatrix_1.12.0     abind_1.4-5              \n [31] zlibbioc_1.48.0           Rtsne_0.16               \n [33] R.utils_2.12.2            purrr_1.0.1              \n [35] RCurl_1.98-1.12           GenomeInfoDbData_1.2.11  \n [37] ggrepel_0.9.3             irlba_2.3.5.1            \n [39] listenv_0.9.0             spatstat.utils_3.0-3     \n [41] goftest_1.2-3             spatstat.random_3.1-5    \n [43] dqrng_0.3.0               fitdistrplus_1.1-11      \n [45] parallelly_1.36.0         DelayedMatrixStats_1.24.0\n [47] DropletUtils_1.22.0       leiden_0.4.3             \n [49] codetools_0.2-19          DelayedArray_0.28.0      \n [51] tidyselect_1.2.0          farver_2.1.1             \n [53] viridis_0.6.3             ScaledMatrix_1.10.0      \n [55] spatstat.explore_3.2-1    jsonlite_1.8.5           \n [57] BiocNeighbors_1.20.2      ellipsis_0.3.2           \n [59] progressr_0.13.0          ggridges_0.5.4           \n [61] survival_3.5-5            tools_4.3.0              \n [63] ica_1.0-3                 Rcpp_1.0.10              \n [65] glue_1.6.2                gridExtra_2.3            \n [67] SparseArray_1.2.3         xfun_0.39                \n [69] HDF5Array_1.30.0          withr_2.5.0              \n [71] fastmap_1.1.1             rhdf5filters_1.14.1      \n [73] bluster_1.12.0            fansi_1.0.4              \n [75] digest_0.6.31             rsvd_1.0.5               \n [77] R6_2.5.1                  mime_0.12                \n [79] colorspace_2.1-0          scattermore_1.2          \n [81] tensor_1.5                spatstat.data_3.0-1      \n [83] R.methodsS3_1.8.2         utf8_1.2.3               \n [85] tidyr_1.3.0               generics_0.1.3           \n [87] data.table_1.14.8         httr_1.4.6               \n [89] htmlwidgets_1.6.2         S4Arrays_1.2.0           \n [91] uwot_0.1.14               pkgconfig_2.0.3          \n [93] gtable_0.3.3              lmtest_0.9-40            \n [95] XVector_0.42.0            htmltools_0.5.5          \n [97] SeuratObject_4.1.3        scales_1.2.1             \n [99] png_0.1-8                 knitr_1.43               \n[101] rstudioapi_0.14           reshape2_1.4.4           \n[103] nlme_3.1-162              rhdf5_2.46.1             \n[105] zoo_1.8-12                stringr_1.5.0            \n[107] KernSmooth_2.23-20        parallel_4.3.0           \n[109] miniUI_0.1.1.1            vipor_0.4.5              \n[111] pillar_1.9.0              grid_4.3.0               \n[113] vctrs_0.6.2               RANN_2.6.1               \n[115] promises_1.2.0.1          BiocSingular_1.18.0      \n[117] beachmat_2.18.0           xtable_1.8-4             \n[119] cluster_2.1.4             beeswarm_0.4.0           \n[121] evaluate_0.21             cli_3.6.1                \n[123] locfit_1.5-9.8            compiler_4.3.0           \n[125] rlang_1.1.1               crayon_1.5.2             \n[127] future.apply_1.11.0       labeling_0.4.2           \n[129] plyr_1.8.8                ggbeeswarm_0.7.2         \n[131] stringi_1.7.12            viridisLite_0.4.2        \n[133] deldir_1.0-9              BiocParallel_1.36.0      \n[135] munsell_0.5.0             lazyeval_0.2.2           \n[137] spatstat.geom_3.2-1       sparseMatrixStats_1.14.0 \n[139] future_1.32.0             Rhdf5lib_1.24.1          \n[141] statmod_1.5.0             shiny_1.7.4              \n[143] ROCR_1.0-11               igraph_1.4.3"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html",
    "href": "labs/scanpy/scanpy_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands."
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_data",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\nimport os\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_covid = \"./data/covid\"\nif not os.path.exists(path_covid):\n    os.makedirs(path_covid, exist_ok=True)\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\n\nimport urllib.request\n\nfile_list = [\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n]\n\nfor i in file_list:\n    path_file = os.path.join(path_covid, i)\n    if not os.path.exists(path_file):\n        file_url = os.path.join(path_data, \"covid\", i)\n        urllib.request.urlretrieve(file_url, path_file)\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80)\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\n\ndata_cov1 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_1.h5'))\ndata_cov1.var_names_make_unique()\ndata_cov15 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_15.h5'))\ndata_cov15.var_names_make_unique()\ndata_cov17 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_17.h5'))\ndata_cov17.var_names_make_unique()\ndata_ctrl5 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_5.h5'))\ndata_ctrl5.var_names_make_unique()\ndata_ctrl13 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_13.h5'))\ndata_ctrl13.var_names_make_unique()\ndata_ctrl14 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_14.h5'))\ndata_ctrl14.var_names_make_unique()\n\nreading ./data/covid/ncov_pbmc_1.h5\n (0:00:00)\nreading ./data/covid/ncov_pbmc_15.h5\n (0:00:00)\nreading ./data/covid/ncov_pbmc_17.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_5.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_13.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_14.h5\n (0:00:00)"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_collate",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\n\n# add some metadata\ndata_cov1.obs['type']=\"Covid\"\ndata_cov1.obs['sample']=\"covid_1\"\ndata_cov15.obs['type']=\"Covid\"\ndata_cov15.obs['sample']=\"covid_15\"\ndata_cov17.obs['type']=\"Covid\"\ndata_cov17.obs['sample']=\"covid_17\"\ndata_ctrl5.obs['type']=\"Ctrl\"\ndata_ctrl5.obs['sample']=\"ctrl_5\"\ndata_ctrl13.obs['type']=\"Ctrl\"\ndata_ctrl13.obs['sample']=\"ctrl_13\"\ndata_ctrl14.obs['type']=\"Ctrl\"\ndata_ctrl14.obs['sample']=\"ctrl_14\"\n\n# merge into one object.\nadata = data_cov1.concatenate(data_cov15, data_cov17, data_ctrl5, data_ctrl13, data_ctrl14)\n\n# and delete individual datasets to save space\ndel(data_cov1, data_cov15, data_cov17)\ndel(data_ctrl5, data_ctrl13, data_ctrl14)\n\nYou can print a summary of the datasets in the Scanpy object, or a summary of the whole object.\n\nprint(adata.obs['sample'].value_counts())\nadata\n\nsample\ncovid_1     1500\ncovid_15    1500\ncovid_17    1500\nctrl_5      1500\nctrl_13     1500\nctrl_14     1500\nName: count, dtype: int64\n\n\nAnnData object with n_obs × n_vars = 9000 × 33538\n    obs: 'type', 'sample', 'batch'\n    var: 'gene_ids', 'feature_types', 'genome'"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_calqc",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion hemoglobin genes can give an indication of red blood cell contamination. This will be helpful to visualize them across different metadata parameteres (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\nFirst, let Scanpy calculate some general qc-stats for genes and cells with the function sc.pp.calculate_qc_metrics, similar to calculateQCmetrics() in Scater. It can also calculate proportion of counts for specific gene populations, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.\n\n# mitochondrial genes\nadata.var['mt'] = adata.var_names.str.startswith('MT-') \n# ribosomal genes\nadata.var['ribo'] = adata.var_names.str.startswith((\"RPS\",\"RPL\"))\n# hemoglobin genes.\nadata.var['hb'] = adata.var_names.str.contains((\"^HB[^(P)]\"))\n\nadata.var\n\n\n\n\n\n\n\n\ngene_ids\nfeature_types\ngenome\nmt\nribo\nhb\n\n\n\n\nMIR1302-2HG\nENSG00000243485\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nFAM138A\nENSG00000237613\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nOR4F5\nENSG00000186092\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAL627309.1\nENSG00000238009\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAL627309.3\nENSG00000239945\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\nAC233755.2\nENSG00000277856\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC233755.1\nENSG00000275063\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC240274.1\nENSG00000271254\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC213203.1\nENSG00000277475\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nFAM231C\nENSG00000268674\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\n\n\n33538 rows × 6 columns\n\n\n\n\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt','ribo','hb'], percent_top=None, log1p=False, inplace=True)\n\nNow you can see that we have additional data in the metadata slot.\n\nmito_genes = adata.var_names.str.startswith('MT-')\n# for each cell compute fraction of counts in mito genes vs. all genes\n# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\nadata.obs['percent_mt2'] = np.sum(\n    adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n# add the total counts per cell as observations-annotation to adata\nadata.obs['n_counts'] = adata.X.sum(axis=1).A1\n\nadata\n\nAnnData object with n_obs × n_vars = 9000 × 33538\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_plotqc",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation= 45)\n\n\n\n\n\n\n\n\nAs you can see, there is quite some difference in quality for the 4 datasets, with for instance the covid_15 sample having fewer cells with many detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. And we can plot the different QC-measures as scatter plots.\n\nsc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color=\"sample\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_filter",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\n\nsc.pp.filter_cells(adata, min_genes=200)\nsc.pp.filter_genes(adata, min_cells=3)\n\nprint(adata.n_obs, adata.n_vars)\n\nfiltered out 897 cells that have less than 200 genes expressed\nfiltered out 14683 genes that are detected in less than 3 cells\n8103 18855\n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip for now as we are doing doublet prediction\n#keep_v2 = (adata.obs['n_genes_by_counts'] &lt; 2000) & (adata.obs['n_genes_by_counts'] &gt; 500) & (adata.obs['lib_prep'] == 'v2')\n#print(sum(keep_v2))\n\n# filter for gene detection for v3\n#keep_v3 = (adata.obs['n_genes_by_counts'] &lt; 4100) & (adata.obs['n_genes_by_counts'] &gt; 1000) & (adata.obs['lib_prep'] != 'v2')\n#print(sum(keep_v3))\n\n# keep both sets of cells\n#keep = (keep_v2) | (keep_v3)\n#print(sum(keep))\n#adata = adata[keep, :]\n\n#print(\"Remaining cells %d\"%adata.n_obs)\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\n\nsc.pl.highest_expr_genes(adata, n_top=20)\n\nnormalizing counts per cell\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\n# filter for percent mito\nadata = adata[adata.obs['pct_counts_mt'] &lt; 20, :]\n\n# filter for percent ribo &gt; 0.05\nadata = adata[adata.obs['pct_counts_ribo'] &gt; 5, :]\n\nprint(\"Remaining cells %d\"%adata.n_obs)\n\nRemaining cells 5888\n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats another time.\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation = 45)\n\n\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis.\n\nmalat1 = adata.var_names.str.startswith('MALAT1')\n# we need to redefine the mito_genes since they were first \n# calculated on the full object before removing low expressed genes.\nmito_genes = adata.var_names.str.startswith('MT-')\nhb_genes = adata.var_names.str.contains('^HB[^(P)]')\n\nremove = np.add(mito_genes, malat1)\nremove = np.add(remove, hb_genes)\nkeep = np.invert(remove)\n\nadata = adata[:,keep]\n\nprint(adata.n_obs, adata.n_vars)\n\n5888 18830"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_sex",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain you experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also bee a good way to detect if there has been any sample mixups, if the sample metadata sex does not agree with the computational predictions.\nTo get choromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. Hence, we will use biomart to fetch chromosome information.\n\n# requires pybiomart\nannot = sc.queries.biomart_annotations(\"hsapiens\", [\"ensembl_gene_id\", \"external_gene_name\", \"start_position\", \"end_position\", \"chromosome_name\"], ).set_index(\"external_gene_name\")\n# adata.var[annot.columns] = annot\n\nNow that we have the chromosome information, we can calculate per cell the proportion of reads that comes from chromosome Y.\n\nchrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"Y\"])\nchrY_genes\n\nadata.obs['percent_chrY'] = np.sum(\n    adata[:, chrY_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\n# color inputs must be from either .obs or .var, so add in XIST expression to obs.\nadata.obs[\"XIST-counts\"] = adata.X[:,adata.var_names.str.match('XIST')].toarray()\n\nsc.pl.scatter(adata, x='XIST-counts', y='percent_chrY', color=\"sample\")\n\n\n\n\n\n\n\n\nPlot as violins.\n\nsc.pl.violin(adata, [\"XIST-counts\", \"percent_chrY\"], jitter=0.4, groupby = 'sample', rotation= 45)\n\n\n\n\n\n\n\n\nHere, we can see clearly that we have two males and 4 females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_cellcycle",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\nFirst read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. We first download the file.\n\npath_file = os.path.join(path_results, 'regev_lab_cell_cycle_genes.txt')\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(path_data, 'regev_lab_cell_cycle_genes.txt'), path_file)\n\n\ncell_cycle_genes = [x.strip() for x in open('./data/covid/results/regev_lab_cell_cycle_genes.txt')]\nprint(len(cell_cycle_genes))\n\n# Split into 2 lists\ns_genes = cell_cycle_genes[:43]\ng2m_genes = cell_cycle_genes[43:]\n\ncell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]\nprint(len(cell_cycle_genes))\n\n97\n94\n\n\nBefore running cell cycle we have to normalize the data. In the scanpy object, the data slot will be overwritten with the normalized data. So first, save the raw data into the slot raw. Then run normalization, log transformation and scale the data.\n\n# save normalized counts in raw slot.\nadata.raw = adata\n\n# normalize to depth 10 000\nsc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n\n# logaritmize\nsc.pp.log1p(adata)\n\n# scale\nsc.pp.scale(adata)\n\nnormalizing by total count per cell\n    finished (0:00:00): normalized adata.X and added    'n_counts', counts per cell before normalization (adata.obs)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n\n\nWe here perform cell cycle scoring. The function is actually a wrapper to sc.tl.score_gene_list, which is launched twice, to score separately S and G2M phases. Both sc.tl.score_gene_list and sc.tl.score_cell_cycle_genes are a port from Seurat and are supposed to work in a very similar way. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\nsc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n\ncalculating cell cycle phase\ncomputing score 'S_score'\nWARNING: genes are not in var_names and ignored: ['MLF1IP']\n    finished: added\n    'S_score', score of gene set (adata.obs).\n    727 total control genes are used. (0:00:00)\ncomputing score 'G2M_score'\nWARNING: genes are not in var_names and ignored: ['FAM64A', 'HN1']\n    finished: added\n    'G2M_score', score of gene set (adata.obs).\n    771 total control genes are used. (0:00:00)\n--&gt;     'phase', cell cycle phase (adata.obs)\n\n\nWe can now plot a violin plot for the cell cycle scores as well.\n\nsc.pl.violin(adata, ['S_score', 'G2M_score'], jitter=0.4, groupby = 'sample', rotation=45)\n\n\n\n\n\n\n\n\nIn this case it looks like we only have a few cycling cells in the datasets."
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_doublet",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\n\n\n\n\n\n\nCaution\n\n\n\nIdeally doublet prediction should be run on each sample separately, especially if your different samples have different proportions of cell types. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs so it is okay to run them together.\n\n\nFor doublet detection, we will use the package Scrublet, so first we need to get the raw counts from adata.raw.X and run scrublet with that matrix. Then we add in the doublet prediction info into our anndata object.\nDoublet prediction should be run for each dataset separately, so first we need to split the adata object into 6 separate objects, one per sample and then run scrublet on each of them.\n\nimport scrublet as scr\n\n# split per batch into new objects.\nbatches = adata.obs['sample'].cat.categories.tolist()\nalldata = {}\nfor batch in batches:\n    tmp = adata[adata.obs['sample'] == batch,]\n    print(batch, \":\", tmp.shape[0], \" cells\")\n    scrub = scr.Scrublet(tmp.raw.X)\n    out = scrub.scrub_doublets(verbose=False, n_prin_comps = 20)\n    alldata[batch] = pd.DataFrame({'doublet_score':out[0],'predicted_doublets':out[1]},index = tmp.obs.index)\n    print(alldata[batch].predicted_doublets.sum(), \" predicted_doublets\")\n\ncovid_1 : 900  cells\n25  predicted_doublets\ncovid_15 : 599  cells\n8  predicted_doublets\ncovid_17 : 1101  cells\n18  predicted_doublets\nctrl_5 : 1052  cells\n24  predicted_doublets\nctrl_13 : 1173  cells\n56  predicted_doublets\nctrl_14 : 1063  cells\n32  predicted_doublets\n\n\n\n# add predictions to the adata object.\nscrub_pred = pd.concat(alldata.values())\nadata.obs['doublet_scores'] = scrub_pred['doublet_score'] \nadata.obs['predicted_doublets'] = scrub_pred['predicted_doublets'] \n\nsum(adata.obs['predicted_doublets'])\n\n163\n\n\nWe should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.\n\n# add in column with singlet/doublet instead of True/Fals\n%matplotlib inline\n\nadata.obs['doublet_info'] = adata.obs[\"predicted_doublets\"].astype(str)\nsc.pl.violin(adata, 'n_genes_by_counts', jitter=0.4, groupby = 'doublet_info', rotation=45)\n\n\n\n\n\n\n\n\nNow, lets run PCA and UMAP and plot doublet scores onto UMAP to check the doublet predictions.\n\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\nadata = adata[:, adata.var.highly_variable]\nsc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\nsc.pp.scale(adata, max_value=10)\nsc.tl.pca(adata, svd_solver='arpack')\nsc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color=['doublet_scores','doublet_info','sample'])\n\nextracting highly variable genes\n    finished (0:00:01)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nregressing out ['total_counts', 'pct_counts_mt']\n    finished (0:00:30)\ncomputing PCA\n    on highly variable genes\n    with n_comps=50\n    finished (0:00:01)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 40\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:07)\n\n\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\n# also revert back to the raw counts as the main matrix in adata\nadata = adata.raw.to_adata() \n\nadata = adata[adata.obs['doublet_info'] == 'False',:]\nprint(adata.shape)\n\n(5725, 18830)"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_save",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory results and save data to that folder. This will be used in downstream labs.\n\nadata.write_h5ad('data/covid/results/scanpy_covid_qc.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-session",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nannoy               NA\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfuture              0.18.3\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nlazy_loader         NA\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npybiomart           0.2.0\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrequests_cache      0.4.13\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nscrublet            NA\nseaborn             0.12.2\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nskimage             0.22.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsparse              0.14.0\nstack_data          0.6.2\nstatsmodels         0.14.1\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:17"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html",
    "href": "labs/scanpy/scanpy_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands."
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_prep",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport urllib.request\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\n# sc.logging.print_versions()\n\nsc.settings.set_figure_params(dpi=80)\n\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc.h5ad\"\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'covid/results/scanpy_covid_qc.h5ad'), path_file)\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 5725 × 18830\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'umap'\n    obsm: 'X_pca', 'X_umap'\n    obsp: 'connectivities', 'distances'\n\n\nBefore variable gene selection we need to normalize and log transform the data. Then store the full matrix in the raw slot before doing variable gene selection.\n\n# normalize to depth 10 000\nsc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n\n# log transform\nsc.pp.log1p(adata)\n\n# store normalized counts in the raw slot, \n# we will subset adata.X for variable genes, but want to keep all genes matrix as well.\nadata.raw = adata\n\nadata\n\nnormalizing by total count per cell\n    finished (0:00:00): normalized adata.X and added    'n_counts', counts per cell before normalization (adata.obs)\nWARNING: adata.X seems to be already log-transformed.\n\n\nAnnData object with n_obs × n_vars = 5725 × 18830\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'umap'\n    obsm: 'X_pca', 'X_umap'\n    obsp: 'connectivities', 'distances'"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_fs",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nNext, we first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\n\n# compute variable genes\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\nprint(\"Highly variable genes: %d\"%sum(adata.var.highly_variable))\n\n#plot variable genes\nsc.pl.highly_variable_genes(adata)\n\n# subset for variable genes in the dataset\nadata = adata[:, adata.var['highly_variable']]\n\nextracting highly variable genes\n    finished (0:00:01)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes: 2727"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_zs",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the data is prepared, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling is called Z-score normalization it is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\n\n#run this line if you get the \"AttributeError: swapaxes not found\" \n# adata = adata.copy()\n\n# regress out unwanted variables\nsc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\n\n# scale data, clip values exceeding standard deviation 10.\nsc.pp.scale(adata, max_value=10)\n\nregressing out ['total_counts', 'pct_counts_mt']\n    sparse input is densified and may lead to high memory use\n    finished (0:00:37)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_pca",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of life sciences, we want to segregate samples based on gene expression patterns in the data.\nTo run PCA, you can use the function pca().\n\nsc.tl.pca(adata, svd_solver='arpack')\n\ncomputing PCA\n    on highly variable genes\n    with n_comps=50\n    finished (0:00:02)\n\n\nWe then plot the first principal components.\n\n# plot more PCS\nsc.pl.pca(adata, color='sample', components = ['1,2','3,4','5,6','7,8'], ncols=2)\n\n\n\n\n\n\n\n\nTo identify genes that contribute most to each PC, one can retrieve the loading matrix information.\n\n#Plot loadings\nsc.pl.pca_loadings(adata, components=[1,2,3,4,5,6,7,8])\n\n# OBS! only plots the positive axes genes from each PC!!\n\n\n\n\n\n\n\n\nThe function to plot loading genes only plots genes on the positive axes. Instead plot as a heatmaps, with genes on both positive and negative side, one per pc, and plot their expression amongst cells ordered by their position along the pc.\n\n# adata.obsm[\"X_pca\"] is the embeddings\n# adata.uns[\"pca\"] is pc variance\n# adata.varm['PCs'] is the loadings\n\ngenes = adata.var['gene_ids']\n\nfor pc in [1,2,3,4]:\n    g = adata.varm['PCs'][:,pc-1]\n    o = np.argsort(g)\n    sel = np.concatenate((o[:10],o[-10:])).tolist()\n    emb = adata.obsm['X_pca'][:,pc-1]\n    # order by position on that pc\n    tempdata = adata[np.argsort(emb),]\n    sc.pl.heatmap(tempdata, var_names = genes[sel].index.tolist(), groupby='predicted_doublets', swap_axes = True, use_raw=False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also plot the amount of variance explained by each PC.\n\nsc.pl.pca_variance_ratio(adata, log=True, n_pcs = 50)\n\n\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_tsne",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe can now run BH-tSNE.\n\nsc.tl.tsne(adata, n_pcs = 30)\n\ncomputing tSNE\n    using 'X_pca' with n_pcs = 30\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm) (0:00:10)\n\n\nWe can now plot the tSNE colored per dataset. We can clearly see the effect of batches present in the dataset.\n\nsc.pl.tsne(adata, color='sample')"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_umap",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nThe UMAP implementation in SCANPY uses a neighborhood graph as the distance matrix, so we need to first calculate the graph.\n\nsc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20)\n\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\n\n\nWe can now run UMAP for cell embeddings.\n\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='sample')\n\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:09)\n\n\n\n\n\n\n\n\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\n# run with 10 components, save to a new object so that the umap with 2D is not overwritten.\numap10 = sc.tl.umap(adata, n_components=10, copy=True)\nfig, axs = plt.subplots(1, 3, figsize=(10, 4), constrained_layout=True)\n\nsc.pl.umap(adata, color='sample',  title=\"UMAP\",\n           show=False, ax=axs[0], legend_loc=None)\nsc.pl.umap(umap10, color='sample', title=\"UMAP10\", show=False,\n           ax=axs[1], components=['1,2'], legend_loc=None)\nsc.pl.umap(umap10, color='sample', title=\"UMAP10\",\n           show=False, ax=axs[2], components=['3,4'], legend_loc=None)\n\n# we can also plot the umap with neighbor edges\nsc.pl.umap(adata, color='sample', title=\"UMAP\", edges=True)\n\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE, what similarities/differences do you see, can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 8), constrained_layout=True)\nsc.pl.pca(adata, color='sample', components=['1,2'], ax=axs[0, 0], show=False)\nsc.pl.tsne(adata, color='sample', components=['1,2'], ax=axs[0, 1], show=False)\nsc.pl.umap(adata, color='sample', components=['1,2'], ax=axs[1, 0], show=False)\n\n&lt;Axes: title={'center': 'sample'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\nFinally, we can compare the PCA, tSNE and UMAP.\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "7 Genes of interest",
    "text": "7 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nsc.pl.umap(adata, color=[\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR3A\"])\n\n\n\n\n\n\n\n\nThe default is to plot gene expression in the normalized and log-transformed data. You can also plot it on the scaled and corrected data by using use_raw=False. However, not all of these genes are included in the variable gene set so we first need to filter them.\n\ngenes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR3A\"]\nvar_genes = adata.var.highly_variable\nvar_genes.index[var_genes]\nvarg = [x for x in genes if x in var_genes.index[var_genes]]\nsc.pl.umap(adata, color=varg, use_raw=False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_save",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "8 Save data",
    "text": "8 Save data\nWe can finally save the object for use in future steps.\n\nadata.write_h5ad('data/covid/results/scanpy_covid_qc_dr.h5ad')\n\n\nprint(adata.X.shape)\nprint(adata.raw.X.shape)\n\n(5725, 2727)\n(5725, 18830)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-session",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "9 Session info",
    "text": "9 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnetworkx            3.2.1\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsparse              0.14.0\nstack_data          0.6.2\nstatsmodels         0.14.1\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:19"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html",
    "href": "labs/scanpy/scanpy_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-int_prep",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport urllib.request\n\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3             \n\nsc.settings.set_figure_params(dpi=80)\n%matplotlib inline\n\nCreate individual adata objects per batch.\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc_dr.h5ad\"\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'covid/results/scanpy_covid_qc_dr.h5ad'), path_file)\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 5725 × 2727\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n    obsm: 'X_pca', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'\n\n\n\nprint(adata.X.shape)\n\n(5725, 2727)\n\n\nAs the stored AnnData object contains scaled data based on variable genes, we need to make a new object with the logtransformed normalized counts. The new variable gene selection should not be performed on the scaled data matrix.\n\nadata2 = adata.raw.to_adata() \n\nadata2.uns['log1p']['base']=None\n\n# check that the matrix looks like normalized counts\nprint(adata2.X[1:10,1:10])\n\n  (0, 2)    0.7825693876867097\n  (7, 5)    1.1311041336746985"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#detect-variable-genes",
    "href": "labs/scanpy/scanpy_03_integration.html#detect-variable-genes",
    "title": " Data Integration",
    "section": "2 Detect variable genes",
    "text": "2 Detect variable genes\nVariable genes can be detected across the full dataset, but then we run the risk of getting many batch-specific genes that will drive a lot of the variation. Or we can select variable genes from each batch separately to get only celltype variation. In the dimensionality reduction exercise, we already selected variable genes, so they are already stored in adata.var.highly_variable.\n\nvar_genes_all = adata.var.highly_variable\n\nprint(\"Highly variable genes: %d\"%sum(var_genes_all))\n\nHighly variable genes: 2727\n\n\nDetect variable genes in each dataset separately using the batch_key parameter.\n\nsc.pp.highly_variable_genes(adata2, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key = 'sample')\n\nprint(\"Highly variable genes intersection: %d\"%sum(adata2.var.highly_variable_intersection))\n\nprint(\"Number of batches where gene is variable:\")\nprint(adata2.var.highly_variable_nbatches.value_counts())\n\nvar_genes_batch = adata2.var.highly_variable_nbatches &gt; 0\n\nextracting highly variable genes\n    finished (0:00:02)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes intersection: 196\nNumber of batches where gene is variable:\nhighly_variable_nbatches\n0    8436\n1    4729\n2    3037\n3    1504\n4     627\n5     301\n6     196\nName: count, dtype: int64\n\n\nCompare overlap of variable genes with batches or with all data.\n\nprint(\"Any batch var genes: %d\"%sum(var_genes_batch))\nprint(\"All data var genes: %d\"%sum(var_genes_all))\nprint(\"Overlap: %d\"%sum(var_genes_batch & var_genes_all))\nprint(\"Variable genes in all batches: %d\"%sum(adata2.var.highly_variable_nbatches == 6))\nprint(\"Overlap batch instersection and all: %d\"%sum(var_genes_all & adata2.var.highly_variable_intersection))\n\nAny batch var genes: 10394\nAll data var genes: 2727\nOverlap: 2724\nVariable genes in all batches: 196\nOverlap batch instersection and all: 193\n\n\nSelect all genes that are variable in at least 2 datasets and use for remaining analysis.\n\nvar_select = adata2.var.highly_variable_nbatches &gt; 2\nvar_genes = var_select.index[var_select]\nlen(var_genes)\n\n2628"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#bbknn",
    "href": "labs/scanpy/scanpy_03_integration.html#bbknn",
    "title": " Data Integration",
    "section": "3 BBKNN",
    "text": "3 BBKNN\nFirst, we will run BBKNN that is implemented in scanpy.\n\nimport bbknn\nbbknn.bbknn(adata2,batch_key='sample')\n\n# then run umap on the integrated space\nsc.tl.umap(adata2)\nsc.tl.tsne(adata2)\n\ncomputing batch balanced neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:02)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:09)\ncomputing tSNE\n    using 'X_pca' with n_pcs = 50\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm) (0:00:10)\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.tsne(adata2, color=\"sample\", title=\"BBKNN Corrected tsne\", ax=axs[0,0], show=False)\nsc.pl.tsne(adata, color=\"sample\", title=\"Uncorrected tsne\", ax=axs[0,1], show=False)\nsc.pl.umap(adata2, color=\"sample\", title=\"BBKNN Corrected umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Uncorrected umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Uncorrected umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\nsave_file = './data/covid/results/scanpy_covid_qc_dr_bbknn.h5ad'\nadata2.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#combat",
    "href": "labs/scanpy/scanpy_03_integration.html#combat",
    "title": " Data Integration",
    "section": "4 Combat",
    "text": "4 Combat\nBatch correction can also be performed with combat. Note that ComBat batch correction requires a dense matrix format as input (which is already the case in this example).\n\n# create a new object with lognormalized counts\nadata_combat = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs = adata.obs)\n\n# first store the raw data \nadata_combat.raw = adata_combat\n\n# run combat\nsc.pp.combat(adata_combat, key='sample')\n\nStandardizing Data across genes.\n\nFound 6 batches\n\nFound 0 numerical variables:\n    \n\nFound 37 genes with zero variance.\nFitting L/S model and finding priors\n\nFinding parametric adjustments\n\nAdjusting data\n\n\n\nThen we run the regular steps of dimensionality reduction on the combat corrected data. Variable gene selection, pca and umap with combat data.\n\nsc.pp.highly_variable_genes(adata_combat)\nprint(\"Highly variable genes: %d\"%sum(adata_combat.var.highly_variable))\nsc.pl.highly_variable_genes(adata_combat)\n\nsc.pp.pca(adata_combat, n_comps=30, use_highly_variable=True, svd_solver='arpack')\n\nsc.pp.neighbors(adata_combat)\n\nsc.tl.umap(adata_combat)\nsc.tl.tsne(adata_combat)\n\nextracting highly variable genes\n    finished (0:00:01)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes: 3533\ncomputing PCA\n    on highly variable genes\n    with n_comps=30\n    finished (0:00:01)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:08)\ncomputing tSNE\n    using 'X_pca' with n_pcs = 30\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm) (0:00:09)\n\n\n\n\n\n\n\n\n\n\n# compare var_genes\nvar_genes_combat = adata_combat.var.highly_variable\nprint(\"With all data %d\"%sum(var_genes_all))\nprint(\"With combat %d\"%sum(var_genes_combat))\nprint(\"Overlap %d\"%sum(var_genes_all & var_genes_combat))\n\nprint(\"With 2 batches %d\"%sum(var_select))\nprint(\"Overlap %d\"%sum(var_genes_combat & var_select))\n\nWith all data 2727\nWith combat 3533\nOverlap 2003\nWith 2 batches 2628\nOverlap 1896\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.tsne(adata2, color=\"sample\", title=\"BBKNN tsne\", ax=axs[0,0], show=False)\nsc.pl.tsne(adata_combat, color=\"sample\", title=\"Combat tsne\", ax=axs[0,1], show=False)\nsc.pl.umap(adata2, color=\"sample\", title=\"BBKNN umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata_combat, color=\"sample\", title=\"Combat umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Combat umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\n#save to file\nsave_file = './data/covid/results/scanpy_covid_qc_dr_combat.h5ad'\nadata_combat.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-int_scanorama",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-int_scanorama",
    "title": " Data Integration",
    "section": "5 Scanorama",
    "text": "5 Scanorama\nTry out Scanorama for data integration as well. First we need to create individual AnnData objects from each of the datasets.\n\n# split per batch into new objects.\nbatches = adata.obs['sample'].cat.categories.tolist()\nalldata = {}\nfor batch in batches:\n    alldata[batch] = adata2[adata2.obs['sample'] == batch,]\n\nalldata   \n\n{'covid_1': View of AnnData object with n_obs × n_vars = 875 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances',\n 'covid_15': View of AnnData object with n_obs × n_vars = 591 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances',\n 'covid_17': View of AnnData object with n_obs × n_vars = 1083 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances',\n 'ctrl_5': View of AnnData object with n_obs × n_vars = 1028 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances',\n 'ctrl_13': View of AnnData object with n_obs × n_vars = 1117 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances',\n 'ctrl_14': View of AnnData object with n_obs × n_vars = 1031 × 18830\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n     obsm: 'X_pca', 'X_tsne', 'X_umap'\n     obsp: 'connectivities', 'distances'}\n\n\n\nimport scanorama\n\n#subset the individual dataset to the variable genes we defined at the beginning\nalldata2 = dict()\nfor ds in alldata.keys():\n    print(ds)\n    alldata2[ds] = alldata[ds][:,var_genes]\n\n#convert to list of AnnData objects\nadatas = list(alldata2.values())\n\n# run scanorama.integrate\nscanorama.integrate_scanpy(adatas, dimred = 50)\n\ncovid_1\ncovid_15\ncovid_17\nctrl_5\nctrl_13\nctrl_14\nFound 2628 genes among all datasets\n[[0.         0.74450085 0.2843952  0.63521401 0.456      0.37485714]\n [0.         0.         0.5177665  0.48346304 0.32656514 0.36886633]\n [0.         0.         0.         0.32976654 0.11080332 0.15327793]\n [0.         0.         0.         0.         0.83754864 0.74319066]\n [0.         0.         0.         0.         0.         0.85675918]\n [0.         0.         0.         0.         0.         0.        ]]\nProcessing datasets (4, 5)\nProcessing datasets (3, 4)\nProcessing datasets (0, 1)\nProcessing datasets (3, 5)\nProcessing datasets (0, 3)\nProcessing datasets (1, 2)\nProcessing datasets (1, 3)\nProcessing datasets (0, 4)\nProcessing datasets (0, 5)\nProcessing datasets (1, 5)\nProcessing datasets (2, 3)\nProcessing datasets (1, 4)\nProcessing datasets (0, 2)\nProcessing datasets (2, 5)\nProcessing datasets (2, 4)\n\n\n\n#scanorama adds the corrected matrix to adata.obsm in each of the datasets in adatas.\nadatas[0].obsm['X_scanorama'].shape\n\n(875, 50)\n\n\n\n# Get all the integrated matrices.\nscanorama_int = [ad.obsm['X_scanorama'] for ad in adatas]\n\n# make into one matrix.\nall_s = np.concatenate(scanorama_int)\nprint(all_s.shape)\n\n# add to the AnnData object, create a new object first\nadata_sc = adata.copy()\nadata_sc.obsm[\"Scanorama\"] = all_s\n\n(5725, 50)\n\n\n\n# tsne and umap\nsc.pp.neighbors(adata_sc, n_pcs =30, use_rep = \"Scanorama\")\nsc.tl.umap(adata_sc)\nsc.tl.tsne(adata_sc, n_pcs = 30, use_rep = \"Scanorama\")\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:08)\ncomputing tSNE\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm) (0:00:09)\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(adata2, color=\"sample\", title=\"BBKNN tsne\", ax=axs[0,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Scanorama tsne\", ax=axs[0,1], show=False)\nsc.pl.umap(adata2, color=\"sample\", title=\"BBKNN umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Scanorama umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Scanorama umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\n#save to file\nsave_file = './data/covid/results/scanpy_covid_qc_dr_scanorama.h5ad'\nadata_sc.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#compare-all",
    "href": "labs/scanpy/scanpy_03_integration.html#compare-all",
    "title": " Data Integration",
    "section": "6 Compare all",
    "text": "6 Compare all\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot umap of all the methods we tested here. Which do you think looks better and why?\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(adata, color=\"sample\", title=\"Uncorrected\", ax=axs[0,0], show=False)\nsc.pl.umap(adata2, color=\"sample\", title=\"BBKNN\", ax=axs[0,1], show=False)\nsc.pl.umap(adata_combat, color=\"sample\", title=\"Combat\", ax=axs[1,0], show=False)\nsc.pl.umap(adata_sc, color=\"sample\", title=\"Scanorama\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Scanorama'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the documentation for BBKNN\nTry changing some of the parameteres in BBKNN, such as distance metric, number of PCs and number of neighbors. How does the results change with different parameters? Can you explain why?"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-session",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nannoy               NA\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\nbbknn               1.6.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfbpca               NA\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nintervaltree        NA\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscanorama           1.7.4\nscipy               1.11.4\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsortedcontainers    2.4.0\nsparse              0.14.0\nstack_data          0.6.2\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:21"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html",
    "href": "labs/scanpy/scanpy_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nIn this tutorial we will continue the analysis of the integrated dataset. We will use the scanpy enbedding to perform the clustering using graph community detection algorithms.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport urllib.request\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80)\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc_dr_scanorama.h5ad\"\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'covid/results/scanpy_covid_qc_dr_scanorama.h5ad'), path_file)\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 5725 × 2727\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n    obsm: 'Scanorama', 'X_pca', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_graphclust",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps: 1) Build a kNN graph from the data. 2) Prune spurious connections from kNN graph (optional step). This is a SNN graph. 3) Find groups of cells that maximizes the connections within the group compared other groups.\nIf you recall from the integration, we already constructed a knn graph before running UMAP. Hence we do not need to do it again, and can run the community detection right away.\nThe modularity optimization algoritm in Scanpy are Leiden and Louvain. Lets test both and see how they compare.\n\n1.1 Leiden\n\nsc.tl.leiden(adata, key_added = \"leiden_1.0\") # default resolution in 1.0\nsc.tl.leiden(adata, resolution = 0.6, key_added = \"leiden_0.6\")\nsc.tl.leiden(adata, resolution = 0.4, key_added = \"leiden_0.4\")\nsc.tl.leiden(adata, resolution = 1.4, key_added = \"leiden_1.4\")\n\nrunning Leiden clustering\n    finished: found 16 clusters and added\n    'leiden_1.0', the cluster labels (adata.obs, categorical) (0:00:01)\nrunning Leiden clustering\n    finished: found 12 clusters and added\n    'leiden_0.6', the cluster labels (adata.obs, categorical) (0:00:01)\nrunning Leiden clustering\n    finished: found 10 clusters and added\n    'leiden_0.4', the cluster labels (adata.obs, categorical) (0:00:01)\nrunning Leiden clustering\n    finished: found 18 clusters and added\n    'leiden_1.4', the cluster labels (adata.obs, categorical) (0:00:02)\n\n\nPlot the clusters, as you can see, with increased resolution, we get higher granularity in the clustering.\n\nsc.pl.umap(adata, color=['leiden_0.4', 'leiden_0.6', 'leiden_1.0','leiden_1.4'])\n\n\n\n\n\n\n\n\nOnce we have done clustering, the relationships between clusters can be calculated as correlation in PCA space and we also visualize some of the marker genes that we used in the Dim Reduction lab onto the clusters.\n\nsc.tl.dendrogram(adata, groupby = \"leiden_0.6\")\nsc.pl.dendrogram(adata, groupby = \"leiden_0.6\")\n\ngenes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"FCGR3A\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR1A\"]\nsc.pl.dotplot(adata, genes, groupby='leiden_0.6', dendrogram=True)\n\n    using 'X_pca' with n_pcs = 50\nStoring dendrogram info using `.uns['dendrogram_leiden_0.6']`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot proportion of cells from each condition per cluster.\n\ntmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['type'], normalize='index')\ntmp.plot.bar(stacked=True).legend(loc='upper right')\n\n&lt;matplotlib.legend.Legend at 0x7ffff99a2c20&gt;\n\n\n\n\n\n\n\n\n\n\n\n1.2 Louvain\n\nsc.tl.louvain(adata, key_added = \"louvain_1.0\") # default resolution in 1.0\nsc.tl.louvain(adata, resolution = 0.6, key_added = \"louvain_0.6\")\nsc.tl.louvain(adata, resolution = 0.4, key_added = \"louvain_0.4\")\nsc.tl.louvain(adata, resolution = 1.4, key_added = \"louvain_1.4\")\n\nsc.pl.umap(adata, color=['louvain_0.4', 'louvain_0.6', 'louvain_1.0','louvain_1.4'])\n\nsc.tl.dendrogram(adata, groupby = \"louvain_0.6\")\nsc.pl.dendrogram(adata, groupby = \"louvain_0.6\")\n\ngenes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"FCGR3A\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR1A\"]\n\nsc.pl.dotplot(adata, genes, groupby='louvain_0.6', dendrogram=True)\n\nrunning Louvain clustering\n    using the \"louvain\" package of Traag (2017)\n    finished: found 12 clusters and added\n    'louvain_1.0', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Louvain clustering\n    using the \"louvain\" package of Traag (2017)\n    finished: found 9 clusters and added\n    'louvain_0.6', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Louvain clustering\n    using the \"louvain\" package of Traag (2017)\n    finished: found 7 clusters and added\n    'louvain_0.4', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Louvain clustering\n    using the \"louvain\" package of Traag (2017)\n    finished: found 17 clusters and added\n    'louvain_1.4', the cluster labels (adata.obs, categorical) (0:00:00)\n    using 'X_pca' with n_pcs = 50\nStoring dendrogram info using `.uns['dendrogram_louvain_0.6']`"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_kmean",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\n\n# extract pca coordinates\nX_pca = adata.obsm['Scanorama'] \n\n# kmeans with k=5\nkmeans = KMeans(n_clusters=5, random_state=0).fit(X_pca) \nadata.obs['kmeans5'] = kmeans.labels_.astype(str)\n\n# kmeans with k=10\nkmeans = KMeans(n_clusters=10, random_state=0).fit(X_pca) \nadata.obs['kmeans10'] = kmeans.labels_.astype(str)\n\n# kmeans with k=15\nkmeans = KMeans(n_clusters=15, random_state=0).fit(X_pca)\nadata.obs['kmeans15'] = kmeans.labels_.astype(str)\n\nsc.pl.umap(adata, color=['kmeans5', 'kmeans10', 'kmeans15'])\n\nadata.obsm\n\n\n\n\n\n\n\n\nAxisArrays with keys: Scanorama, X_pca, X_tsne, X_umap"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_hier",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\nHierarchical clustering is another generic form of clustering that can be applied also to scRNA-seq data. As K-means, it is typically applied to a reduced dimension representation of the data. Hierarchical clustering returns an entire hierarchy of partitionings (a dendrogram) that can be cut at different levels. Hierarchical clustering is done in these steps:\n\nDefine the distances between samples. The most common are Euclidean distance (a.k.a. straight line between two points) or correlation coefficients.\nDefine a measure of distances between clusters, called linkage criteria. It can for example be average distances between clusters. Commonly used methods are single, complete, average, median, centroid and ward.\nDefine the dendrogram among all samples using Bottom-up or Top-down approach. Bottom-up is where samples start with their own cluster which end up merged pair-by-pair until only one cluster is left. Top-down is where samples start all in the same cluster that end up being split by 2 until each sample has its own cluster.\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n[adj = ]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\nThe function AgglomerativeClustering has the option of running with disntance metrics “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. However, with ward linkage only euklidean distances works. Here we will try out euclidean distance and ward linkage calculated in PCA space.\n\nfrom sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\nadata.obs['hclust_5'] = cluster.fit_predict(X_pca).astype(str)\n\ncluster = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')\nadata.obs['hclust_10'] = cluster.fit_predict(X_pca).astype(str)\n\ncluster = AgglomerativeClustering(n_clusters=15, affinity='euclidean', linkage='ward')\nadata.obs['hclust_15'] = cluster.fit_predict(X_pca).astype(str)\n\nsc.pl.umap(adata, color=['hclust_5', 'hclust_10', 'hclust_15'])\n\n\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nadata.write_h5ad('./data/covid/results/scanpy_covid_qc_dr_scanorama_cl.h5ad')\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated due to quality metrics. Could it be explained biologically, or could you have technical bias there?"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-session",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "4 Session info",
    "text": "4 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nstack_data          0.6.2\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:22"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html",
    "href": "labs/scanpy/scanpy_05_dge.html",
    "title": " Differential gene expression",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nIn this tutorial we will cover about Differetial gene expression, which comprises an extensive range of topics and methods. In single cell, differential expresison can have multiple functionalities such as of identifying marker genes for cell populations, as well as differentially regulated genes across conditions (healthy vs control). We will also exercise on how to account the batch information in your test.\nDifferential expression is performed with the function rank_genes_group. The default method to compute differential expression is the t-test_overestim_var. Other implemented methods are: logreg, t-test and wilcoxon.\nBy default, the .raw attribute of AnnData is used in case it has been initialized, it can be changed by setting use_raw=False.\nThe clustering with resolution 0.6 seems to give a reasonable number of clusters, so we will use that clustering for all DE tests.\nFirst, let’s import libraries and fetch the clustered data from the previous lab.\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport gseapy\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport urllib.request\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 2\n\nsc.settings.set_figure_params(dpi=80)\nRead in the clustered data object.\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n   \n# path_file = \"data/covid/results/scanpy_covid_qc_dr_scanorama_cl.h5ad\"\npath_file = \"data/covid/results/scanpy_clustered_covid.h5ad\"\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'covid/results/scanpy_covid_qc_dr_scanorama_cl.h5ad'), path_file)\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 5725 × 2727\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden_1.0', 'leiden_0.6', 'leiden_0.4', 'leiden_1.4', 'louvain_1.0', 'louvain_0.6', 'louvain_0.4', 'louvain_1.4', 'kmeans5', 'kmeans10', 'kmeans15', 'hclust_5', 'hclust_10', 'hclust_15'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'dendrogram_leiden_0.6', 'dendrogram_louvain_0.6', 'doublet_info_colors', 'hclust_10_colors', 'hclust_15_colors', 'hclust_5_colors', 'hvg', 'kmeans10_colors', 'kmeans15_colors', 'kmeans5_colors', 'leiden', 'leiden_0.4_colors', 'leiden_0.6_colors', 'leiden_1.0_colors', 'leiden_1.4_colors', 'log1p', 'louvain', 'louvain_0.4_colors', 'louvain_0.6_colors', 'louvain_1.0_colors', 'louvain_1.4_colors', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n    obsm: 'Scanorama', 'X_pca', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'\nprint(adata.X.shape)\nprint(adata.raw.X.shape)\nprint(adata.raw.X[:10,:10])\n\n(5725, 2727)\n(5725, 18830)\n  (1, 3)    0.7825693876867097\n  (8, 6)    1.1311041336746985\nAs you can see, the X matrix only contains the variable genes, while the raw matrix contains all genes.\nPrinting a few of the values in adata.raw.X shows that the raw matrix is not normalized.\nFor DGE analysis we would like to run with all genes, but on normalized values, so we will have to revert back to the raw matrix and renormalize.\nadata = adata.raw.to_adata()\nsc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\nsc.pp.log1p(adata)\n\nnormalizing by total count per cell\n    finished (0:00:00): normalized adata.X and added    'n_counts', counts per cell before normalization (adata.obs)\nWARNING: adata.X seems to be already log-transformed.\nNow lets look at the clustering of the object we loaded in the umap. We will use louvain_0.6 clustering in this exercise.\nsc.pl.umap(adata, color='louvain_0.6')"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#t-test",
    "href": "labs/scanpy/scanpy_05_dge.html#t-test",
    "title": " Differential gene expression",
    "section": "1 T-test",
    "text": "1 T-test\n\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', method='t-test', key_added = \"t-test\")\nsc.pl.rank_genes_groups(adata, n_genes=25, sharey=False, key = \"t-test\")\n\n# results are stored in the adata.uns[\"t-test\"] slot\nadata\n\nranking genes\n    finished (0:00:02)\n\n\n\n\n\n\n\n\n\nAnnData object with n_obs × n_vars = 5725 × 18830\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden_1.0', 'leiden_0.6', 'leiden_0.4', 'leiden_1.4', 'louvain_1.0', 'louvain_0.6', 'louvain_0.4', 'louvain_1.4', 'kmeans5', 'kmeans10', 'kmeans15', 'hclust_5', 'hclust_10', 'hclust_15'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'dendrogram_leiden_0.6', 'dendrogram_louvain_0.6', 'doublet_info_colors', 'hclust_10_colors', 'hclust_15_colors', 'hclust_5_colors', 'hvg', 'kmeans10_colors', 'kmeans15_colors', 'kmeans5_colors', 'leiden', 'leiden_0.4_colors', 'leiden_0.6_colors', 'leiden_1.0_colors', 'leiden_1.4_colors', 'log1p', 'louvain', 'louvain_0.4_colors', 'louvain_0.6_colors', 'louvain_1.0_colors', 'louvain_1.4_colors', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap', 't-test'\n    obsm: 'Scanorama', 'X_pca', 'X_tsne', 'X_umap'\n    obsp: 'connectivities', 'distances'"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#t-test-overestimated_variance",
    "href": "labs/scanpy/scanpy_05_dge.html#t-test-overestimated_variance",
    "title": " Differential gene expression",
    "section": "2 T-test overestimated_variance",
    "text": "2 T-test overestimated_variance\n\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', method='t-test_overestim_var', key_added = \"t-test_ov\")\nsc.pl.rank_genes_groups(adata, n_genes=25, sharey=False, key = \"t-test_ov\")\n\nranking genes\n    finished (0:00:00)"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#wilcoxon-rank-sum",
    "href": "labs/scanpy/scanpy_05_dge.html#wilcoxon-rank-sum",
    "title": " Differential gene expression",
    "section": "3 Wilcoxon rank-sum",
    "text": "3 Wilcoxon rank-sum\nThe result of a Wilcoxon rank-sum (Mann-Whitney-U) test is very similar. We recommend using the latter in publications, see e.g., Sonison & Robinson (2018). You might also consider much more powerful differential testing packages like MAST, limma, DESeq2 and, for python, the recent diffxpy.\n\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', method='wilcoxon', key_added = \"wilcoxon\")\nsc.pl.rank_genes_groups(adata, n_genes=25, sharey=False, key=\"wilcoxon\")\n\nranking genes\n    finished (0:00:07)"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#logistic-regression-test",
    "href": "labs/scanpy/scanpy_05_dge.html#logistic-regression-test",
    "title": " Differential gene expression",
    "section": "4 Logistic regression test",
    "text": "4 Logistic regression test\nAs an alternative, let us rank genes using logistic regression. For instance, this has been suggested by Natranos et al. (2018). The essential difference is that here, we use a multi-variate appraoch whereas conventional differential tests are uni-variate. Clark et al. (2014) has more details.\n\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', method='logreg',key_added = \"logreg\")\nsc.pl.rank_genes_groups(adata, n_genes=25, sharey=False, key = \"logreg\")\n\nranking genes\n    finished (0:00:17)"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#compare-genes",
    "href": "labs/scanpy/scanpy_05_dge.html#compare-genes",
    "title": " Differential gene expression",
    "section": "5 Compare genes",
    "text": "5 Compare genes\nTake all significant DE genes for cluster0 with each test and compare the overlap.\n\n#compare cluster1 genes, only stores top 100 by default\n\nwc = sc.get.rank_genes_groups_df(adata, group='0', key='wilcoxon', pval_cutoff=0.01, log2fc_min=0)['names']\ntt = sc.get.rank_genes_groups_df(adata, group='0', key='t-test', pval_cutoff=0.01, log2fc_min=0)['names']\ntt_ov = sc.get.rank_genes_groups_df(adata, group='0', key='t-test_ov', pval_cutoff=0.01, log2fc_min=0)['names']\n\nfrom matplotlib_venn import venn3\n\nvenn3([set(wc),set(tt),set(tt_ov)], ('Wilcox','T-test','T-test_ov') )\nplt.show()\n\n\n\n\n\n\n\n\nAs you can see, the Wilcoxon test and the T-test with overestimated variance gives very similar result. Also the regular T-test has good overlap, while the Logistic regression gives quite different genes."
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#visualization",
    "href": "labs/scanpy/scanpy_05_dge.html#visualization",
    "title": " Differential gene expression",
    "section": "6 Visualization",
    "text": "6 Visualization\nThere are several ways to visualize the expression of top DE genes. Here we will plot top 5 genes per cluster from Wilcoxon test as heatmap, dotplot, violin plot or matrix.\n\nsc.pl.rank_genes_groups_heatmap(adata, n_genes=5, key=\"wilcoxon\", groupby=\"louvain_0.6\", show_gene_labels=True)\nsc.pl.rank_genes_groups_dotplot(adata, n_genes=5, key=\"wilcoxon\", groupby=\"louvain_0.6\")\nsc.pl.rank_genes_groups_stacked_violin(adata, n_genes=5, key=\"wilcoxon\", groupby=\"louvain_0.6\")\nsc.pl.rank_genes_groups_matrixplot(adata, n_genes=5, key=\"wilcoxon\", groupby=\"louvain_0.6\")"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#compare-specific-clusters",
    "href": "labs/scanpy/scanpy_05_dge.html#compare-specific-clusters",
    "title": " Differential gene expression",
    "section": "7 Compare specific clusters",
    "text": "7 Compare specific clusters\nWe can also do pairwise comparisons of individual clusters on one vs many clusters. For instance, clusters 1 & 2 have very similar expression profiles.\n\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', groups=['1'], reference='2', method='wilcoxon')\nsc.pl.rank_genes_groups(adata, groups=['1'], n_genes=20)\n\nranking genes\n    finished (0:00:02)\n\n\n\n\n\n\n\n\n\nPlot as violins for those two groups.\n\nsc.pl.rank_genes_groups_violin(adata, groups='1', n_genes=10)\n\n# plot the same genes as violins across all the datasets.\n\n# convert numpy.recarray to list\nmynames = [x[0] for x in adata.uns['rank_genes_groups']['names'][:10]]\nsc.pl.stacked_violin(adata, mynames, groupby = 'louvain_0.6')"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#meta-dge_cond",
    "href": "labs/scanpy/scanpy_05_dge.html#meta-dge_cond",
    "title": " Differential gene expression",
    "section": "8 DGE across conditions",
    "text": "8 DGE across conditions\nThe second way of computing differential expression is to answer which genes are differentially expressed within a cluster. For example, in our case we have libraries comming from patients and controls and we would like to know which genes are influenced the most in a particular cell type. For this end, we will first subset our data for the desired cell cluster, then change the cell identities to the variable of comparison (which now in our case is the “type”, e.g. Covid/Ctrl).\n\ncl1 = adata[adata.obs['louvain_0.6'] == '4',:]\ncl1.obs['type'].value_counts()\n\nsc.tl.rank_genes_groups(cl1, 'type', method='wilcoxon', key_added = \"wilcoxon\")\nsc.pl.rank_genes_groups(cl1, n_genes=25, sharey=False, key=\"wilcoxon\")\n\nranking genes\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\n\nsc.pl.rank_genes_groups_violin(cl1, n_genes=10, key=\"wilcoxon\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also plot these genes across all clusters, but split by “type”, to check if the genes are also up/downregulated in other celltypes.\n\nimport seaborn as sns\n\ngenes1 = sc.get.rank_genes_groups_df(cl1, group='Covid', key='wilcoxon')['names'][:5]\ngenes2 = sc.get.rank_genes_groups_df(cl1, group='Ctrl', key='wilcoxon')['names'][:5]\ngenes = genes1.tolist() +  genes2.tolist() \ndf = sc.get.obs_df(adata, genes + ['louvain_0.6','type'], use_raw=False)\ndf2 = df.melt(id_vars=[\"louvain_0.6\",'type'], value_vars=genes)\n\nsns.catplot(x = \"louvain_0.6\", y = \"value\", hue = \"type\", kind = 'violin', col = \"variable\", data = df2, col_wrap=4, inner=None)\n\n\n\n\n\n\n\n\nAs you can see, we have many sex chromosome related genes among the top DE genes. And if you remember from the QC lab, we have inbalanced sex distribution among our subjects, so this may not be related to covid at all.\n\n8.1 Remove sex chromosome genes\nTo remove some of the bias due to inbalanced sex in the subjects we can remove the sex chromosome related genes.\n\nannot = sc.queries.biomart_annotations(\n        \"hsapiens\",\n        [\"ensembl_gene_id\", \"external_gene_name\", \"start_position\", \"end_position\", \"chromosome_name\"],\n    ).set_index(\"external_gene_name\")\n\nchrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"Y\"])\nchrX_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"X\"])\n\nsex_genes = chrY_genes.union(chrX_genes)\nprint(len(sex_genes))\nall_genes = cl1.var.index.tolist()\nprint(len(all_genes))\n\nkeep_genes = [x for x in all_genes if x not in sex_genes]\nprint(len(keep_genes))\n\ncl1 = cl1[:,keep_genes]\n\n536\n18830\n18294\n\n\nRerun differential expression.\n\nsc.tl.rank_genes_groups(cl1, 'type', method='wilcoxon', key_added = \"wilcoxon\")\nsc.pl.rank_genes_groups(cl1, n_genes=25, sharey=False, key=\"wilcoxon\")\n\nranking genes\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\n\n\n8.2 Patient batch effects\nWhen we are testing for Covid vs Control we are running a DGE test for 3 vs 3 individuals. That will be very sensitive to sample differences unless we find a way to control for it. So first, lets check how the top DGEs are expressed across the individuals:\n\ngenes1 = sc.get.rank_genes_groups_df(cl1, group='Covid', key='wilcoxon')['names'][:5]\ngenes2 = sc.get.rank_genes_groups_df(cl1, group='Ctrl', key='wilcoxon')['names'][:5]\ngenes = genes1.tolist() +  genes2.tolist() \n\nsc.pl.violin(cl1, genes1, groupby='sample')\nsc.pl.violin(cl1, genes2, groupby='sample')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, many of the genes detected as DGE in Covid are unique to one or 2 patients.\nWe can examine more genes with a DotPlot:\nWe can also plot the top Covid and top Ctrl genes as a dotplot:\n\ngenes1 = sc.get.rank_genes_groups_df(cl1, group='Covid', key='wilcoxon')['names'][:20]\ngenes2 = sc.get.rank_genes_groups_df(cl1, group='Ctrl', key='wilcoxon')['names'][:20]\ngenes = genes1.tolist() +  genes2.tolist() \n\nsc.pl.dotplot(cl1,genes, groupby='sample')\n\n\n\n\n\n\n\n\nClearly many of the top Covid genes are only high in the covid_17 sample, and not a general feature of covid patients.\nThis is also the patient with the highest number of cells in this cluster:\n\ncl1.obs['sample'].value_counts()\n\nsample\ncovid_17    129\nctrl_5      115\ncovid_1     110\nctrl_13      64\nctrl_14      63\ncovid_15     35\nName: count, dtype: int64\n\n\n\n\n8.3 Subsample\nSo one obvious thing to consider is an equal amount of cells per individual so that the DGE results are not dominated by a single sample.\nSo we will downsample to an equal number of cells per sample.\n\ncl1.obs['sample'].value_counts()\n\nsample\ncovid_17    129\nctrl_5      115\ncovid_1     110\nctrl_13      64\nctrl_14      63\ncovid_15     35\nName: count, dtype: int64\n\n\n\ntarget_cells = 50\n\ntmp = [cl1[cl1.obs['sample'] == s] for s in cl1.obs['sample'].cat.categories]\n\nfor dat in tmp:\n    if dat.n_obs &gt; target_cells:\n            sc.pp.subsample(dat, n_obs=target_cells)\n\ncl1_sub = tmp[0].concatenate(*tmp[1:])\n\ncl1_sub.obs['sample'].value_counts()\n\nsample\ncovid_1     50\ncovid_17    50\nctrl_5      50\nctrl_13     50\nctrl_14     50\ncovid_15    35\nName: count, dtype: int64\n\n\n\nsc.tl.rank_genes_groups(cl1_sub, 'type', method='wilcoxon', key_added = \"wilcoxon\")\nsc.pl.rank_genes_groups(cl1_sub, n_genes=25, sharey=False, key=\"wilcoxon\")\n\nranking genes\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\n\ngenes1 = sc.get.rank_genes_groups_df(cl1_sub, group='Covid', key='wilcoxon')['names'][:20]\ngenes2 = sc.get.rank_genes_groups_df(cl1_sub, group='Ctrl', key='wilcoxon')['names'][:20]\ngenes = genes1.tolist() +  genes2.tolist() \n\nsc.pl.dotplot(cl1,genes, groupby='sample')\n\n\n\n\n\n\n\n\nIt looks much better now. But if we look per patient you can see that we still have some genes that are dominated by a single patient. Still, it is often a good idea to control the number of cells from each sample when doing differential expression.\nWhy do you think this is?\nThere are many different ways to try and resolve the issue of patient batch effects, however most of them require R packages. These can be run via rpy2 as is demonstraded in this compendium: https://www.sc-best-practices.org/conditions/differential_gene_expression.html\nHowever, we have not included it here as of now. So please have a look at the patient batch effect section in the seurat DGE tutorial where we run EdgeR on pseudobulk and MAST with random effect."
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#meta-dge_gsa",
    "href": "labs/scanpy/scanpy_05_dge.html#meta-dge_gsa",
    "title": " Differential gene expression",
    "section": "9 Gene Set Analysis (GSA)",
    "text": "9 Gene Set Analysis (GSA)\n\n9.1 Hypergeometric enrichment test\nHaving a defined list of differentially expressed genes, you can now look for their combined function using hypergeometric test.\n\n#Available databases : ‘Human’, ‘Mouse’, ‘Yeast’, ‘Fly’, ‘Fish’, ‘Worm’ \ngene_set_names = gseapy.get_library_name(organism='Human')\nprint(gene_set_names)\n\n['ARCHS4_Cell-lines', 'ARCHS4_IDG_Coexp', 'ARCHS4_Kinases_Coexp', 'ARCHS4_TFs_Coexp', 'ARCHS4_Tissues', 'Achilles_fitness_decrease', 'Achilles_fitness_increase', 'Aging_Perturbations_from_GEO_down', 'Aging_Perturbations_from_GEO_up', 'Allen_Brain_Atlas_10x_scRNA_2021', 'Allen_Brain_Atlas_down', 'Allen_Brain_Atlas_up', 'Azimuth_2023', 'Azimuth_Cell_Types_2021', 'BioCarta_2013', 'BioCarta_2015', 'BioCarta_2016', 'BioPlanet_2019', 'BioPlex_2017', 'CCLE_Proteomics_2020', 'CORUM', 'COVID-19_Related_Gene_Sets', 'COVID-19_Related_Gene_Sets_2021', 'Cancer_Cell_Line_Encyclopedia', 'CellMarker_Augmented_2021', 'ChEA_2013', 'ChEA_2015', 'ChEA_2016', 'ChEA_2022', 'Chromosome_Location', 'Chromosome_Location_hg19', 'ClinVar_2019', 'DSigDB', 'Data_Acquisition_Method_Most_Popular_Genes', 'DepMap_WG_CRISPR_Screens_Broad_CellLines_2019', 'DepMap_WG_CRISPR_Screens_Sanger_CellLines_2019', 'Descartes_Cell_Types_and_Tissue_2021', 'Diabetes_Perturbations_GEO_2022', 'DisGeNET', 'Disease_Perturbations_from_GEO_down', 'Disease_Perturbations_from_GEO_up', 'Disease_Signatures_from_GEO_down_2014', 'Disease_Signatures_from_GEO_up_2014', 'DrugMatrix', 'Drug_Perturbations_from_GEO_2014', 'Drug_Perturbations_from_GEO_down', 'Drug_Perturbations_from_GEO_up', 'ENCODE_Histone_Modifications_2013', 'ENCODE_Histone_Modifications_2015', 'ENCODE_TF_ChIP-seq_2014', 'ENCODE_TF_ChIP-seq_2015', 'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X', 'ESCAPE', 'Elsevier_Pathway_Collection', 'Enrichr_Libraries_Most_Popular_Genes', 'Enrichr_Submissions_TF-Gene_Coocurrence', 'Enrichr_Users_Contributed_Lists_2020', 'Epigenomics_Roadmap_HM_ChIP-seq', 'FANTOM6_lncRNA_KD_DEGs', 'GO_Biological_Process_2013', 'GO_Biological_Process_2015', 'GO_Biological_Process_2017', 'GO_Biological_Process_2017b', 'GO_Biological_Process_2018', 'GO_Biological_Process_2021', 'GO_Biological_Process_2023', 'GO_Cellular_Component_2013', 'GO_Cellular_Component_2015', 'GO_Cellular_Component_2017', 'GO_Cellular_Component_2017b', 'GO_Cellular_Component_2018', 'GO_Cellular_Component_2021', 'GO_Cellular_Component_2023', 'GO_Molecular_Function_2013', 'GO_Molecular_Function_2015', 'GO_Molecular_Function_2017', 'GO_Molecular_Function_2017b', 'GO_Molecular_Function_2018', 'GO_Molecular_Function_2021', 'GO_Molecular_Function_2023', 'GTEx_Aging_Signatures_2021', 'GTEx_Tissue_Expression_Down', 'GTEx_Tissue_Expression_Up', 'GTEx_Tissues_V8_2023', 'GWAS_Catalog_2019', 'GWAS_Catalog_2023', 'GeDiPNet_2023', 'GeneSigDB', 'Gene_Perturbations_from_GEO_down', 'Gene_Perturbations_from_GEO_up', 'Genes_Associated_with_NIH_Grants', 'Genome_Browser_PWMs', 'GlyGen_Glycosylated_Proteins_2022', 'HDSigDB_Human_2021', 'HDSigDB_Mouse_2021', 'HMDB_Metabolites', 'HMS_LINCS_KinomeScan', 'HomoloGene', 'HuBMAP_ASCT_plus_B_augmented_w_RNAseq_Coexpression', 'HuBMAP_ASCTplusB_augmented_2022', 'HumanCyc_2015', 'HumanCyc_2016', 'Human_Gene_Atlas', 'Human_Phenotype_Ontology', 'IDG_Drug_Targets_2022', 'InterPro_Domains_2019', 'Jensen_COMPARTMENTS', 'Jensen_DISEASES', 'Jensen_TISSUES', 'KEA_2013', 'KEA_2015', 'KEGG_2013', 'KEGG_2015', 'KEGG_2016', 'KEGG_2019_Human', 'KEGG_2019_Mouse', 'KEGG_2021_Human', 'KOMP2_Mouse_Phenotypes_2022', 'Kinase_Perturbations_from_GEO_down', 'Kinase_Perturbations_from_GEO_up', 'L1000_Kinase_and_GPCR_Perturbations_down', 'L1000_Kinase_and_GPCR_Perturbations_up', 'LINCS_L1000_CRISPR_KO_Consensus_Sigs', 'LINCS_L1000_Chem_Pert_Consensus_Sigs', 'LINCS_L1000_Chem_Pert_down', 'LINCS_L1000_Chem_Pert_up', 'LINCS_L1000_Ligand_Perturbations_down', 'LINCS_L1000_Ligand_Perturbations_up', 'Ligand_Perturbations_from_GEO_down', 'Ligand_Perturbations_from_GEO_up', 'MAGMA_Drugs_and_Diseases', 'MAGNET_2023', 'MCF7_Perturbations_from_GEO_down', 'MCF7_Perturbations_from_GEO_up', 'MGI_Mammalian_Phenotype_2013', 'MGI_Mammalian_Phenotype_2017', 'MGI_Mammalian_Phenotype_Level_3', 'MGI_Mammalian_Phenotype_Level_4', 'MGI_Mammalian_Phenotype_Level_4_2019', 'MGI_Mammalian_Phenotype_Level_4_2021', 'MSigDB_Computational', 'MSigDB_Hallmark_2020', 'MSigDB_Oncogenic_Signatures', 'Metabolomics_Workbench_Metabolites_2022', 'Microbe_Perturbations_from_GEO_down', 'Microbe_Perturbations_from_GEO_up', 'MoTrPAC_2023', 'Mouse_Gene_Atlas', 'NCI-60_Cancer_Cell_Lines', 'NCI-Nature_2015', 'NCI-Nature_2016', 'NIH_Funded_PIs_2017_AutoRIF_ARCHS4_Predictions', 'NIH_Funded_PIs_2017_GeneRIF_ARCHS4_Predictions', 'NIH_Funded_PIs_2017_Human_AutoRIF', 'NIH_Funded_PIs_2017_Human_GeneRIF', 'NURSA_Human_Endogenous_Complexome', 'OMIM_Disease', 'OMIM_Expanded', 'Old_CMAP_down', 'Old_CMAP_up', 'Orphanet_Augmented_2021', 'PFOCR_Pathways', 'PFOCR_Pathways_2023', 'PPI_Hub_Proteins', 'PanglaoDB_Augmented_2021', 'Panther_2015', 'Panther_2016', 'Pfam_Domains_2019', 'Pfam_InterPro_Domains', 'PheWeb_2019', 'PhenGenI_Association_2021', 'Phosphatase_Substrates_from_DEPOD', 'ProteomicsDB_2020', 'Proteomics_Drug_Atlas_2023', 'RNA-Seq_Disease_Gene_and_Drug_Signatures_from_GEO', 'RNAseq_Automatic_GEO_Signatures_Human_Down', 'RNAseq_Automatic_GEO_Signatures_Human_Up', 'RNAseq_Automatic_GEO_Signatures_Mouse_Down', 'RNAseq_Automatic_GEO_Signatures_Mouse_Up', 'Rare_Diseases_AutoRIF_ARCHS4_Predictions', 'Rare_Diseases_AutoRIF_Gene_Lists', 'Rare_Diseases_GeneRIF_ARCHS4_Predictions', 'Rare_Diseases_GeneRIF_Gene_Lists', 'Reactome_2013', 'Reactome_2015', 'Reactome_2016', 'Reactome_2022', 'Rummagene_kinases', 'Rummagene_signatures', 'Rummagene_transcription_factors', 'SILAC_Phosphoproteomics', 'SubCell_BarCode', 'SynGO_2022', 'SysMyo_Muscle_Gene_Sets', 'TF-LOF_Expression_from_GEO', 'TF_Perturbations_Followed_by_Expression', 'TG_GATES_2020', 'TRANSFAC_and_JASPAR_PWMs', 'TRRUST_Transcription_Factors_2019', 'Table_Mining_of_CRISPR_Studies', 'Tabula_Muris', 'Tabula_Sapiens', 'TargetScan_microRNA', 'TargetScan_microRNA_2017', 'The_Kinase_Library_2023', 'Tissue_Protein_Expression_from_Human_Proteome_Map', 'Tissue_Protein_Expression_from_ProteomicsDB', 'Transcription_Factor_PPIs', 'UK_Biobank_GWAS_v1', 'Virus-Host_PPI_P-HIPSTer_2020', 'VirusMINT', 'Virus_Perturbations_from_GEO_down', 'Virus_Perturbations_from_GEO_up', 'WikiPathway_2021_Human', 'WikiPathway_2023_Human', 'WikiPathways_2013', 'WikiPathways_2015', 'WikiPathways_2016', 'WikiPathways_2019_Human', 'WikiPathways_2019_Mouse', 'dbGaP', 'huMAP', 'lncHUB_lncRNA_Co-Expression', 'miRTarBase_2017']\n\n\nGet the significant DEGs for the Covid patients.\n\n#?gseapy.enrichr\nglist = sc.get.rank_genes_groups_df(cl1_sub, group='Covid', key='wilcoxon', log2fc_min=0.25, pval_cutoff=0.05)['names'].squeeze().str.strip().tolist()\nprint(len(glist))\n\n18\n\n\n\nenr_res = gseapy.enrichr(gene_list=glist, organism='Human', gene_sets='GO_Biological_Process_2018', cutoff = 0.5)\nenr_res.results.head()\n\n\n\n\n\n\n\n\nGene_set\nTerm\nOverlap\nP-value\nAdjusted P-value\nOld P-value\nOld Adjusted P-value\nOdds Ratio\nCombined Score\nGenes\n\n\n\n\n0\nGO_Biological_Process_2018\ncellular response to type I interferon (GO:007...\n5/65\n2.569729e-09\n3.186464e-07\n0\n0\n127.705128\n2525.939157\nISG20;IFITM1;IFITM2;ISG15;XAF1\n\n\n1\nGO_Biological_Process_2018\ntype I interferon signaling pathway (GO:0060337)\n5/65\n2.569729e-09\n3.186464e-07\n0\n0\n127.705128\n2525.939157\nISG20;IFITM1;IFITM2;ISG15;XAF1\n\n\n2\nGO_Biological_Process_2018\ncytokine-mediated signaling pathway (GO:0019221)\n8/633\n3.184846e-08\n2.632806e-06\n0\n0\n24.776960\n427.706745\nISG20;NFKBIA;IFITM1;IFITM2;ISG15;VIM;XAF1;SOD1\n\n\n3\nGO_Biological_Process_2018\nnegative regulation of viral genome replicatio...\n4/50\n1.030352e-07\n6.388183e-06\n0\n0\n123.826087\n1992.138251\nISG20;IFITM1;IFITM2;ISG15\n\n\n4\nGO_Biological_Process_2018\nnegative regulation of viral life cycle (GO:19...\n4/61\n2.320426e-07\n1.093538e-05\n0\n0\n99.874687\n1525.720152\nISG20;IFITM1;IFITM2;ISG15\n\n\n\n\n\n\n\nSome databases of interest:\nGO_Biological_Process_2017bKEGG_2019_HumanKEGG_2019_MouseWikiPathways_2019_HumanWikiPathways_2019_Mouse\nYou visualize your results using a simple barplot, for example:\n\ngseapy.barplot(enr_res.res2d,title='GO_Biological_Process_2018')\n\n&lt;Axes: title={'center': 'GO_Biological_Process_2018'}, xlabel='$- \\\\log_{10}$ (Adjusted P-value)'&gt;"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#meta-dge_gsea",
    "href": "labs/scanpy/scanpy_05_dge.html#meta-dge_gsea",
    "title": " Differential gene expression",
    "section": "10 Gene Set Enrichment Analysis (GSEA)",
    "text": "10 Gene Set Enrichment Analysis (GSEA)\nBesides the enrichment using hypergeometric test, we can also perform gene set enrichment analysis (GSEA), which scores ranked genes list (usually based on fold changes) and computes permutation test to check if a particular gene set is more present in the Up-regulated genes, among the DOWN_regulated genes or not differentially regulated.\nWe need a table with all DEGs and their log foldchanges. However, many lowly expressed genes will have high foldchanges and just contribue noise, so also filter for expression in enough cells.\n\ngene_rank = sc.get.rank_genes_groups_df(cl1_sub, group='Covid', key='wilcoxon')[['names','logfoldchanges']]\ngene_rank.sort_values(by=['logfoldchanges'], inplace=True, ascending=False)\n\n# calculate_qc_metrics will calculate number of cells per gene\nsc.pp.calculate_qc_metrics(cl1, percent_top=None, log1p=False, inplace=True)\n\n# filter for genes expressed in at least 30 cells.\ngene_rank = gene_rank[gene_rank['names'].isin(cl1.var_names[cl1.var.n_cells_by_counts&gt;30])]\n\ngene_rank\n\n\n\n\n\n\n\n\nnames\nlogfoldchanges\n\n\n\n\n169\nTTTY15\n27.813257\n\n\n234\nCXCL8\n27.684155\n\n\n385\nG0S2\n27.324526\n\n\n61\nIFIT3\n4.778945\n\n\n228\nSLFN5\n4.398190\n\n\n...\n...\n...\n\n\n17616\nPSMD5\n-2.900448\n\n\n17498\nFARSA\n-2.907254\n\n\n17784\nDHDDS\n-3.096821\n\n\n18109\nCD200\n-3.213758\n\n\n18101\nFAM111B\n-3.797801\n\n\n\n\n6567 rows × 2 columns\n\n\n\nOnce our list of genes are sorted, we can proceed with the enrichment itself. We can use the package to get gene set from the Molecular Signature Database (MSigDB) and select KEGG pathways as an example.\n\n#Available databases : ‘Human’, ‘Mouse’, ‘Yeast’, ‘Fly’, ‘Fish’, ‘Worm’ \ngene_set_names = gseapy.get_library_name(organism='Human')\nprint(gene_set_names)\n\n['ARCHS4_Cell-lines', 'ARCHS4_IDG_Coexp', 'ARCHS4_Kinases_Coexp', 'ARCHS4_TFs_Coexp', 'ARCHS4_Tissues', 'Achilles_fitness_decrease', 'Achilles_fitness_increase', 'Aging_Perturbations_from_GEO_down', 'Aging_Perturbations_from_GEO_up', 'Allen_Brain_Atlas_10x_scRNA_2021', 'Allen_Brain_Atlas_down', 'Allen_Brain_Atlas_up', 'Azimuth_2023', 'Azimuth_Cell_Types_2021', 'BioCarta_2013', 'BioCarta_2015', 'BioCarta_2016', 'BioPlanet_2019', 'BioPlex_2017', 'CCLE_Proteomics_2020', 'CORUM', 'COVID-19_Related_Gene_Sets', 'COVID-19_Related_Gene_Sets_2021', 'Cancer_Cell_Line_Encyclopedia', 'CellMarker_Augmented_2021', 'ChEA_2013', 'ChEA_2015', 'ChEA_2016', 'ChEA_2022', 'Chromosome_Location', 'Chromosome_Location_hg19', 'ClinVar_2019', 'DSigDB', 'Data_Acquisition_Method_Most_Popular_Genes', 'DepMap_WG_CRISPR_Screens_Broad_CellLines_2019', 'DepMap_WG_CRISPR_Screens_Sanger_CellLines_2019', 'Descartes_Cell_Types_and_Tissue_2021', 'Diabetes_Perturbations_GEO_2022', 'DisGeNET', 'Disease_Perturbations_from_GEO_down', 'Disease_Perturbations_from_GEO_up', 'Disease_Signatures_from_GEO_down_2014', 'Disease_Signatures_from_GEO_up_2014', 'DrugMatrix', 'Drug_Perturbations_from_GEO_2014', 'Drug_Perturbations_from_GEO_down', 'Drug_Perturbations_from_GEO_up', 'ENCODE_Histone_Modifications_2013', 'ENCODE_Histone_Modifications_2015', 'ENCODE_TF_ChIP-seq_2014', 'ENCODE_TF_ChIP-seq_2015', 'ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X', 'ESCAPE', 'Elsevier_Pathway_Collection', 'Enrichr_Libraries_Most_Popular_Genes', 'Enrichr_Submissions_TF-Gene_Coocurrence', 'Enrichr_Users_Contributed_Lists_2020', 'Epigenomics_Roadmap_HM_ChIP-seq', 'FANTOM6_lncRNA_KD_DEGs', 'GO_Biological_Process_2013', 'GO_Biological_Process_2015', 'GO_Biological_Process_2017', 'GO_Biological_Process_2017b', 'GO_Biological_Process_2018', 'GO_Biological_Process_2021', 'GO_Biological_Process_2023', 'GO_Cellular_Component_2013', 'GO_Cellular_Component_2015', 'GO_Cellular_Component_2017', 'GO_Cellular_Component_2017b', 'GO_Cellular_Component_2018', 'GO_Cellular_Component_2021', 'GO_Cellular_Component_2023', 'GO_Molecular_Function_2013', 'GO_Molecular_Function_2015', 'GO_Molecular_Function_2017', 'GO_Molecular_Function_2017b', 'GO_Molecular_Function_2018', 'GO_Molecular_Function_2021', 'GO_Molecular_Function_2023', 'GTEx_Aging_Signatures_2021', 'GTEx_Tissue_Expression_Down', 'GTEx_Tissue_Expression_Up', 'GTEx_Tissues_V8_2023', 'GWAS_Catalog_2019', 'GWAS_Catalog_2023', 'GeDiPNet_2023', 'GeneSigDB', 'Gene_Perturbations_from_GEO_down', 'Gene_Perturbations_from_GEO_up', 'Genes_Associated_with_NIH_Grants', 'Genome_Browser_PWMs', 'GlyGen_Glycosylated_Proteins_2022', 'HDSigDB_Human_2021', 'HDSigDB_Mouse_2021', 'HMDB_Metabolites', 'HMS_LINCS_KinomeScan', 'HomoloGene', 'HuBMAP_ASCT_plus_B_augmented_w_RNAseq_Coexpression', 'HuBMAP_ASCTplusB_augmented_2022', 'HumanCyc_2015', 'HumanCyc_2016', 'Human_Gene_Atlas', 'Human_Phenotype_Ontology', 'IDG_Drug_Targets_2022', 'InterPro_Domains_2019', 'Jensen_COMPARTMENTS', 'Jensen_DISEASES', 'Jensen_TISSUES', 'KEA_2013', 'KEA_2015', 'KEGG_2013', 'KEGG_2015', 'KEGG_2016', 'KEGG_2019_Human', 'KEGG_2019_Mouse', 'KEGG_2021_Human', 'KOMP2_Mouse_Phenotypes_2022', 'Kinase_Perturbations_from_GEO_down', 'Kinase_Perturbations_from_GEO_up', 'L1000_Kinase_and_GPCR_Perturbations_down', 'L1000_Kinase_and_GPCR_Perturbations_up', 'LINCS_L1000_CRISPR_KO_Consensus_Sigs', 'LINCS_L1000_Chem_Pert_Consensus_Sigs', 'LINCS_L1000_Chem_Pert_down', 'LINCS_L1000_Chem_Pert_up', 'LINCS_L1000_Ligand_Perturbations_down', 'LINCS_L1000_Ligand_Perturbations_up', 'Ligand_Perturbations_from_GEO_down', 'Ligand_Perturbations_from_GEO_up', 'MAGMA_Drugs_and_Diseases', 'MAGNET_2023', 'MCF7_Perturbations_from_GEO_down', 'MCF7_Perturbations_from_GEO_up', 'MGI_Mammalian_Phenotype_2013', 'MGI_Mammalian_Phenotype_2017', 'MGI_Mammalian_Phenotype_Level_3', 'MGI_Mammalian_Phenotype_Level_4', 'MGI_Mammalian_Phenotype_Level_4_2019', 'MGI_Mammalian_Phenotype_Level_4_2021', 'MSigDB_Computational', 'MSigDB_Hallmark_2020', 'MSigDB_Oncogenic_Signatures', 'Metabolomics_Workbench_Metabolites_2022', 'Microbe_Perturbations_from_GEO_down', 'Microbe_Perturbations_from_GEO_up', 'MoTrPAC_2023', 'Mouse_Gene_Atlas', 'NCI-60_Cancer_Cell_Lines', 'NCI-Nature_2015', 'NCI-Nature_2016', 'NIH_Funded_PIs_2017_AutoRIF_ARCHS4_Predictions', 'NIH_Funded_PIs_2017_GeneRIF_ARCHS4_Predictions', 'NIH_Funded_PIs_2017_Human_AutoRIF', 'NIH_Funded_PIs_2017_Human_GeneRIF', 'NURSA_Human_Endogenous_Complexome', 'OMIM_Disease', 'OMIM_Expanded', 'Old_CMAP_down', 'Old_CMAP_up', 'Orphanet_Augmented_2021', 'PFOCR_Pathways', 'PFOCR_Pathways_2023', 'PPI_Hub_Proteins', 'PanglaoDB_Augmented_2021', 'Panther_2015', 'Panther_2016', 'Pfam_Domains_2019', 'Pfam_InterPro_Domains', 'PheWeb_2019', 'PhenGenI_Association_2021', 'Phosphatase_Substrates_from_DEPOD', 'ProteomicsDB_2020', 'Proteomics_Drug_Atlas_2023', 'RNA-Seq_Disease_Gene_and_Drug_Signatures_from_GEO', 'RNAseq_Automatic_GEO_Signatures_Human_Down', 'RNAseq_Automatic_GEO_Signatures_Human_Up', 'RNAseq_Automatic_GEO_Signatures_Mouse_Down', 'RNAseq_Automatic_GEO_Signatures_Mouse_Up', 'Rare_Diseases_AutoRIF_ARCHS4_Predictions', 'Rare_Diseases_AutoRIF_Gene_Lists', 'Rare_Diseases_GeneRIF_ARCHS4_Predictions', 'Rare_Diseases_GeneRIF_Gene_Lists', 'Reactome_2013', 'Reactome_2015', 'Reactome_2016', 'Reactome_2022', 'Rummagene_kinases', 'Rummagene_signatures', 'Rummagene_transcription_factors', 'SILAC_Phosphoproteomics', 'SubCell_BarCode', 'SynGO_2022', 'SysMyo_Muscle_Gene_Sets', 'TF-LOF_Expression_from_GEO', 'TF_Perturbations_Followed_by_Expression', 'TG_GATES_2020', 'TRANSFAC_and_JASPAR_PWMs', 'TRRUST_Transcription_Factors_2019', 'Table_Mining_of_CRISPR_Studies', 'Tabula_Muris', 'Tabula_Sapiens', 'TargetScan_microRNA', 'TargetScan_microRNA_2017', 'The_Kinase_Library_2023', 'Tissue_Protein_Expression_from_Human_Proteome_Map', 'Tissue_Protein_Expression_from_ProteomicsDB', 'Transcription_Factor_PPIs', 'UK_Biobank_GWAS_v1', 'Virus-Host_PPI_P-HIPSTer_2020', 'VirusMINT', 'Virus_Perturbations_from_GEO_down', 'Virus_Perturbations_from_GEO_up', 'WikiPathway_2021_Human', 'WikiPathway_2023_Human', 'WikiPathways_2013', 'WikiPathways_2015', 'WikiPathways_2016', 'WikiPathways_2019_Human', 'WikiPathways_2019_Mouse', 'dbGaP', 'huMAP', 'lncHUB_lncRNA_Co-Expression', 'miRTarBase_2017']\n\n\nNext, we will be using the GSEA. This will result in a table containing information for several pathways. We can then sort and filter those pathways to visualize only the top ones. You can select/filter them by either p-value or normalized enrichment score (NES).\n\nres = gseapy.prerank(rnk=gene_rank, gene_sets='KEGG_2021_Human')\n\nterms = res.res2d.Term\nterms[:10]\n\n0                                  Coronavirus disease\n1               Cytokine-cytokine receptor interaction\n2    Viral protein interaction with cytokine and cy...\n3                RIG-I-like receptor signaling pathway\n4                         NF-kappa B signaling pathway\n5                              IL-17 signaling pathway\n6                                        Legionellosis\n7                                            Pertussis\n8                 Toll-like receptor signaling pathway\n9                                 Rheumatoid arthritis\nName: Term, dtype: object\n\n\n\ngseapy.gseaplot(rank_metric=res.ranking, term=terms[0], **res.results[terms[0]])\n\n[&lt;Axes: xlabel='Gene Rank', ylabel='Ranked metric'&gt;,\n &lt;Axes: &gt;,\n &lt;Axes: &gt;,\n &lt;Axes: ylabel='Enrichment Score'&gt;]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWhich KEGG pathways are upregulated in this cluster?Which KEGG pathways are dowregulated in this cluster?\nChange the pathway source to another gene set (e.g. “CP:WIKIPATHWAYS” or “CP:REACTOME” or “CP:BIOCARTA” or “GO:BP”) and check the if you get similar results?\n\n\nFinally, lets save the integrated data for further analysis.\n\nadata.write_h5ad('./data/covid/results/scanpy_covid_qc_dr_scanorama_cl_dge.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_05_dge.html#meta-session",
    "href": "labs/scanpy/scanpy_05_dge.html#meta-session",
    "title": " Differential gene expression",
    "section": "11 Session info",
    "text": "11 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfuture              0.18.3\ngmpy2               2.1.2\ngseapy              1.0.6\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmatplotlib_venn     0.11.9\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npybiomart           0.2.0\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrequests_cache      0.4.13\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nseaborn             0.12.2\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsparse              0.14.0\nstack_data          0.6.2\nstatsmodels         0.14.1\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:23"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html",
    "href": "labs/scanpy/scanpy_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each celltype.\nWe will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to even if the celltype of that cell is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nHere we will use a reference PBMC dataset that we get from scanpy datasets and classify celltypes based on two methods:\nFirst, lets load required libraries\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport urllib.request\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 2\nsc.settings.set_figure_params(dpi=80)\nLet’s read in the saved Covid-19 data object from the clustering step.\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\n# path_file = \"data/covid/results/scanpy_covid_qc_dr_scanorama_cl.h5ad\"\npath_file = \"data/covid/results/scanpy_clustered_covid.h5ad\"\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'covid/results/scanpy_covid_qc_dr_scanorama_cl.h5ad'), path_file)\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 5725 × 2727\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden_1.0', 'leiden_0.6', 'leiden_0.4', 'leiden_1.4', 'louvain_1.0', 'louvain_0.6', 'louvain_0.4', 'louvain_1.4', 'kmeans5', 'kmeans10', 'kmeans15', 'hclust_5', 'hclust_10', 'hclust_15'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'dendrogram_leiden_0.6', 'dendrogram_louvain_0.6', 'doublet_info_colors', 'hclust_10_colors', 'hclust_15_colors', 'hclust_5_colors', 'hvg', 'kmeans10_colors', 'kmeans15_colors', 'kmeans5_colors', 'leiden', 'leiden_0.4_colors', 'leiden_0.6_colors', 'leiden_1.0_colors', 'leiden_1.4_colors', 'log1p', 'louvain', 'louvain_0.4_colors', 'louvain_0.6_colors', 'louvain_1.0_colors', 'louvain_1.4_colors', 'neighbors', 'pca', 'sample_colors', 'tsne', 'umap'\n    obsm: 'Scanorama', 'X_pca', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'\nadata.uns['log1p']['base']=None\nprint(adata.shape)\nprint(adata.raw.shape)\n\n(5725, 2727)\n(5725, 18830)\nSubset one patient.\nadata = adata[adata.obs[\"sample\"] == \"ctrl_13\",:]\nprint(adata.shape)\n\n(1117, 2727)\nsc.pl.umap(\n    adata, color=[\"louvain_0.6\"], palette=sc.pl.palettes.default_20\n)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#meta-ct_ref",
    "href": "labs/scanpy/scanpy_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "1 Reference data",
    "text": "1 Reference data\nLoad the reference data from scanpy.datasets. It is the annotated and processed pbmc3k dataset from 10x.\n\nadata_ref = sc.datasets.pbmc3k_processed() \n\nadata_ref.obs['sample']='pbmc3k'\n\nprint(adata_ref.shape)\nadata_ref.obs\n\ntry downloading from url\nhttps://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad\n... this may take a while but only happens once\n(2638, 1838)\n\n\n\n\n\n\n\n\n\nn_genes\npercent_mito\nn_counts\nlouvain\nsample\n\n\nindex\n\n\n\n\n\n\n\n\n\nAAACATACAACCAC-1\n781\n0.030178\n2419.0\nCD4 T cells\npbmc3k\n\n\nAAACATTGAGCTAC-1\n1352\n0.037936\n4903.0\nB cells\npbmc3k\n\n\nAAACATTGATCAGC-1\n1131\n0.008897\n3147.0\nCD4 T cells\npbmc3k\n\n\nAAACCGTGCTTCCG-1\n960\n0.017431\n2639.0\nCD14+ Monocytes\npbmc3k\n\n\nAAACCGTGTATGCG-1\n522\n0.012245\n980.0\nNK cells\npbmc3k\n\n\n...\n...\n...\n...\n...\n...\n\n\nTTTCGAACTCTCAT-1\n1155\n0.021104\n3459.0\nCD14+ Monocytes\npbmc3k\n\n\nTTTCTACTGAGGCA-1\n1227\n0.009294\n3443.0\nB cells\npbmc3k\n\n\nTTTCTACTTCCTCG-1\n622\n0.021971\n1684.0\nB cells\npbmc3k\n\n\nTTTGCATGAGAGGC-1\n454\n0.020548\n1022.0\nB cells\npbmc3k\n\n\nTTTGCATGCCTCAC-1\n724\n0.008065\n1984.0\nCD4 T cells\npbmc3k\n\n\n\n\n2638 rows × 5 columns\n\n\n\n\nsc.pl.umap(adata_ref, color='louvain')\n\n\n\n\n\n\n\n\nMake sure we have the same genes in both datset by taking the intersection\n\nprint(adata_ref.shape[1])\nprint(adata.shape[1])\nvar_names = adata_ref.var_names.intersection(adata.var_names)\nprint(len(var_names))\n\nadata_ref = adata_ref[:, var_names]\nadata = adata[:, var_names]\n\n1838\n2727\n427\n\n\nFirst we need to rerun pca and umap with the same gene set for both datasets.\n\nsc.pp.pca(adata_ref)\nsc.pp.neighbors(adata_ref)\nsc.tl.umap(adata_ref)\nsc.pl.umap(adata_ref, color='louvain')\n\ncomputing PCA\n    with n_comps=50\n    finished (0:00:00)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 50\n    finished (0:00:08)\ncomputing UMAP\n    finished (0:00:04)\n\n\n\n\n\n\n\n\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='louvain_0.6')\n\ncomputing PCA\n    on highly variable genes\n    with n_comps=50\n    finished (0:00:00)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 50\n    finished (0:00:00)\ncomputing UMAP\n    finished (0:00:02)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#integrate-with-scanorama",
    "href": "labs/scanpy/scanpy_06_celltyping.html#integrate-with-scanorama",
    "title": " Celltype prediction",
    "section": "2 Integrate with scanorama",
    "text": "2 Integrate with scanorama\n\nimport scanorama\n\n#subset the individual dataset to the same variable genes as in MNN-correct.\nalldata = dict()\nalldata['ctrl']=adata\nalldata['ref']=adata_ref\n\n#convert to list of AnnData objects\nadatas = list(alldata.values())\n\n# run scanorama.integrate\nscanorama.integrate_scanpy(adatas, dimred = 50)\n\nFound 427 genes among all datasets\n[[0.         0.96329454]\n [0.         0.        ]]\nProcessing datasets (0, 1)\n\n\n\n# add in sample info\nadata_ref.obs['sample']='pbmc3k'\n\n# create a merged scanpy object and add in the scanorama \nadata_merged = alldata['ctrl'].concatenate(alldata['ref'], batch_key='sample', batch_categories=['ctrl','pbmc3k'])\n\nembedding = np.concatenate([ad.obsm['X_scanorama'] for ad in adatas], axis=0)\nadata_merged.obsm['Scanorama'] = embedding\n\n\n#run  umap.\nsc.pp.neighbors(adata_merged, n_pcs =50, use_rep = \"Scanorama\")\nsc.tl.umap(adata_merged)\n\ncomputing neighbors\n    finished (0:00:00)\ncomputing UMAP\n    finished (0:00:05)\n\n\n\nsc.pl.umap(adata_merged, color=[\"sample\",\"louvain\"])\n\n\n\n\n\n\n\n\n\n2.1 Label transfer\nUsing the function in the Spatial tutorial at the scanpy website we will calculate normalized cosine distances between the two datasets and tranfer labels to the celltype with the highest scores.\n\nfrom sklearn.metrics.pairwise import cosine_distances\n\ndistances = 1 - cosine_distances(\n    adata_merged[adata_merged.obs['sample'] == \"pbmc3k\"].obsm[\"Scanorama\"],\n    adata_merged[adata_merged.obs['sample'] == \"ctrl\"].obsm[\"Scanorama\"],\n)\n\ndef label_transfer(dist, labels, index):\n    lab = pd.get_dummies(labels)\n    class_prob = lab.to_numpy().T @ dist\n    norm = np.linalg.norm(class_prob, 2, axis=0)\n    class_prob = class_prob / norm\n    class_prob = (class_prob.T - class_prob.min(1)) / class_prob.ptp(1)\n    # convert to df\n    cp_df = pd.DataFrame(\n        class_prob, columns=lab.columns\n    )\n    cp_df.index = index\n    # classify as max score\n    m = cp_df.idxmax(axis=1)\n    \n    return m\n\nclass_def = label_transfer(distances, adata_ref.obs.louvain, adata.obs.index)\n\n# add to obs section of the original object\nadata.obs['predicted'] = class_def\n\nsc.pl.umap(adata, color=\"predicted\")\n\n\n\n\n\n\n\n\n\n# add to merged object.\nadata_merged.obs[\"predicted\"] = pd.concat(\n    [class_def, adata_ref.obs[\"louvain\"]], axis=0\n).tolist()\n\nsc.pl.umap(adata_merged, color=[\"sample\",\"louvain\",'predicted'])\n#plot only ctrl cells.\nsc.pl.umap(adata_merged[adata_merged.obs['sample']=='ctrl'], color='predicted')"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#ingest",
    "href": "labs/scanpy/scanpy_06_celltyping.html#ingest",
    "title": " Celltype prediction",
    "section": "3 Ingest",
    "text": "3 Ingest\nAnother method for celltype prediction is Ingest, for more information, please look at https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html\n\nsc.tl.ingest(adata, adata_ref, obs='louvain')\nsc.pl.umap(adata, color=['louvain','louvain_0.6'], wspace=0.5)\n\nrunning ingest\n    finished (0:00:20)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#compare-results",
    "href": "labs/scanpy/scanpy_06_celltyping.html#compare-results",
    "title": " Celltype prediction",
    "section": "4 Compare results",
    "text": "4 Compare results\nThe predictions from ingest is stored in the column ‘louvain’ while we named the label transfer with scanorama as ‘predicted’\n\nsc.pl.umap(adata, color=['louvain','predicted'], wspace=0.5)\n\n\n\n\n\n\n\n\nAs you can see, the main celltypes are the same, but dendritic cells are mainly predicted to cluster 8 by ingest and the proportions of the different celltypes are different.\nThe only way to make sure which method you trust is to look at what genes the different celltypes express and use your biological knowledge to make decisions."
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#gene-set-analysis",
    "href": "labs/scanpy/scanpy_06_celltyping.html#gene-set-analysis",
    "title": " Celltype prediction",
    "section": "5 Gene set analysis",
    "text": "5 Gene set analysis\nAnother way of predicting celltypes is to use the differentially expressed genes per cluster and compare to lists of known cell marker genes. This requires a list of genes that you trust and that is relevant for the tissue you are working on.\nYou can either run it with a marker list from the ontology or a list of your choice as in the example below.\n\npath_file = 'data/human_cell_markers.txt'\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(\n        path_data, 'human_cell_markers.txt'), path_file)\n\n\ndf = pd.read_table(path_file)\ndf\n\n\n\n\n\n\n\n\nspeciesType\ntissueType\nUberonOntologyID\ncancerType\ncellType\ncellName\nCellOntologyID\ncellMarker\ngeneSymbol\ngeneID\nproteinName\nproteinID\nmarkerResource\nPMID\nCompany\n\n\n\n\n0\nHuman\nKidney\nUBERON_0002113\nNormal\nNormal cell\nProximal tubular cell\nNaN\nIntestinal Alkaline Phosphatase\nALPI\n248\nPPBI\nP09923\nExperiment\n9263997\nNaN\n\n\n1\nHuman\nLiver\nUBERON_0002107\nNormal\nNormal cell\nIto cell (hepatic stellate cell)\nCL_0000632\nSynaptophysin\nSYP\n6855\nSYPH\nP08247\nExperiment\n10595912\nNaN\n\n\n2\nHuman\nEndometrium\nUBERON_0001295\nNormal\nNormal cell\nTrophoblast cell\nCL_0000351\nCEACAM1\nCEACAM1\n634\nCEAM1\nP13688\nExperiment\n10751340\nNaN\n\n\n3\nHuman\nGerm\nUBERON_0000923\nNormal\nNormal cell\nPrimordial germ cell\nCL_0000670\nVASA\nDDX4\n54514\nDDX4\nQ9NQI0\nExperiment\n10920202\nNaN\n\n\n4\nHuman\nCorneal epithelium\nUBERON_0001772\nNormal\nNormal cell\nEpithelial cell\nCL_0000066\nKLF6\nKLF6\n1316\nKLF6\nQ99612\nExperiment\n12407152\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2863\nHuman\nEmbryo\nUBERON_0000922\nNormal\nNormal cell\n1-cell stage cell (Blastomere)\nCL_0000353\nACCSL, ACVR1B, ARHGEF16, ASF1B, BCL2L10, BLCAP...\nACCSL, ACVR1B, ARHGEF16, ASF1B, BCL2L10, BLCAP...\n390110, 91, 27237, 55723, 10017, 10904, 662, 7...\n1A1L2, ACV1B, ARHGG, ASF1B, B2L10, BLCAP, SEC2...\nQ4AC99, P36896, Q5VV41, Q9NVP2, Q9HD36, P62952...\nSingle-cell sequencing\n23892778\nNaN\n\n\n2864\nHuman\nEmbryo\nUBERON_0000922\nNormal\nNormal cell\n4-cell stage cell (Blastomere)\nCL_0000353\nADPGK, AIM1, AIMP2, ARG2, ARHGAP17, ARIH1, CDC...\nADPGK, CRYBG1, AIMP2, ARG2, ARHGAP17, ARIH1, C...\n83440, 202, 7965, 384, 55114, 25820, 55536, 24...\nADPGK, CRBG1, AIMP2, ARGI2, RHG17, ARI1, CDA7L...\nQ9BRR6, Q9Y4K1, Q13155, P78540, Q68EM7, Q9Y4X5...\nSingle-cell sequencing\n23892778\nNaN\n\n\n2865\nHuman\nEmbryo\nUBERON_0000922\nNormal\nNormal cell\n8-cell stage cell (Blastomere)\nCL_0000353\nC11orf48, C19orf53, DHX9, DIABLO, EIF1AD, EIF4...\nLBHD1, C19orf53, DHX9, DIABLO, EIF1AD, EIF4G1,...\n79081, 28974, 1660, 56616, 84285, 1981, 26017,...\nLBHD1, L10K, DHX9, DBLOH, EIF1A, IF4G1, FA32A,...\nQ9BQE6, Q9UNZ5, Q08211, Q9NR28, Q8N9N8, Q04637...\nSingle-cell sequencing\n23892778\nNaN\n\n\n2866\nHuman\nEmbryo\nUBERON_0000922\nNormal\nNormal cell\nMorula cell (Blastomere)\nCL_0000360\nADCK1, AGL, AIMP1, AKAP12, ARPC3, ATP1B3, ATP5...\nADCK1, AGL, AIMP1, AKAP12, ARPC3, ATP1B3, NA, ...\n57143, 178, 9255, 9590, 10094, 483, NA, 586, 9...\nADCK1, GDE, AIMP1, AKA12, ARPC3, AT1B3, AT5F1,...\nQ86TW2, P35573, Q12904, Q02952, O15145, P54709...\nSingle-cell sequencing\n23892778\nNaN\n\n\n2867\nHuman\nBrain\nUBERON_0000955\noligodendroglioma\nCancer cell\nCancer stem cell\nNaN\nASCL1, BOC, CCND2, CD24, CHD7, EGFR, NFIB, SOX...\nASCL1, BOC, CCND2, CD24, CHD7, EGFR, NFIB, SOX...\n429, 91653, 894, 100133941, 55636, 1956, 4781,...\nASCL1, BOC, CCND2, CD24, CHD7, EGFR, NFIB, SOX...\nP50553, Q9BWV1, P30279, P25063, Q9P2D1, P00533...\nSingle-cell sequencing\n27806376\nNaN\n\n\n\n\n2868 rows × 15 columns\n\n\n\n\n# Filter for number of genes per celltype\nprint(df.shape)\n\n(2868, 15)\n\n\n\ndf['nG'] = df.geneSymbol.str.split(\",\").str.len()\n\ndf = df[df['nG'] &gt; 5]\ndf = df[df['nG'] &lt; 100]\nd = df[df['cancerType'] == \"Normal\"]\nprint(df.shape)\n\n(445, 16)\n\n\n\n# this chunk has issues and therefore not evaluated\n\ndf.index = df.cellName\ngene_dict = df.geneSymbol.str.split(\",\").to_dict()\n\n# run differential expression per cluster\nsc.tl.rank_genes_groups(adata, 'louvain_0.6', method='wilcoxon', key_added = \"wilcoxon\")\n\n\n# this chunk has issues and therefore not evaluated\n\n# do gene set overlap to the groups in the gene list and top 300 DEGs.\nimport gseapy\n\ngsea_res = dict()\npred = dict()\n\nfor cl in adata.obs['louvain_0.6'].cat.categories.tolist():\n    print(cl)\n    glist = sc.get.rank_genes_groups_df(adata, group=cl, key='wilcoxon')[\n        'names'].squeeze().str.strip().tolist()\n    enr_res = gseapy.enrichr(gene_list=glist[:300],\n                             organism='Human',\n                             gene_sets=gene_dict,\n                             background=adata.raw.shape[1],\n                             cutoff=1)\n    if enr_res.results.shape[0] == 0:\n        pred[cl] = \"Unass\"\n    else:\n        enr_res.results.sort_values(\n            by=\"P-value\", axis=0, ascending=True, inplace=True)\n        print(enr_res.results.head(2))\n        gsea_res[cl] = enr_res\n        pred[cl] = enr_res.results[\"Term\"][0]\n\n\n# this chunk has issues and therefore not evaluated\n\n# prediction per cluster\npred\n\n\n# this chunk has issues and therefore not evaluated\n\nprediction = [pred[x] for x in adata.obs['louvain_0.6']]\nadata.obs[\"GS_overlap_pred\"] = prediction\n\nsc.pl.umap(adata, color='GS_overlap_pred')\n\n\n\n\n\n\n\nDiscuss\n\n\n\nAs you can see, it agrees to some extent with the predictions from label transfer and ingest, but there are clear differences, which do you think looks better?"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#meta-session",
    "href": "labs/scanpy/scanpy_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nannoy               NA\nanyio               NA\narray_api_compat    1.4\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfbpca               NA\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nintervaltree        NA\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscanorama           1.7.4\nscipy               1.11.4\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsortedcontainers    2.4.0\nsparse              0.14.0\nstack_data          0.6.2\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:24"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html",
    "href": "labs/scanpy/scanpy_07_trajectory.html",
    "title": " Trajectory inference using PAGA",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nPartly following this tutorial."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#loading-libraries",
    "href": "labs/scanpy/scanpy_07_trajectory.html#loading-libraries",
    "title": " Trajectory inference using PAGA",
    "section": "1 Loading libraries",
    "text": "1 Loading libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as pl\nfrom matplotlib import rcParams\nimport scanpy as sc\n\nimport scipy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=100, frameon=False, figsize=(5, 5), facecolor='white', color_map = 'viridis_r')"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#loading-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#loading-data",
    "title": " Trajectory inference using PAGA",
    "section": "2 Loading data",
    "text": "2 Loading data\nIn order to speed up the computations during the exercises, we will be using a subset of a bone marrow dataset (originally containing about 100K cells). The bone marrow is the source of adult immune cells, and contains virtually all differentiation stages of cell from the immune system which later circulate in the blood to all other organs.\n\n\n\n\n\nAll the data has been preprocessed with Seurat. The file trajectory_scanpy_filtered.h5ad was converted from the Seurat object using the SeuratDisk package. For more information on how it was done, have a look at the script: convert_to_h5ad.R in the github repo.\n\nimport os\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_trajectory = \"./data/trajectory\"\nif not os.path.exists(path_trajectory):\n    os.makedirs(path_trajectory, exist_ok=True)\n\n\nimport urllib.request\n\npath_results = \"data/trajectory\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/trajectory/trajectory_seurat_filtered.h5ad\"\nif not os.path.exists(path_file):\n    file_url = os.path.join(\n        path_data, \"trajectory/trajectory_seurat_filtered.h5ad\")\n    urllib.request.urlretrieve(file_url, path_file)\n\nCheck that the variable names are correct.\n\nadata = sc.read_h5ad(\"data/trajectory/trajectory_seurat_filtered.h5ad\")\nadata.var\n\n\n\n\n\n\n\n\nfeatures\n\n\n\n\n0610040J01Rik\n0610040J01Rik\n\n\n1190007I07Rik\n1190007I07Rik\n\n\n1500009L16Rik\n1500009L16Rik\n\n\n1700012B09Rik\n1700012B09Rik\n\n\n1700020L24Rik\n1700020L24Rik\n\n\n...\n...\n\n\nSqor\nSqor\n\n\nSting1\nSting1\n\n\nTent5a\nTent5a\n\n\nTlcd4\nTlcd4\n\n\nZnrd2\nZnrd2\n\n\n\n\n3585 rows × 1 columns\n\n\n\n\n# check what you have in the X matrix, should be lognormalized counts.\nprint(adata.X[:10,:10])\n\n  (0, 4)    0.11622072805743532\n  (0, 8)    0.4800893970571722\n  (1, 8)    0.2478910541698065\n  (1, 9)    0.17188973970230348\n  (2, 1)    0.09413397843954842\n  (2, 7)    0.18016412971724202\n  (3, 1)    0.08438841021254412\n  (3, 4)    0.08438841021254412\n  (3, 7)    0.08438841021254412\n  (3, 8)    0.3648216463668793\n  (4, 1)    0.14198147850903975\n  (4, 8)    0.14198147850903975\n  (5, 1)    0.17953169693896723\n  (5, 8)    0.17953169693896723\n  (5, 9)    0.17953169693896723\n  (6, 4)    0.2319546390006887\n  (6, 8)    0.42010741700351195\n  (7, 1)    0.1775659421407816\n  (7, 8)    0.39593115482156394\n  (7, 9)    0.09271901219711086\n  (8, 1)    0.12089079757716388\n  (8, 8)    0.22873058755480363\n  (9, 1)    0.08915380247493314\n  (9, 4)    0.08915380247493314\n  (9, 8)    0.38270398718590104"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#explore-the-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#explore-the-data",
    "title": " Trajectory inference using PAGA",
    "section": "3 Explore the data",
    "text": "3 Explore the data\nThere is a umap and clusters provided with the object, first plot some information from the previous analysis onto the umap.\n\nsc.pl.umap(adata, color = ['clusters','dataset','batches','Phase'],legend_loc = 'on data', legend_fontsize = 'xx-small', ncols = 2)\n\n\n\n\n\n\n\n\nIt is crucial that you performing analysis of a dataset understands what is going on, what are the clusters you see in your data and most importantly How are the clusters related to each other?. Well, let’s explore the data a bit. With the help of this table, write down which cluster numbers in your dataset express these key markers.\n\n\n\nMarker\nCell Type\n\n\n\n\nCd34\nHSC progenitor\n\n\nMs4a1\nB cell lineage\n\n\nCd3e\nT cell lineage\n\n\nLtf\nGranulocyte lineage\n\n\nCst3\nMonocyte lineage\n\n\nMcpt8\nMast Cell lineage\n\n\nAlas2\nRBC lineage\n\n\nSiglech\nDendritic cell lineage\n\n\nC1qc\nMacrophage cell lineage\n\n\nPf4\nMegakaryocyte cell lineage\n\n\n\n\nmarkers = [\"Cd34\",\"Alas2\",\"Pf4\",\"Mcpt8\",\"Ltf\",\"Cst3\", \"Siglech\", \"C1qc\", \"Ms4a1\", \"Cd3e\", ]\nsc.pl.umap(adata, color = markers, use_raw = False, ncols = 4)"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#rerun-analysis-in-scanpy",
    "href": "labs/scanpy/scanpy_07_trajectory.html#rerun-analysis-in-scanpy",
    "title": " Trajectory inference using PAGA",
    "section": "4 Rerun analysis in Scanpy",
    "text": "4 Rerun analysis in Scanpy\nRedo clustering and umap using the basic Scanpy pipeline. Use the provided “X_harmony_Phase” dimensionality reduction as the staring point.\n\n# first, store the old umap with a new name so it is not overwritten\nadata.obsm['X_umap_old'] = adata.obsm['X_umap']\n\nsc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20, use_rep=\"X_harmony_Phase\")\nsc.tl.umap(adata, min_dist=0.4, spread=3)\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:09)\n\n\n\n#sc.tl.umap(adata, min_dist=0.6, spread=1.5)\nsc.pl.umap(adata, color = ['clusters'],legend_loc = 'on data', legend_fontsize = 'xx-small', edges = True)\n\nsc.pl.umap(adata, color = markers, use_raw = False, ncols = 4)\n\n# Redo clustering as well\nsc.tl.leiden(adata, key_added = \"leiden_1.0\", resolution = 1.0) # default resolution in 1.0\nsc.tl.leiden(adata, key_added = \"leiden_1.2\", resolution = 1.2) # default resolution in 1.0\nsc.tl.leiden(adata, key_added = \"leiden_1.4\", resolution = 1.4) # default resolution in 1.0\n\n#sc.tl.louvain(adata, key_added = \"leiden_1.0\") # default resolution in 1.0\nsc.pl.umap(adata, color = ['leiden_1.0', 'leiden_1.2', 'leiden_1.4','clusters'],legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrunning Leiden clustering\n    finished: found 16 clusters and added\n    'leiden_1.0', the cluster labels (adata.obs, categorical) (0:00:02)\nrunning Leiden clustering\n    finished: found 17 clusters and added\n    'leiden_1.2', the cluster labels (adata.obs, categorical) (0:00:01)\nrunning Leiden clustering\n    finished: found 19 clusters and added\n    'leiden_1.4', the cluster labels (adata.obs, categorical) (0:00:02)\n\n\n\n\n\n\n\n\n\n\n#Rename clusters with really clear markers, the rest are left unlabelled.\n\nannot = pd.DataFrame(adata.obs['leiden_1.4'].astype('string'))\nannot[annot['leiden_1.4'] == '10'] = '10_megakaryo' #Pf4\nannot[annot['leiden_1.4'] == '17'] = '17_macro'  #C1qc\nannot[annot['leiden_1.4'] == '11'] = '11_eryth' #Alas2\nannot[annot['leiden_1.4'] == '18'] = '18_dend' #Siglech\nannot[annot['leiden_1.4'] == '13'] = '13_mast' #Mcpt8\nannot[annot['leiden_1.4'] == '0'] = '0_mono' #Cts3\nannot[annot['leiden_1.4'] == '1'] = '1_gran' #Ltf\nannot[annot['leiden_1.4'] == '9'] = '9_gran'\nannot[annot['leiden_1.4'] == '14'] = '14_TC' #Cd3e\nannot[annot['leiden_1.4'] == '16'] = '16_BC' #Ms4a1\nannot[annot['leiden_1.4'] == '8'] = '8_progen'  # Cd34\nannot[annot['leiden_1.4'] == '4'] = '4_progen' \nannot[annot['leiden_1.4'] == '5'] = '5_progen'\n\nadata.obs['annot']=annot['leiden_1.4'].astype('category')\n\nsc.pl.umap(adata, color = 'annot',legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)\n\nannot.value_counts()\n#type(annot)\n\n# astype('category')\n\n\n\n\n\n\n\n\nleiden_1.4  \n0_mono          509\n1_gran          487\n2               479\n3               463\n4_progen        387\n5_progen        384\n7               368\n6               368\n8_progen        367\n9_gran          366\n10_megakaryo    301\n11_eryth        294\n12              276\n13_mast         159\n14_TC           151\n15              128\n16_BC           124\n17_macro        116\n18_dend         101\nName: count, dtype: int64\n\n\n\n# plot onto the Seurat embedding:\nsc.pl.embedding(adata, basis='X_umap_old', color = 'annot',legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#run-paga",
    "href": "labs/scanpy/scanpy_07_trajectory.html#run-paga",
    "title": " Trajectory inference using PAGA",
    "section": "5 Run PAGA",
    "text": "5 Run PAGA\nUse the clusters from leiden clustering with leiden_1.4 and run PAGA. First we create the graph and initialize the positions using the umap.\n\n# use the umap to initialize the graph layout.\nsc.tl.draw_graph(adata, init_pos='X_umap')\nsc.pl.draw_graph(adata, color='annot', legend_loc='on data', legend_fontsize = 'xx-small')\nsc.tl.paga(adata, groups='annot')\nsc.pl.paga(adata, color='annot', edge_width_scale = 0.3)\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:03)\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, we have edges between many clusters that we know are are unrelated, so we may need to clean up the data a bit more."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#data-pre-processing-prior-trajectory-inference",
    "href": "labs/scanpy/scanpy_07_trajectory.html#data-pre-processing-prior-trajectory-inference",
    "title": " Trajectory inference using PAGA",
    "section": "6 Data pre-processing prior trajectory inference",
    "text": "6 Data pre-processing prior trajectory inference\nFirst, lets explore the graph a bit. So we plot the umap with the graph connections on top.\n\nsc.pl.umap(adata, edges=True, color = 'annot', legend_loc= 'on data', legend_fontsize= 'xx-small')\n\n\n\n\n\n\n\n\nWe have many edges in the graph between unrelated clusters, so lets try with fewer neighbors.\n\nsc.pp.neighbors(adata, n_neighbors=5,  use_rep = 'X_harmony_Phase', n_pcs = 30)\nsc.pl.umap(adata, edges=True, color = 'annot', legend_loc= 'on data', legend_fontsize= 'xx-small')\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#rerun-paga-again-on-the-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#rerun-paga-again-on-the-data",
    "title": " Trajectory inference using PAGA",
    "section": "7 Rerun PAGA again on the data",
    "text": "7 Rerun PAGA again on the data\n\nsc.tl.draw_graph(adata, init_pos='X_umap')\nsc.pl.draw_graph(adata, color='annot', legend_loc='on data', legend_fontsize = 'xx-small')\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:02)\n\n\n\n\n\n\n\n\n\n\nsc.tl.paga(adata, groups='annot')\nsc.pl.paga(adata, color='annot', edge_width_scale = 0.3)\n\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#recomputing-the-embedding-using-paga-initialization",
    "href": "labs/scanpy/scanpy_07_trajectory.html#recomputing-the-embedding-using-paga-initialization",
    "title": " Trajectory inference using PAGA",
    "section": "8 Recomputing the embedding using PAGA-initialization",
    "text": "8 Recomputing the embedding using PAGA-initialization\nThe following is just as well possible for a UMAP.\n\nsc.tl.draw_graph(adata, init_pos='paga')\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:15)\n\n\nNow we can see all marker genes also at single-cell resolution in a meaningful layout.\n\nsc.pl.draw_graph(adata, color=['annot'], legend_loc='on data', legend_fontsize=  'xx-small')\n\n\n\n\n\n\n\n\nCompare the 2 graphs\n\nsc.pl.paga_compare(\n    adata, threshold=0.03, title='', right_margin=0.2, size=10, edge_width_scale=0.5,\n    legend_fontsize=12, fontsize=12, frameon=False, edges=True)\n\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#reconstructing-gene-changes-along-paga-paths-for-a-given-set-of-genes",
    "href": "labs/scanpy/scanpy_07_trajectory.html#reconstructing-gene-changes-along-paga-paths-for-a-given-set-of-genes",
    "title": " Trajectory inference using PAGA",
    "section": "9 Reconstructing gene changes along PAGA paths for a given set of genes",
    "text": "9 Reconstructing gene changes along PAGA paths for a given set of genes\nChoose a root cell for diffusion pseudotime. We have 3 progenitor clusters, but cluster 5 seems the most clear.\n\nadata.uns['iroot'] = np.flatnonzero(adata.obs['annot']  == '5_progen')[0]\n\nsc.tl.dpt(adata)\n\nWARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.\ncomputing Diffusion Maps using n_comps=15(=n_dcs)\ncomputing transitions\n    finished (0:00:00)\n    eigenvalues of transition matrix\n    [1.         0.9989591  0.997628   0.9970365  0.9956704  0.99334306\n     0.9918951  0.9915921  0.99013233 0.98801893 0.9870309  0.9861044\n     0.9851118  0.9845008  0.9839531 ]\n    finished: added\n    'X_diffmap', diffmap coordinates (adata.obsm)\n    'diffmap_evals', eigenvalues of transition matrix (adata.uns) (0:00:01)\ncomputing Diffusion Pseudotime using n_dcs=10\n    finished: added\n    'dpt_pseudotime', the pseudotime (adata.obs) (0:00:00)\n\n\nUse the full raw data for visualization.\n\nsc.pl.draw_graph(adata, color=['annot', 'dpt_pseudotime'], legend_loc='on data', legend_fontsize= 'x-small')\n\n\n\n\n\n\n\n\nBy looking at the different know lineages and the layout of the graph we define manually some paths to the graph that corresponds to spcific lineages.\n\n# Define paths\n\npaths = [('erythrocytes', ['5_progen', '8_progen', '6', '3', '7', '11_eryth']),\n         ('lympoid', ['5_progen', '12', '16_BC', '14_TC']),\n         ('granulo', ['5_progen', '4_progen', '2', '9_gran', '1_gran']),\n         ('mono', ['5_progen', '4_progen', '0_mono', '18_dend', '17_macro'])\n         ]\n\nadata.obs['distance'] = adata.obs['dpt_pseudotime']\n\nThen we select some genes that can vary in the lineages and plot onto the paths.\n\ngene_names = ['Gata2', 'Gata1', 'Klf1', 'Epor', 'Hba-a2',  # erythroid\n              'Elane', 'Cebpe', 'Gfi1',                    # neutrophil\n              'Irf8', 'Csf1r', 'Ctsg',                     # monocyte\n              'Itga2b','Prss34','Cma1','Procr',            # Megakaryo,Basophil,Mast,HPC\n              'C1qc','Siglech','Ms4a1','Cd3e','Cd34']\n\n\n_, axs = pl.subplots(ncols=4, figsize=(10, 4), gridspec_kw={\n                     'wspace': 0.05, 'left': 0.12})\npl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2)\nfor ipath, (descr, path) in enumerate(paths):\n    _, data = sc.pl.paga_path(\n        adata, path, gene_names,\n        show_node_names=False,\n        ax=axs[ipath],\n        ytick_fontsize=12,\n        left_margin=0.15,\n        n_avg=50,\n        annotations=['distance'],\n        show_yticks=True if ipath == 0 else False,\n        show_colorbar=False,\n        color_map='Greys',\n        groups_key='annot',\n        color_maps_annotations={'distance': 'viridis'},\n        title='{} path'.format(descr),\n        return_data=True,\n        use_raw=False,\n        show=False)\n    data.to_csv('data/trajectory/paga_path_{}.csv'.format(descr))\npl.savefig('data/trajectory/paga_path.pdf')\npl.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nAs you can see, we can manipulate the trajectory quite a bit by selecting different number of neighbors, components etc. to fit with our assumptions on the development of these celltypes.\nPlease explore further how you can tweak the trajectory. For instance, can you create a PAGA trajectory using the orignial umap from Seurat instead? Hint, you first need to compute the neighbors on the umap."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#session-info",
    "href": "labs/scanpy/scanpy_07_trajectory.html#session-info",
    "title": " Trajectory inference using PAGA",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfontTools           4.47.0\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnetworkx            3.2.1\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsparse              0.14.0\nstack_data          0.6.2\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:26"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html",
    "href": "labs/scanpy/scanpy_08_spatial.html",
    "title": " Spatial Transcriptomics",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nAdapted from tutorials by Giovanni Palla (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html) and Carlos Talavera-López (https://docs.scvi-tools.org/en/latest/tutorials/notebooks/stereoscope_heart_LV_tutorial.html)\nSpatial transcriptomic data with the Visium platform is in many ways similar to scRNAseq data. It contains UMI counts for 5-20 cells instead of single cells, but is still quite sparse in the same way as scRNAseq data is, but with the additional information about spatial location in the tissue.\nHere we will first run quality control in a similar manner to scRNAseq data, then QC filtering, dimensionality reduction, integration and clustering. Then we will use scRNAseq data from mouse cortex to run LabelTransfer to predict celltypes in the Visium spots.\nWe will use two Visium spatial transcriptomics dataset of the mouse brain (Sagittal), which are publicly available from the 10x genomics website. Note, that these dataset have already been filtered for spots that does not overlap with the tissue."
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_prep",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_prep",
    "title": " Spatial Transcriptomics",
    "section": "1 Preparation",
    "text": "1 Preparation\nLoad packages\n\nimport scanpy as sc\nimport anndata as an\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scanorama\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n#sc.logging.print_versions() # gives errror!!\nsc.set_figure_params(facecolor=\"white\", figsize=(8, 8))\nsc.settings.verbosity = 3\n\nLoad ST data\nThe function datasets.visium_sge() downloads the dataset from 10x genomics and returns an AnnData object that contains counts, images and spatial coordinates. We will calculate standards QC metrics with pp.calculate_qc_metrics() and visualize them.\nWhen using your own Visium data, use Scanpy’s read_visium() function to import it.\n\nimport os\nif not os.path.exists(\"./data/spatial/visium\"):\n    os.makedirs(\"./data/spatial/visium\")\n\n\nadata_anterior = sc.datasets.visium_sge(\n    sample_id=\"V1_Mouse_Brain_Sagittal_Anterior\"\n)\nadata_posterior = sc.datasets.visium_sge(\n    sample_id=\"V1_Mouse_Brain_Sagittal_Posterior\"\n)\n\nreading /work/labs/scanpy/data/V1_Mouse_Brain_Sagittal_Anterior/filtered_feature_bc_matrix.h5\n (0:00:00)\nreading /work/labs/scanpy/data/V1_Mouse_Brain_Sagittal_Posterior/filtered_feature_bc_matrix.h5\n (0:00:00)\n\n\n\nadata_anterior.var_names_make_unique()\nadata_posterior.var_names_make_unique()\n\nTo make sure that both images are included in the merged object, use uns_merge=“unique”.\n\n# merge into one dataset\nlibrary_names = [\"V1_Mouse_Brain_Sagittal_Anterior\", \"V1_Mouse_Brain_Sagittal_Posterior\"]\n\nadata = adata_anterior.concatenate(\n    adata_posterior,\n    batch_key=\"library_id\",\n    uns_merge=\"unique\",\n    batch_categories=library_names\n)\n\nadata\n\nAnnData object with n_obs × n_vars = 6050 × 32285\n    obs: 'in_tissue', 'array_row', 'array_col', 'library_id'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'spatial'\n    obsm: 'spatial'\n\n\nAs you can see, we now have the slot spatial in obsm, which contains the spatial information from the Visium platform."
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_qc",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_qc",
    "title": " Spatial Transcriptomics",
    "section": "2 Quality control",
    "text": "2 Quality control\nSimilar to scRNA-seq we use statistics on number of counts, number of features and percent mitochondria for quality control.\n\n# add info on mitochondrial and hemoglobin genes to the objects.\nadata.var['mt'] = adata.var_names.str.startswith('mt-') \nadata.var['hb'] = adata.var_names.str.contains((\"^Hb.*-\"))\n\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt','hb'], percent_top=None, log1p=False, inplace=True)\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_hb'], jitter=0.4, groupby = 'library_id', rotation= 45)\n\n\n\n\n\n\n\n\nWe can also plot the same data onto the tissue section.\nIn scanpy, this is a bit tricky when you have multiple sections, as you would have to subset and plot them separately.\n\n# need to plot the two sections separately and specify the library_id\nfor library in library_names:\n    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = [\"total_counts\", \"n_genes_by_counts\",'pct_counts_mt', 'pct_counts_hb'])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, the spots with low number of counts/features and high mitochondrial content are mainly towards the edges of the tissue. It is quite likely that these regions are damaged tissue. You may also see regions within a tissue with low quality if you have tears or folds in your section.\nBut remember, for some tissue types, the amount of genes expressed and proportion mitochondria may also be a biological features, so bear in mind what tissue you are working on and what these features mean.\n\n2.1 Filter spots\nSelect all spots with less than 25% mitocondrial reads, less than 20% hb-reads and 500 detected genes. You must judge for yourself based on your knowledge of the tissue what are appropriate filtering criteria for your dataset.\n\nkeep = (adata.obs['pct_counts_hb'] &lt; 20) & (adata.obs['pct_counts_mt'] &lt; 25) & (adata.obs['n_genes_by_counts'] &gt; 1000)\nprint(sum(keep))\n\nadata = adata[keep,:]\n\n5749\n\n\nAnd replot onto tissue sections.\n\nfor library in library_names:\n    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = [\"total_counts\", \"n_genes_by_counts\",'pct_counts_mt', 'pct_counts_hb'])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2 Top expressed genes\nAs for scRNA-seq data, we will look at what the top expressed genes are.\n\nsc.pl.highest_expr_genes(adata, n_top=20)\n\nnormalizing counts per cell\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\nAs you can see, the mitochondrial genes are among the top expressed genes. Also the lncRNA gene Bc1 (brain cytoplasmic RNA 1). Also one hemoglobin gene.\n\n\n2.3 Filter genes\nWe will remove the Bc1 gene, hemoglobin genes (blood contamination) and the mitochondrial genes.\n\nmito_genes = adata.var_names.str.startswith('mt-')\nhb_genes = adata.var_names.str.contains('^Hb.*-')\n\nremove = np.add(mito_genes, hb_genes)\nremove[adata.var_names == \"Bc1\"] = True\nkeep = np.invert(remove)\nprint(sum(remove))\n\nadata = adata[:,keep]\n\nprint(adata.n_obs, adata.n_vars)\n\n22\n5749 32263"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_analysis",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_analysis",
    "title": " Spatial Transcriptomics",
    "section": "3 Analysis",
    "text": "3 Analysis\nWe will proceed with the data in a very similar manner to scRNA-seq data.\nAs we have two sections, we will select variable genes with batch_key=“library_id” and then take the union of variable genes for further analysis. The idea is to avoid including batch specific genes in the analysis.\n\n# save the counts to a separate object for later, we need the normalized counts in raw for DEG dete\ncounts_adata = adata.copy()\n\nsc.pp.normalize_total(adata, inplace=True)\nsc.pp.log1p(adata)\n# take 1500 variable genes per batch and then use the union of them.\nsc.pp.highly_variable_genes(adata, flavor=\"seurat\", n_top_genes=1500, inplace=True, batch_key=\"library_id\")\n\n# subset for variable genes\nadata.raw = adata\nadata = adata[:,adata.var.highly_variable_nbatches &gt; 0]\n\n# scale data\nsc.pp.scale(adata)\n\nnormalizing counts per cell\n    finished (0:00:00)\nIf you pass `n_top_genes`, all cutoffs are ignored.\nextracting highly variable genes\n    finished (0:00:02)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n\n\nNow we can plot gene expression of individual genes, the gene Hpca is a strong hippocampal marker and Ttr is a marker of the choroid plexus.\n\nfor library in library_names:\n    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = [\"Ttr\", \"Hpca\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1 Dimensionality reduction and clustering\nWe can then now run dimensionality reduction and clustering using the same workflow as we use for scRNA-seq analysis.\n\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.tl.leiden(adata, key_added=\"clusters\")\n\ncomputing neighbors\nWARNING: You’re trying to run this on 2405 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n         Falling back to preprocessing with `sc.pp.pca` and default params.\ncomputing PCA\n    with n_comps=50\n    finished (0:00:00)\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:09)\nrunning Leiden clustering\n    finished: found 23 clusters and added\n    'clusters', the cluster labels (adata.obs, categorical) (0:00:01)\n\n\nWe can then plot clusters onto umap or onto the tissue section.\n\nsc.pl.umap(\n    adata, color=[\"clusters\", \"library_id\"], palette=sc.pl.palettes.default_20\n)\n\nWARNING: Length of palette colors is smaller than the number of categories (palette length: 20, categories length: 23. Some categories will have the same color.\n\n\n\n\n\n\n\n\n\nAs we are plotting the two sections separately, we need to make sure that they get the same colors by fetching cluster colors from a dict.\n\nclusters_colors = dict(\n    zip([str(i) for i in range(len(adata.obs.clusters.cat.categories))], adata.uns[\"clusters_colors\"])\n)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 10))\n\nfor i, library in enumerate(\n    [\"V1_Mouse_Brain_Sagittal_Anterior\", \"V1_Mouse_Brain_Sagittal_Posterior\"]\n):\n    ad = adata[adata.obs.library_id == library, :].copy()\n    sc.pl.spatial(\n        ad,\n        img_key=\"hires\",\n        library_id=library,\n        color=\"clusters\",\n        size=1.5,\n        palette=[\n            v\n            for k, v in clusters_colors.items()\n            if k in ad.obs.clusters.unique().tolist()\n        ],\n        legend_loc=None,\n        show=False,\n        ax=axs[i],\n    )\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n3.2 Integration\nQuite often there are strong batch effects between different ST sections, so it may be a good idea to integrate the data across sections.\nWe will do a similar integration as in the Data Integration lab, here we will use Scanorama for integration.\n\nadatas = {}\nfor batch in library_names:\n    adatas[batch] = adata[adata.obs['library_id'] == batch,]\n\nadatas \n\n{'V1_Mouse_Brain_Sagittal_Anterior': View of AnnData object with n_obs × n_vars = 2597 × 2405\n     obs: 'in_tissue', 'array_row', 'array_col', 'library_id', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'clusters'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'spatial', 'library_id_colors', 'log1p', 'hvg', 'neighbors', 'umap', 'leiden', 'clusters_colors'\n     obsm: 'spatial', 'X_pca', 'X_umap'\n     obsp: 'distances', 'connectivities',\n 'V1_Mouse_Brain_Sagittal_Posterior': View of AnnData object with n_obs × n_vars = 3152 × 2405\n     obs: 'in_tissue', 'array_row', 'array_col', 'library_id', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'clusters'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'spatial', 'library_id_colors', 'log1p', 'hvg', 'neighbors', 'umap', 'leiden', 'clusters_colors'\n     obsm: 'spatial', 'X_pca', 'X_umap'\n     obsp: 'distances', 'connectivities'}\n\n\n\nimport scanorama\n\n#convert to list of AnnData objects\nadatas = list(adatas.values())\n\n# run scanorama.integrate\nscanorama.integrate_scanpy(adatas, dimred = 50)\n\n# Get all the integrated matrices.\nscanorama_int = [ad.obsm['X_scanorama'] for ad in adatas]\n\n# make into one matrix.\nall_s = np.concatenate(scanorama_int)\nprint(all_s.shape)\n\n# add to the AnnData object\nadata.obsm[\"Scanorama\"] = all_s\n\nadata\n\nFound 2405 genes among all datasets\n[[0.         0.47824413]\n [0.         0.        ]]\nProcessing datasets (0, 1)\n(5749, 50)\n\n\nAnnData object with n_obs × n_vars = 5749 × 2405\n    obs: 'in_tissue', 'array_row', 'array_col', 'library_id', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'clusters'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n    uns: 'spatial', 'library_id_colors', 'log1p', 'hvg', 'neighbors', 'umap', 'leiden', 'clusters_colors'\n    obsm: 'spatial', 'X_pca', 'X_umap', 'Scanorama'\n    obsp: 'distances', 'connectivities'\n\n\nThen we run dimensionality reduction and clustering as before.\n\nsc.pp.neighbors(adata, use_rep=\"Scanorama\")\nsc.tl.umap(adata)\nsc.tl.leiden(adata, key_added=\"clusters\")\n\nsc.pl.umap(\n    adata, color=[\"clusters\", \"library_id\"], palette=sc.pl.palettes.default_20\n)\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:09)\nrunning Leiden clustering\n    finished: found 19 clusters and added\n    'clusters', the cluster labels (adata.obs, categorical) (0:00:01)\n\n\n\n\n\n\n\n\n\nAs we have new clusters, we again need to make a new dict for cluster colors\n\nclusters_colors = dict(\n    zip([str(i) for i in range(len(adata.obs.clusters.cat.categories))], adata.uns[\"clusters_colors\"])\n)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 10))\n\nfor i, library in enumerate(\n    [\"V1_Mouse_Brain_Sagittal_Anterior\", \"V1_Mouse_Brain_Sagittal_Posterior\"]\n):\n    ad = adata[adata.obs.library_id == library, :].copy()\n    sc.pl.spatial(\n        ad,\n        img_key=\"hires\",\n        library_id=library,\n        color=\"clusters\",\n        size=1.5,\n        palette=[\n            v\n            for k, v in clusters_colors.items()\n            if k in ad.obs.clusters.unique().tolist()\n        ],\n        legend_loc=\"on data\",\n        show=False,\n        ax=axs[i],\n    )\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you see any differences between the integrated and non-integrated clustering? Judge for yourself, which of the clusterings do you think looks best? As a reference, you can compare to brain regions in the Allen brain atlas.\n\n\n\n\n3.3 Spatially Variable Features\nThere are two main workflows to identify molecular features that correlate with spatial location within a tissue. The first is to perform differential expression based on spatially distinct clusters, the other is to find features that have spatial patterning without taking clusters or spatial annotation into account. First, we will do differential expression between clusters just as we did for the scRNAseq data before.\n\n# run t-test \nsc.tl.rank_genes_groups(adata, \"clusters\", method=\"wilcoxon\")\n# plot as heatmap for cluster5 genes\nsc.pl.rank_genes_groups_heatmap(adata, groups=\"5\", n_genes=10, groupby=\"clusters\")\n\nranking genes\n    finished: added to `.uns['rank_genes_groups']`\n    'names', sorted np.recarray to be indexed by group ids\n    'scores', sorted np.recarray to be indexed by group ids\n    'logfoldchanges', sorted np.recarray to be indexed by group ids\n    'pvals', sorted np.recarray to be indexed by group ids\n    'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:15)\nWARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 50\nStoring dendrogram info using `.uns['dendrogram_clusters']`\nWARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.\ncategories: 0, 1, 2, etc.\nvar_group_labels: 5\n\n\n\n\n\n\n\n\n\n\n# plot onto spatial location\ntop_genes = sc.get.rank_genes_groups_df(adata, group='5',log2fc_min=0)['names'][:3]\n\nfor library in [\"V1_Mouse_Brain_Sagittal_Anterior\", \"V1_Mouse_Brain_Sagittal_Posterior\"]:\n    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = top_genes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial transcriptomics allows researchers to investigate how gene expression trends varies in space, thus identifying spatial patterns of gene expression. For this purpose there are multiple methods, such as SpatailDE, SPARK, Trendsceek, HMRF and Splotch.\nWe use SpatialDE Svensson et al., a Gaussian process-based statistical framework that aims to identify spatially variable genes.\n\nTakes a long time to run, so skip this step for now and download the precomputed file.\n\n\n# slow step\n\nimport NaiveDE\nimport SpatialDE\n\ncounts = sc.get.obs_df(adata, keys=list(adata.var_names), use_raw=True)\ntotal_counts = sc.get.obs_df(adata, keys=[\"total_counts\"])\nnorm_expr = NaiveDE.stabilize(counts.T).T\nresid_expr = NaiveDE.regress_out(\n    total_counts, norm_expr.T, \"np.log(total_counts)\").T\nresults = SpatialDE.run(adata.obsm[\"spatial\"], resid_expr)\n\nimport pickle\nwith open('data/spatial/visium/scanpy_spatialde.pkl', 'wb') as file:\n    pickle.dump(results, file)\n\n\nimport urllib.request\nimport os\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_file = \"data/spatial/visium/scanpy_spatialde.pkl\"\nif not os.path.exists(path_file):\n    file_url = os.path.join(\n        path_data, \"spatial/visium/results/scanpy_spatialde.pkl\")\n    urllib.request.urlretrieve(file_url, path_file)\n\n\nimport pickle\nwith open('data/spatial/visium/scanpy_spatialde.pkl', 'rb') as file:\n    results = pickle.load(file)\n\n\n# We concatenate the results with the DataFrame of annotations of variables: `adata.var`.\nresults.index = results[\"g\"]\nadata.var = pd.concat(\n    [adata.var, results.loc[adata.var.index.values, :]], axis=1)\nadata.write_h5ad('./data/spatial/visium/adata_processed_sc.h5ad')\n\n# Then we can inspect significant genes that varies in space and visualize them with `sc.pl.spatial` function.\nresults.sort_values(\"qval\").head(10)\n\n\n\n\n\n\n\n\nFSV\nM\ng\nl\nmax_delta\nmax_ll\nmax_mu_hat\nmax_s2_t_hat\nmodel\nn\ns2_FSV\ns2_logdelta\ntime\nBIC\nmax_ll_null\nLLR\npval\nqval\n\n\ng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfnb3\n1.775241e-01\n4\nEfnb3\n544.733658\n4.490546e+00\n-4701.690768\n0.920436\n6.950994e-02\nSE\n5749\n8.838199e-06\n4.029374e-04\n0.002817\n9438.008662\n-5374.163817\n672.473049\n0.0\n0.0\n\n\nS100a16\n5.205988e-02\n4\nS100a16\n544.733658\n1.764863e+01\n-4013.533873\n1.703474\n3.034361e-02\nSE\n5749\n7.639943e-06\n2.521451e-03\n0.002874\n8061.694871\n-4099.970498\n86.436625\n0.0\n0.0\n\n\nS100a5\n3.082312e-01\n4\nS100a5\n544.733658\n2.175292e+00\n-989.712703\n-0.692740\n3.893413e-02\nSE\n5749\n1.244686e-05\n3.006748e-04\n0.006836\n2014.052530\n-2128.916543\n1139.203841\n0.0\n0.0\n\n\nS100a6\n1.198049e-01\n4\nS100a6\n544.733658\n7.120948e+00\n-4911.277757\n0.024394\n4.364682e-02\nSE\n5749\n1.525869e-05\n1.234171e-03\n0.005581\n9857.182640\n-5087.893957\n176.616199\n0.0\n0.0\n\n\nCers2\n6.170160e-02\n4\nCers2\n544.733658\n1.473933e+01\n-4909.254062\n1.688963\n3.873848e-02\nSE\n5749\n6.963833e-06\n1.699495e-03\n0.002615\n9853.135249\n-5025.230150\n115.976088\n0.0\n0.0\n\n\nCar14\n6.721518e-02\n4\nCar14\n544.733658\n1.345078e+01\n-4078.211327\n1.646634\n3.422252e-02\nSE\n5749\n5.827188e-06\n1.224504e-03\n0.002738\n8191.049780\n-4232.446324\n154.234997\n0.0\n0.0\n\n\nHmgcs2\n1.043706e-01\n4\nHmgcs2\n544.733658\n8.317319e+00\n64.273783\n-0.697246\n9.799863e-03\nSE\n5749\n1.273224e-05\n1.280151e-03\n0.002757\n-93.920441\n-106.666922\n170.940704\n0.0\n0.0\n\n\nAtp1a1\n1.951715e-01\n4\nAtp1a1\n544.733658\n3.996873e+00\n-2655.884269\n-1.945325\n6.109633e-02\nSE\n5749\n1.387274e-05\n5.578607e-04\n0.002461\n5346.395662\n-3228.572142\n572.687873\n0.0\n0.0\n\n\nVangl1\n1.997762e-09\n4\nVangl1\n544.733658\n4.851652e+08\n523.655680\n-0.633082\n9.297993e-10\nSE\n5749\n5.712059e-09\n1.036289e+09\n0.011918\n-1012.684235\n435.773794\n87.881886\n0.0\n0.0\n\n\nTspan2\n2.008700e-01\n4\nTspan2\n544.733658\n3.855987e+00\n-4904.385928\n2.862779\n1.358988e-01\nSE\n5749\n1.765625e-05\n6.842354e-04\n0.002182\n9843.398981\n-5358.727526\n454.341598\n0.0\n0.0"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_ss",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_ss",
    "title": " Spatial Transcriptomics",
    "section": "4 Single cell data",
    "text": "4 Single cell data\nWe can use a scRNA-seq dataset as a reference to predict the proportion of different celltypes in the Visium spots. Keep in mind that it is important to have a reference that contains all the celltypes you expect to find in your spots. Ideally it should be a scRNA-seq reference from the exact same tissue. We will use a reference scRNA-seq dataset of ~14,000 adult mouse cortical cell taxonomy from the Allen Institute, generated with the SMART-Seq2 protocol.\nConveniently, you can also download the pre-processed dataset in h5ad format from here. Here with bash code:\n\nimport urllib.request\nimport os\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_file = \"data/spatial/visium/allen_cortex.h5ad\"\nif not os.path.exists(path_file):\n    file_url = os.path.join(\n        path_data, \"spatial/visium/allen_cortex.h5ad\")\n    urllib.request.urlretrieve(file_url, path_file)\n\n\nadata_cortex = sc.read_h5ad(\"data/spatial/visium/allen_cortex.h5ad\")\nadata_cortex\n\nAnnData object with n_obs × n_vars = 14249 × 34617\n    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sample_id', 'sample_type', 'organism', 'donor', 'sex', 'age_days', 'eye_condition', 'genotype', 'driver_lines', 'reporter_lines', 'brain_hemisphere', 'brain_region', 'brain_subregion', 'injection_label_direction', 'injection_primary', 'injection_secondary', 'injection_tract', 'injection_material', 'injection_exclusion_criterion', 'facs_date', 'facs_container', 'facs_sort_criteria', 'rna_amplification_set', 'library_prep_set', 'library_prep_avg_size_bp', 'seq_name', 'seq_tube', 'seq_batch', 'total_reads', 'percent_exon_reads', 'percent_intron_reads', 'percent_intergenic_reads', 'percent_rrna_reads', 'percent_mt_exon_reads', 'percent_reads_unique', 'percent_synth_reads', 'percent_ecoli_reads', 'percent_aligned_reads_total', 'complexity_cg', 'genes_detected_cpm_criterion', 'genes_detected_fpkm_criterion', 'tdt_cpm', 'gfp_cpm', 'class', 'subclass', 'cluster', 'confusion_score', 'cluster_correlation', 'core_intermediate_call'\n    var: 'features'\n\n\n\nadata_cortex.obs\n\n\n\n\n\n\n\n\norig.ident\nnCount_RNA\nnFeature_RNA\nsample_id\nsample_type\norganism\ndonor\nsex\nage_days\neye_condition\n...\ngenes_detected_cpm_criterion\ngenes_detected_fpkm_criterion\ntdt_cpm\ngfp_cpm\nclass\nsubclass\ncluster\nconfusion_score\ncluster_correlation\ncore_intermediate_call\n\n\n\n\nF1S4_160108_001_A01\n0\n1730700.0\n9029\n527128530\nCells\nMus musculus\n225675\nM\n53\nNormal\n...\n10445\n9222\n248.86\n248.86\nGABAergic\nVip\nVip Arhgap36 Hmcn1\n0.4385\n0.837229\nIntermediate\n\n\nF1S4_160108_001_B01\n0\n1909605.0\n10207\n527128536\nCells\nMus musculus\n225675\nM\n53\nNormal\n...\n11600\n10370\n289.61\n289.61\nGABAergic\nLamp5\nLamp5 Lsp1\n0.1025\n0.878743\nCore\n\n\nF1S4_160108_001_C01\n0\n1984948.0\n10578\n527128542\nCells\nMus musculus\n225675\nM\n53\nNormal\n...\n11848\n10734\n281.06\n281.06\nGABAergic\nLamp5\nLamp5 Lsp1\n0.0195\n0.887084\nCore\n\n\nF1S4_160108_001_D01\n0\n2291552.0\n8482\n527128548\nCells\nMus musculus\n225675\nM\n53\nNormal\n...\n9494\n8561\n390.02\n390.02\nGABAergic\nVip\nVip Crispld2 Htr2c\n0.2734\n0.843552\nCore\n\n\nF1S4_160108_001_E01\n0\n1757463.0\n8697\n527128554\nCells\nMus musculus\n225675\nM\n53\nNormal\n...\n10012\n8791\n253.92\n253.92\nGABAergic\nLamp5\nLamp5 Plch2 Dock5\n0.7532\n0.854994\nCore\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nFYS4_171004_104_C01\n2\n949356.0\n9141\n645142562\nCells\nMus musculus\n350650\nM\n51\nNormal\n...\n9629\n9229\n432.15\n432.15\nGlutamatergic\nL5 PT\nL5 PT VISp C1ql2 Cdh13\n0.0477\n0.885255\nCore\n\n\nFYS4_171004_104_D01\n2\n998736.0\n6927\n645142573\nCells\nMus musculus\n350650\nM\n51\nNormal\n...\n7701\n7023\n217.83\n217.83\nGABAergic\nSst\nSst Hpse Sema3c\n0.1064\n0.854499\nCore\n\n\nFYS4_171004_104_F01\n2\n1002766.0\n6936\n645142613\nCells\nMus musculus\n350650\nM\n51\nNormal\n...\n7888\n7054\n91.88\n91.88\nGlutamatergic\nL5 PT\nL5 PT VISp Chrna6\n0.0095\n0.822625\nCore\n\n\nFYS4_171004_104_G01\n2\n1025804.0\n8027\n645142648\nCells\nMus musculus\n350650\nM\n51\nNormal\n...\n8933\n8146\n127.77\n127.77\nGABAergic\nSst\nSst Calb2 Pdlim5\n0.2852\n0.856322\nCore\n\n\nFYS4_171004_104_H01\n2\n882435.0\n6574\n645142673\nCells\nMus musculus\n350650\nM\n51\nNormal\n...\n7393\n6687\n310.17\n310.17\nGABAergic\nPvalb\nPvalb Reln Tac1\n0.6089\n0.799198\nCore\n\n\n\n\n14249 rows × 52 columns\n\n\n\n\nsc.pp.normalize_total(adata_cortex, target_sum=1e5)\nsc.pp.log1p(adata_cortex)\nsc.pp.highly_variable_genes(adata_cortex, min_mean=0.0125, max_mean=3, min_disp=0.5)\nsc.pp.scale(adata_cortex, max_value=10)\nsc.tl.pca(adata_cortex, svd_solver='arpack')\nsc.pp.neighbors(adata_cortex, n_pcs=30)\nsc.tl.umap(adata_cortex)\nsc.pl.umap(adata_cortex, color=\"subclass\", legend_loc='on data')\n\nnormalizing counts per cell\n    finished (0:00:01)\nextracting highly variable genes\n    finished (0:00:06)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\ncomputing PCA\n    on highly variable genes\n    with n_comps=50\n    finished (0:00:10)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:11)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:12)\n\n\n\n\n\n\n\n\n\n\nadata_cortex.obs.subclass.value_counts()\n\nsubclass\nL6 IT         1872\nSst           1741\nVip           1728\nL4            1401\nPvalb         1337\nLamp5         1122\nL2/3 IT        982\nL6 CT          960\nL5 IT          880\nL5 PT          544\nAstro          368\nNP             362\nL6b            358\nSncg           125\nEndo            94\nOligo           91\nVLMC            67\nSMC             55\nMacrophage      51\nMeis2           45\nPeri            32\nSerpinf1        27\nCR               7\nName: count, dtype: int64\n\n\nFor speed, and for a more fair comparison of the celltypes, we will subsample all celltypes to a maximum of 200 cells per class (subclass).\n\ntarget_cells = 200\n\nadatas2 = [adata_cortex[adata_cortex.obs.subclass == clust] for clust in adata_cortex.obs.subclass.cat.categories]\n\nfor dat in adatas2:\n    if dat.n_obs &gt; target_cells:\n          sc.pp.subsample(dat, n_obs=target_cells)\n\nadata_cortex = adatas2[0].concatenate(*adatas2[1:])\n\nadata_cortex.obs.subclass.value_counts()\n\nsubclass\nAstro         200\nL6 IT         200\nSst           200\nPvalb         200\nNP            200\nLamp5         200\nL6b           200\nVip           200\nL6 CT         200\nL5 PT         200\nL5 IT         200\nL4            200\nL2/3 IT       200\nSncg          125\nEndo           94\nOligo          91\nVLMC           67\nSMC            55\nMacrophage     51\nMeis2          45\nPeri           32\nSerpinf1       27\nCR              7\nName: count, dtype: int64\n\n\n\nsc.pl.umap(\n    adata_cortex, color=[\"class\", \"subclass\", \"genotype\", \"brain_region\"], palette=sc.pl.palettes.default_28\n)\n\nWARNING: Length of palette colors is smaller than the number of categories (palette length: 28, categories length: 61. Some categories will have the same color.\n\n\n\n\n\n\n\n\n\n\nsc.pl.umap(adata_cortex, color=\"subclass\", legend_loc = 'on data')"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_sub",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_sub",
    "title": " Spatial Transcriptomics",
    "section": "5 Subset ST for cortex",
    "text": "5 Subset ST for cortex\nSince the scRNAseq dataset was generated from the mouse cortex, we will subset the visium dataset in order to select mainly the spots part of the cortex. Note that the integration can also be performed on the whole brain slice, but it would give rise to false positive cell type assignments and therefore it should be interpreted with more care.\nFor deconvolution we will need the counts data, so we will subset from the counts_adata object that we created earlier.\n\nlib_a = \"V1_Mouse_Brain_Sagittal_Anterior\"\n\ncounts_adata.obs['clusters'] = adata.obs.clusters\n\nadata_anterior_subset = counts_adata[\n    (counts_adata.obs.library_id == lib_a) \n    & (counts_adata.obsm[\"spatial\"][:, 1] &lt; 6000), :\n].copy()\n\n# select also the cortex clusters\nadata_anterior_subset = adata_anterior_subset[adata_anterior_subset.obs.clusters.isin(['3','4','6','7']),:]\n\n# plot to check that we have the correct regions\n\nsc.pl.spatial(\n    adata_anterior_subset,\n    img_key=\"hires\",\n    library_id = lib_a,\n    color=['clusters'],\n    size=1.5\n)"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-st_deconv",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-st_deconv",
    "title": " Spatial Transcriptomics",
    "section": "6 Deconvolution",
    "text": "6 Deconvolution\nDeconvolution is a method to estimate the abundance (or proportion) of different celltypes in a bulkRNAseq dataset using a single cell reference. As the Visium data can be seen as a small bulk, we can both use methods for traditional bulkRNAseq as well as methods especially developed for Visium data. Some methods for deconvolution are DWLS, cell2location, Tangram, Stereoscope, RCTD, SCDC and many more.\nHere, we will use deconvolution with Stereoscope implemented in the SCVI-tools package. To read more about Stereoscope please check out this github page (https://github.com/almaan/stereoscope)\n\n6.1 Select genes for deconvolution\nMost deconvolution methods does a prior gene selection and there are different options that are used: - Use variable genes in the SC data. - Use variable genes in both SC and ST data - DE genes between clusters in the SC data.\nIn this case we will use top DE genes per cluster, so first we have to run DGE detection on the scRNAseq data.\n\nsc.tl.rank_genes_groups(adata_cortex, 'subclass', method = \"t-test\", n_genes=100)\nsc.pl.rank_genes_groups_dotplot(adata_cortex, n_genes=3)\n\nranking genes\nWARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.\n    finished: added to `.uns['rank_genes_groups']`\n    'names', sorted np.recarray to be indexed by group ids\n    'scores', sorted np.recarray to be indexed by group ids\n    'logfoldchanges', sorted np.recarray to be indexed by group ids\n    'pvals', sorted np.recarray to be indexed by group ids\n    'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:03)\nWARNING: dendrogram data not found (using key=dendrogram_subclass). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 50\nStoring dendrogram info using `.uns['dendrogram_subclass']`\n\n\n\n\n\n\n\n\n\n\nsc.tl.filter_rank_genes_groups(adata_cortex, min_fold_change=1)\n\ngenes = sc.get.rank_genes_groups_df(adata_cortex, group = None)\ngenes\n\nFiltering genes using: min_in_group_fraction: 0.25 min_fold_change: 1, max_out_group_fraction: 0.5\n\n\n\n\n\n\n\n\n\ngroup\nnames\nscores\nlogfoldchanges\npvals\npvals_adj\n\n\n\n\n0\nAstro\n24438\n24.987505\nNaN\n3.887212e-64\n7.446797e-63\n\n\n1\nAstro\n25832\n23.915390\ninf\n1.620941e-60\n2.924028e-59\n\n\n2\nAstro\n18190\n21.893034\ninf\n5.711270e-55\n9.514294e-54\n\n\n3\nAstro\n25833\n21.557812\ninf\n5.534148e-54\n9.045118e-53\n\n\n4\nAstro\n2882\n20.950775\ninf\n2.972020e-53\n4.796383e-52\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2295\nVip\n24162\n10.645898\n193.386642\n2.184734e-21\n7.812906e-20\n\n\n2296\nVip\n31218\n10.593735\n262.868835\n2.901054e-21\n1.025800e-19\n\n\n2297\nVip\n18498\n10.579262\nNaN\n1.337080e-21\n4.856841e-20\n\n\n2298\nVip\n24420\n10.556447\nNaN\n3.184234e-21\n1.123635e-19\n\n\n2299\nVip\n29115\n10.549688\n322.383911\n5.200959e-21\n1.811284e-19\n\n\n\n\n2300 rows × 6 columns\n\n\n\n\ndeg = genes.names.unique().tolist()\nprint(len(deg))\n# check that the genes are also present in the ST data\n\ndeg = np.intersect1d(deg,adata_anterior_subset.var.index).tolist()\nprint(len(deg))\n\n1624\n0\n\n\nTrain the model\nFirst, train the model using scRNAseq data.\nStereoscope requires the data to be in counts, earlier in this tutorial we saved the spatial counts in a separate object counts_adata.\nHowever, the single cell dataset that we dowloaded only has the lognormalized data in the adata.X slot, hence we will have to recalculate the count matrix.\n\n# first do exponent and subtract pseudocount\nE = np.exp(adata_cortex.X)-1\nn = np.sum(E,1)\nprint(np.min(n), np.max(n))\n# all sums to 1.7M\nfactor = np.mean(n)\nnC = np.array(adata_cortex.obs.nCount_RNA) # true number of counts\nscaleF = nC/factor\nC = E * scaleF[:,None]\nC = C.astype(\"int\")\n\n151625.94316551366 10392533.010632813\n\n\n\nsc_adata = adata_cortex.copy()\nsc_adata.X = C\n\nSetup the anndata, the implementation requires the counts matrix to be in the “counts” layer as a copy.\n\n# this chunk has issues and therefore not evaluated\n\nimport scvi\n# from scvi.data import register_tensor_from_anndata\nfrom scvi.external import RNAStereoscope, SpatialStereoscope\n\n# add counts layer\nsc_adata.layers[\"counts\"] = sc_adata.X.copy()\n\n# subset for the selected genes\nsc_adata = sc_adata[:, deg].copy()\n\n# create stereoscope object\nRNAStereoscope.setup_anndata(sc_adata, layer=\"counts\", labels_key=\"subclass\")\n\n\n# this chunk has issues and therefore not evaluated\n\n# the model is saved to a file, so if is slow to run, you can simply reload it from disk by setting train = False\n\ntrain = True\nif train:\n    sc_model = RNAStereoscope(sc_adata)\n    sc_model.train(max_epochs=300)\n    sc_model.history[\"elbo_train\"][10:].plot()\n    sc_model.save(\"./data/spatial/visium/scmodel\", overwrite=True)\nelse:\n    sc_model = RNAStereoscope.load(\"./data/spatial/visium/scmodel\", sc_adata)\n    print(\"Loaded RNA model from file!\")\n\nPredict propritions on the spatial data\nFirst create a new st object with the correct genes and counts as a layer.\n\n# this chunk has issues and therefore not evaluated\n\nst_adata = adata_anterior_subset.copy()\n\nst_adata.layers[\"counts\"] = st_adata.X.copy()\nst_adata = st_adata[:, deg].copy()\n\nSpatialStereoscope.setup_anndata(st_adata, layer=\"counts\")\n\n\n# this chunk has issues and therefore not evaluated\n\ntrain=True\nif train:\n    spatial_model = SpatialStereoscope.from_rna_model(st_adata, sc_model)\n    spatial_model.train(max_epochs = 3000)\n    spatial_model.history[\"elbo_train\"][10:].plot()\n    spatial_model.save(\"./data/spatial/stmodel\", overwrite = True)\nelse:\n    spatial_model = SpatialStereoscope.load(\"./data/spatial/stmodel\", st_adata)\n    print(\"Loaded Spatial model from file!\")\n\nGet the results from the model, also put them in the .obs slot.\n\n# this chunk has issues and therefore not evaluated\n\nst_adata.obsm[\"deconvolution\"] = spatial_model.get_proportions()\n\n# also copy to the obsm data frame\nfor ct in st_adata.obsm[\"deconvolution\"].columns:\n    st_adata.obs[ct] = st_adata.obsm[\"deconvolution\"][ct]\n\nWe are then able to explore how cell types in the scRNA-seq dataset are predicted onto the visium dataset. Let’s first visualize the neurons cortical layers.\n\n# this chunk has issues and therefore not evaluated\n\nsc.pl.spatial(\n    st_adata,\n    img_key=\"hires\",\n    color=[\"L2/3 IT\", \"L4\", \"L5 PT\", \"L6 CT\"],\n    library_id=lib_a,\n    size=1.5,\n    ncols=2\n)\n\nWe can go ahead an visualize astrocytes and oligodendrocytes as well.\n\n# this chunk has issues and therefore not evaluated\n\nsc.pl.spatial(\n    st_adata, img_key=\"hires\", color=[\"Oligo\", \"Astro\"], size=1.5, library_id=lib_a\n)\n\nKeep in mind that the deconvolution results are just predictions, depending on how well your scRNAseq data covers the celltypes that are present in the ST data and on how parameters, gene selection etc. are tuned you may get different results.\n\n# this chunk has issues and therefore not evaluated\n\nsc.pl.violin(st_adata, [\"L2/3 IT\", \"L6 CT\",\"Oligo\",\"Astro\"],\n            jitter=0.4, groupby = 'clusters', rotation= 45)\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSubset for another region that does not contain cortex cells and check what you get from the label transfer. Suggested region is the right end of the posterial section that you can select like this:\n\n# this chunk has issues and therefore not evaluated\n\nlib_p = \"V1_Mouse_Brain_Sagittal_Posterior\"\n\nadata_subregion = adata[\n    (adata.obs.library_id == lib_p)\n    & (adata.obsm[\"spatial\"][:, 0] &gt; 6500),\n    :,\n].copy()\n\nsc.pl.spatial(\n    adata_subregion,\n    img_key=\"hires\",\n    library_id=lib_p,\n    color=['n_genes_by_counts'],\n    size=1.5\n)"
  },
  {
    "objectID": "labs/scanpy/scanpy_08_spatial.html#meta-session",
    "href": "labs/scanpy/scanpy_08_spatial.html#meta-session",
    "title": " Spatial Transcriptomics",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nannoy               NA\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfbpca               NA\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nintervaltree        NA\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscanorama           1.7.4\nscipy               1.11.4\nseaborn             0.12.2\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsortedcontainers    2.4.0\nsparse              0.14.0\nstack_data          0.6.2\nstatsmodels         0.14.1\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-16 23:30"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Warning\n\n\n\nCourse content is presently being updated. As a result, there’s a possibility that certain lab exercises might not function correctly. This alert will be taken down once the update process is complete."
  },
  {
    "objectID": "index.html#single-cell-rna-seq-analysis",
    "href": "index.html#single-cell-rna-seq-analysis",
    "title": "",
    "section": "Single Cell RNA-seq Analysis",
    "text": "Single Cell RNA-seq Analysis\n\n\nOverview of scRNAseq technologies\nQC, normalization and transformation\nDimensionality reduction and clustering\nDifferential gene expression\nCelltype prediction\nTrajectory analysis\nSeurat, Bioconductor and Scanpy toolkits\n\n\n\nUpdated: 17-01-2024 at 19:57:32."
  },
  {
    "objectID": "home_contents.html",
    "href": "home_contents.html",
    "title": "Contents",
    "section": "",
    "text": "You can run the labs either in a Singularity container on Uppmax (recommended during course) or using Docker locally on your system. Instructions on running the labs are provided here"
  },
  {
    "objectID": "home_contents.html#useful-resources",
    "href": "home_contents.html#useful-resources",
    "title": "Contents",
    "section": "Useful resources",
    "text": "Useful resources\n\nThe github repository for this course \nSingle Cell Glossary\nSingle cell RNA-seq course at from Hemberg lab \nSingle cell RNA-seq course in Python \nSingle cell RNA-seq course at Broad \nRepository listing many scRNA-seq tools \nSingleCellExperiment objects for many datasets \nConquer datasets - many different datasets based on a salmon pipeline \nThe Human Cell Atlas project \nBitbucket repository for QC report scripts \nBitbucket repository for the NBIS scRNAseq pipeline"
  },
  {
    "objectID": "home_info.html",
    "href": "home_info.html",
    "title": "Practical Info",
    "section": "",
    "text": "Uppsala\n\n\n\n\n\n\n\n\nRoom E10:1309 Entrance C11 Biomedicinskt centrum Uppsala University / ScilifeLab Husargatan 3 75237 Uppsala Sweden\nFew selected hotels are listed below ranked by distance from the venue.\n\nHotel von Kraemer (900 m, 11 min walk)\nAkademihotellet (1.7 Km, 21 min walk)\nCityStay Hotell (1.8 Km, 21 min walk)\nGrand Hotel Hörnan (1.9 Km, 23 min walk)\nHotell Centralstation (2.1 Km, 25 min walk)\nBest Western Svava (2.2 Km, 26 min walk)\n\nThe venue and hotels are also marked on the map.\nUse the UL website or the UL app for bus and train services around Uppsala. For buses from the Centralstation (Train/Bus), take Bus 4 (towards Gottsunda Centrum) or 8 (towards Sunnersta) and get off at the stop Uppsala Science Park. Bus tickets can be purchased in the app or directly from the driver using a credit card."
  },
  {
    "objectID": "home_info.html#location",
    "href": "home_info.html#location",
    "title": "Practical Info",
    "section": "",
    "text": "Uppsala\n\n\n\n\n\n\n\n\nRoom E10:1309 Entrance C11 Biomedicinskt centrum Uppsala University / ScilifeLab Husargatan 3 75237 Uppsala Sweden\nFew selected hotels are listed below ranked by distance from the venue.\n\nHotel von Kraemer (900 m, 11 min walk)\nAkademihotellet (1.7 Km, 21 min walk)\nCityStay Hotell (1.8 Km, 21 min walk)\nGrand Hotel Hörnan (1.9 Km, 23 min walk)\nHotell Centralstation (2.1 Km, 25 min walk)\nBest Western Svava (2.2 Km, 26 min walk)\n\nThe venue and hotels are also marked on the map.\nUse the UL website or the UL app for bus and train services around Uppsala. For buses from the Centralstation (Train/Bus), take Bus 4 (towards Gottsunda Centrum) or 8 (towards Sunnersta) and get off at the stop Uppsala Science Park. Bus tickets can be purchased in the app or directly from the driver using a credit card."
  },
  {
    "objectID": "home_info.html#contact",
    "href": "home_info.html#contact",
    "title": "Practical Info",
    "section": "Contact",
    "text": "Contact\nThis workshop is run by the National Bioinformatics Infrastructure Sweden (NBIS). NBIS is a platform at SciLifeLab.\nIf you would like to get in touch with us regarding this workshop, please contact us at edu.sc [at] nbis.se."
  },
  {
    "objectID": "home_precourse.html",
    "href": "home_precourse.html",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_precourse.html#fa-book-coding",
    "href": "home_precourse.html#fa-book-coding",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_precourse.html#fa-brands-slack-slack",
    "href": "home_precourse.html#fa-brands-slack-slack",
    "title": "Precourse",
    "section": " Slack",
    "text": "Slack\nWe will use Slack for communication, troubleshooting and group discussions. Please install Slack. All accepted students will receive an invitation link via email to join the course workspace. Please add this workspace to your Slack application on your desktop rather than using it in the browser.\nOnce you are in the workspace, please join the following channels:\n\n#software-to-install for questions about installation and troubleshooting\n#general for general questions about the workshop\n\n\n\n\n\n\n\nNote\n\n\n\nPlease post your question in the channel and NOT directly to the teacher. Any participant that knows the answer to any problem is encouraged to help too."
  },
  {
    "objectID": "home_precourse.html#fa-server-uppmax",
    "href": "home_precourse.html#fa-server-uppmax",
    "title": "Precourse",
    "section": " Uppmax",
    "text": "Uppmax\nWe will use the high performance computing cluster (HPC) UPPMAX for the workshop. You will need to create accounts if you don’t already have one. And you will need to join the course projects. See instructions here."
  },
  {
    "objectID": "home_precourse.html#fa-brands-docker-docker",
    "href": "home_precourse.html#fa-brands-docker-docker",
    "title": "Precourse",
    "section": " Docker",
    "text": "Docker\nIf you use Uppmax, you do not need any local installation or setup on your system. If you use Docker, you will need to set up and run Docker yourself. Instructions are here."
  },
  {
    "objectID": "home_precourse.html#fa-circle-question-faq",
    "href": "home_precourse.html#fa-circle-question-faq",
    "title": "Precourse",
    "section": " FAQ",
    "text": "FAQ\nPlease refer to the FAQ for troubleshooting common issues."
  },
  {
    "objectID": "home_schedule.html",
    "href": "home_schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Note\n\n\n\nSchedule is preliminary and may be subject to change.\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n\n12-Feb-2024MonUppsala\n\n\n09:00 - 09:30\nWelcome and General introduction \nÅsa Björklund\nRFRoy Francis\n\n\n09:30 - 10:30\nLecture: scRNAseq methods and ESCG platform \nHenrik Gezelius\n\n\n\n10:30 - 11:00\nBreak\n\n\n\n\n11:00 - 12:00\nLecture: Quality control \nÅsa Björklund\n\n\n\n11:45 - 13:00\nLunch\n\n\n\n\n13:00 - 13:30\nIntro to Exercises \nÅsa Björklund\nRFRoy Francis,YLYuan Li\n\n\n13:30 - 15:00\nLab: Quality control \nÅsa Björklund\nRFRoy Francis,YLYuan Li\n\n\n15:00 - 15:30\nBreak\n\n\n\n\n15:30 - 16:30\nLecture: Data normalization \nÅsa Björklund\n\n\n\n16:30 - 17:00\nWrap Up\nÅsa Björklund\n\n\n\n13-Feb-2024TueUppsala\n\n\n09:00 - 10:00\nLecture: Dimensionality reduction \nNikolay Oskolkov\n\n\n\n10:00 - 10:30\nBreak\n\n\n\n\n10:30 - 12:00\nLab: Dimensionality reduction \nNikolay Oskolkov\nABÅsa Björklund,RFRoy Francis,YLYuan Li\n\n\n11:45 - 13:00\nLunch\n\n\n\n\n13:00 - 14:00\nLecture: Batch correction + Integration \nNikolay Oskolkov\n\n\n\n14:00 - 15:00\nLab: Data integration \nNikolay Oskolkov\nABÅsa Björklund,RFRoy Francis,YLYuan Li\n\n\n15:00 - 15:30\nBreak\n\n\n\n\n15:30 - 16:30\nLecture: Clustering \nÅsa Björklund\n\n\n\n16:30 - 17:00\nWrap Up\nÅsa Björklund\n\n\n\n18:00 - 21:00\nCourse Dinner\n\n\n\n\n14-Feb-2024WedUppsala\n\n\n09:00 - 10:00\nLab: Clustering \nÅsa Björklund\nRFRoy Francis,YLYuan Li\n\n\n10:00 - 10:30\nBreak\n\n\n\n\n10:30 - 12:00\nLecture: Single Cell Epigenetics \nJakub Westholm\n\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 14:00\nLecture: Differential Gene Expression \nRoy Francis\n\n\n\n14:00 - 14:30\nLecture: Gene set analysis \nRoy Francis\n\n\n\n14:30 - 15:00\nBreak\n\n\n\n\n15:00 - 16:30\nLab: Differential expression \nRoy Francis\nABÅsa Björklund,YLYuan Li\n\n\n16:30 - 17:00\nWrap Up\nÅsa Björklund\n\n\n\n15-Feb-2024ThuUppsala\n\n\n09:00 - 10:00\nLecture: Celltype prediction \nUnassigned\n\n\n\n10:00 - 10:30\nBreak\n\n\n\n\n10:30 - 12:00\nLab: Celltype prediction \nUnassigned\nABÅsa Björklund,RFRoy Francis,YLYuan Li\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 14:00\nLecture: Trajectory inference \nUnassigned\n\n\n\n14:00 - 15:00\nLab: Trajectory inference \nUnassigned\nABÅsa Björklund,RFRoy Francis,YLYuan Li\n\n\n15:00 - 15:30\nBreak\n\n\n\n\n16:30 - 17:00\nWrap Up\nÅsa Björklund\n\n\n\n16-Feb-2024FriUppsala\n\n\n09:00 - 09:30\nIntro to BYOD\nÅsa Björklund\nRFRoy Francis\n\n\n09:30 - 12:00\nBYOD\nÅsa Björklund\nRFRoy Francis,YLYuan Li\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 14:00\nWrap Up \nÅsa Björklund\n\n\n\n\n\n\n\n\n   Date    Venue    Slides    Lab    Form    Video"
  },
  {
    "objectID": "home_syllabus.html",
    "href": "home_syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "SyllabusWho can apply?Entry requirements\n\n\nThis workshop will cover the basic steps in single cell RNAseq (scRNAseq) processing and data analysis, with lectures and practical exercises.\nTopics covered will include:\n\nOverview of the current scRNAseq technologies\nRaw reads into expression values\nQuality control of scRNAseq data\nDimensionality reduction and clustering techniques\nData normalization\nDifferential gene expression for scRNAseq data\nCelltype prediction\nTrajectory analysis\nComparison of sc analysis toolkits: Seurat, Bioconductor and Scanpy\n\n\n\nThis is a national workshop open for PhD students, postdocs, group leaders and core facility staff within all Swedish universities. We do accept application from other countries, but priority is given to applicants from Swedish universities prior to applicants from industry and academics from other countries.\nPlease note that NBIS training events do not provide any formal university credits. The training content is estimated to correspond to a certain number of credits, however the estimated credits are just guidelines. If formal credits are crucial, the student needs to confer with the home department before submitting a workshop application in order to establish whether the workshop is valid for formal credits or not.\nWe cannot invoice private individuals, therefore an affiliation is required.\n\n\nPractical exercises can be performed using R or Python, so we only accept students with previous experience in one of those programming languages.\n\nBasic knowledge in R/Python and command line (bash).\nBe able to use your own computer with R or Python installed for the practical computational exercises. Instructions on installation will be sent by email to accepted participants.\nProgramming/scripting experience is required (in R or python).\nBasic understanding of NGS technologies and RNA-sequencing data.\nDesirable: Previous experience with RNA-seq analysis and/or participation in NGS/RNA-seq workshop is an advantage.\n\nDue to limited space the workshop can accommodate maximum of 25 participants. If we receive more applications, participants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the workshop as well as gender and geographical balance."
  },
  {
    "objectID": "other/uppmax.html",
    "href": "other/uppmax.html",
    "title": "UPPMAX Account Guide",
    "section": "",
    "text": "Caution\n\n\n\nDo these steps well in advance as it can take up to 2 weeks for UPPMAX accounts to be approved. If this is incomplete, you may not be able to follow the labs during the workshop.\nThese are the basic steps in this process:"
  },
  {
    "objectID": "other/uppmax.html#create-an-account-in-supr.",
    "href": "other/uppmax.html#create-an-account-in-supr.",
    "title": "UPPMAX Account Guide",
    "section": "1 ​Create an account in SUPR.",
    "text": "1 ​Create an account in SUPR.\n​If you already have a SUPR account, please continue to the next step.\n​Go to​ https://supr.naiss.se/​ and click Register New Person at the bottom of the first page. Complete the registration process, preferably using SWAMID, and login. If you for some reason can’t use SWAMID to login, you will have to send physical (not electronic) copy of your ID to a place in Gothenburg for manual approval. Do this as ​soon as possible​, as this process can take ​more than 2 weeks.\n\n\n\nSUPR login screen"
  },
  {
    "objectID": "other/uppmax.html#apply-for-membership",
    "href": "other/uppmax.html#apply-for-membership",
    "title": "UPPMAX Account Guide",
    "section": "2 ​Apply for membership",
    "text": "2 ​Apply for membership\n​Log in using your SUPR account. ​Under the Projects heading, go to Request Membership in Project. ​Search for the following project IDs:\n\n\nnaiss2023-22-1345, naiss2023-23-648\n\n\nRequest membership to both projects. The first project is to run computations and the second project is for storage.\n\n\n\nRequest to join a project in SUPR"
  },
  {
    "objectID": "other/uppmax.html#accept-naiss-user-agreement",
    "href": "other/uppmax.html#accept-naiss-user-agreement",
    "title": "UPPMAX Account Guide",
    "section": "3 ​Accept NAISS User Agreement",
    "text": "3 ​Accept NAISS User Agreement\n​In SUPR, click on the link Personal Information in the left sidebar. You will have to accept the NAISS User Agreement to be able to get an UPPMAX account."
  },
  {
    "objectID": "other/uppmax.html#apply-for-uppmax-account",
    "href": "other/uppmax.html#apply-for-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "4 Apply for UPPMAX account",
    "text": "4 Apply for UPPMAX account\n​In SUPR, click on the link Accounts in the left sidebar and apply for an UPPMAX account under the heading Account Requests."
  },
  {
    "objectID": "other/uppmax.html#uppmax-account-details",
    "href": "other/uppmax.html#uppmax-account-details",
    "title": "UPPMAX Account Guide",
    "section": "5 UPPMAX account details",
    "text": "5 UPPMAX account details\n​Within about 2 working days you should get an email with instructions. ​Please, follow these instructions carefully. ​A while later you will get an email with your user name, and another email with a link to your password.\n\n\n\n\n\n\nCaution\n\n\n\nThe link is only valid for ​1​ visit or 7 days​, so if you click the link you better save the password, because you will not be able to use the link again. Do this before 7 days have passed, otherwise the link will no longer be valid."
  },
  {
    "objectID": "other/uppmax.html#login-with-new-uppmax-account",
    "href": "other/uppmax.html#login-with-new-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "6 Login with new UPPMAX account",
    "text": "6 Login with new UPPMAX account\n​Open your terminal program (Terminal in OSX and Linux, otherwise download MobaXterm​ (portable edition) if you have Windows).\n​Type this command in your terminal program: ssh username@rackham.uppmax.uu.se ​You will be asked for your password now, and you will not see any response in the terminal while typing your password. This is to hide the length of your password, i.e. normal. Just press enter when you have typed it in and you should log in.\n​If it is the first time you log in, it will ask you to change your LDAP password (the password you just typed). It will directly ask you for your password again, so type it once more. After that it will ask you for your new password, so make up a new one and press enter. After that it will ask you to confirm the new password. When the password change is completed you will be disconnected and you will have to connect again, using your new password to log in this time."
  },
  {
    "objectID": "other/uppmax.html#create-a-new-file",
    "href": "other/uppmax.html#create-a-new-file",
    "title": "UPPMAX Account Guide",
    "section": "7 ​Create a new file",
    "text": "7 ​Create a new file\n​After having received information that your membership is approved, ​wait 24 h before continuing, as it takes up to 24 h for SUPR to sync with UPPMAX. Else, you will get the message Permission denied if you try to create the file before this sync has been performed.\n\n\n\n\nbash\n\ntouch /proj/​naiss2023-23-648/completed/username\n\n\n\n​Unless you got some kind of error message you should now be finished. To make sure the file was created you can type\n\n\n\n\nbash\n\nls /proj/​naiss2023-23-648/nobackup/username\n\n\n\n​It should write out the name of the file if the file exists. ​If you get an error message, please contact us. Email is on the Info page."
  },
  {
    "objectID": "other/docker.html",
    "href": "other/docker.html",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Mac M1/M2/M3, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#install-docker",
    "href": "other/docker.html#install-docker",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Mac M1/M2/M3, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#test-installation",
    "href": "other/docker.html#test-installation",
    "title": "Docker Set Up",
    "section": "2 Test installation",
    "text": "2 Test installation\nFrom the terminal, type:\ndocker --version\nand then run your first image by typing:\ndocker run hello-world\nIf both work as expected, you successfully installed Docker Desktop!"
  },
  {
    "objectID": "other/docker.html#allocate-resources",
    "href": "other/docker.html#allocate-resources",
    "title": "Docker Set Up",
    "section": "3 Allocate resources",
    "text": "3 Allocate resources\nOpen the Docker Dashboard when Docker Desktop starts and go to Settings ( in the top-right) &gt; Resources to allocate the following resources:\n\nCPU limit: 8\n\nMemory limit: 12 GB\n\nSwap: 2 GB\n\nOn Windows, if WSL engine is used, you might not be able to change resources directly."
  },
  {
    "objectID": "other/containers.html",
    "href": "other/containers.html",
    "title": "Run labs in container",
    "section": "",
    "text": "Note\n\n\n\nThree different toolkits, namely Seurat (R/RStudio), Bioconductor (R/RStudio) and Scanpy (Python/Jupyter) are available to perform the scRNAseq analysis. The labs can be run on Uppmax using Singularity (Apptainer) or on your local machine using Docker. Both options provide the necessary environment to run the analysis.\nIf you use Uppmax, you do not need any local installation or setup on your system but you need an Uppmax account and become a member of the Uppmax projects. If you use Docker, you will need to set up and run Docker yourself."
  },
  {
    "objectID": "other/containers.html#option-a-run-singularity-on-uppmax-recommended",
    "href": "other/containers.html#option-a-run-singularity-on-uppmax-recommended",
    "title": "Run labs in container",
    "section": "1 Option A: Run Singularity on Uppmax (Recommended)",
    "text": "1 Option A: Run Singularity on Uppmax (Recommended)\n\n1.1 Configure Uppmax\n\n1.1.1 Storage\nThis setup needs to be run only once at the beginning of the workshop. It will connect you to Uppmax and create a folder with your username in the workshop’s directory.\nFirst connect to Uppmax:\nssh -Y &lt;username&gt;@rackham.uppmax.uu.se\nOnce you are connected, run the following commands:\n\n\n# change to project directory\ncd /proj/naiss2023-23-648/nobackup\n\n# create a directory with your username and move inside\nmkdir $(id -un) && cd $_\n\n\nNow you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs directory to work on labs.\ngit clone --depth 1 --single-branch --branch master https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\n\n\n1.1.2 Compute\nTo run the labs you need to first create an interactive session.\nConnect to Uppmax and change into your working directory (if not already done):\n\n\nssh -Y &lt;username&gt;@rackham.uppmax.uu.se\ncd /proj/naiss2023-23-648/nobackup/&lt;username&gt;/workshop-scRNAseq/compiled/labs\n\n\nThen start an interactive session:\n\n\ninteractive -A naiss2023-22-1345 -p core -n 4 -t 08:00:00\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRun the interactive command above only ONCE per day at the beginning of the practical session.\n\n\nThis command will connect you to a node with 5 cores for a duration of 8 hours. You can check the node name under the NODELIST column in the output of the following command:\nsqueue -u &lt;username&gt;\nIf you are disconnected from the interactive session, you can re-connect to your node with the following command:\nssh -Y &lt;nodename&gt;\nIf you get disconnected from Uppmax, reconnect to Uppmax as shown in the very first step, then check your job is running using squeue and login to the compute node as shown in the above step.\n\n\n\n1.2 Launch RStudio\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\n\n1.2.1 Seurat\nTo launch RStudio server and run the Seurat labs perform the following steps:\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\n/sw/courses/scrnaseq/singularity/launch_rstudio.sh /sw/courses/scrnaseq/singularity/2024-seurat-r4.3.0.sif\n\n\n1.2.2 Bioconductor\nTo launch RStudio server and run the Bioconductor labs perform the following steps:\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\n/sw/courses/scrnaseq/singularity/launch_rstudio.sh /sw/courses/scrnaseq/singularity/2024-bioconductor-r4.3.0.sif\n\n\n\n1.3 Connect to RStudio\nAfter executing the launch_rstudio.sh script, a message with your login credentials will be printed to your screen, and it looks similar to the one below.\n\n\n\n\n\n\nImportant\n\n\n\nDo not close this terminal!\n\n\n        *************************************************\n        *                                               *\n        *  IMPORTANT: Do not close or exit this shell!  *\n        *                                               *\n        *************************************************\n\n1. SSH tunnel from your workstation using the following command:\n\n   ssh -N -L 8787:r483.uppmax.uu.se:58359 susanner@rackham3.uppmax.uu.se\n\n   and point your web browser to http://localhost:8787\n\n2. log in to RStudio Server using the following credentials:\n\n   user: susanner\n   password: scrnaseq\n\nWhen done using RStudio Server, terminate the job by:\n\n1. Exit the RStudio Session (\"power\" button in the top right corner of the RStudio window).\n2. Issue the following command in both shells:\n\n      CTRL-C\nFollow the instructions printed on the screen to launch the RStudio Server. Open a shell locally and run your ssh command from step 1. Then open localhost:8787 in your web browser and log in to the RStudio Server using your username and password provided in step 2.\nIn RStudio, make sure you are in the correct working directory else set it.\n\n\ngetwd()\nsetwd('/crex/proj/naiss2023-23-648/nobackup/&lt;username&gt;/workshop-scRNAseq/compiled/labs/&lt;topic&gt;')\n\n\n\n\n1.4 Launch JupyterLab\n\n1.4.1 Scanpy\nTo launch JupyterLab and run the Scanpy labs using Jupyter notebooks perform the following steps:\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\n/sw/courses/scrnaseq/singularity/launch_jupyter.sh /sw/courses/scrnaseq/singularity/2024-scanpy-py3.10.sif\n\n\n\n1.5 Connect to JupyterLab\nAfter executing the launch_jupyter.sh script, a message with your login credentials will be printed to your screen, and it looks similar to the one below.\n\n\n\n\n\n\nImportant\n\n\n\nDo not close this terminal!\n\n\n        *************************************************\n        *                                               *\n        *  IMPORTANT: Do not close or exit this shell!  *\n        *                                               *\n        *************************************************\n\n1. SSH tunnel from your workstation using the following command:\n\n   ssh -N -L 8888:r483.uppmax.uu.se:34968 susanner@rackham1.uppmax.uu.se\n\n   point your web browser to http://localhost:8888/lab\n\n2. Log in to JupyterLab using the password:\n\n   scrnaseq\n\nWhen done using JupyterLab, terminate the job by:\n\n1. Shut down all kernels.\n2. Issue the following command in both shells:\n\n   CTRL-C\nFollow the instructions to launch the JupyterLab. Open a shell locally and run your ssh command from step 1. Then open localhost:8888/lab in your web browser and log in to the JupyterLab using the password provided in step 2."
  },
  {
    "objectID": "other/containers.html#option-b-run-docker-locally",
    "href": "other/containers.html#option-b-run-docker-locally",
    "title": "Run labs in container",
    "section": "2 Option B: Run Docker Locally",
    "text": "2 Option B: Run Docker Locally\n\n2.1 Local Setup\nCreate a new directory at a suitable location. Now you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs to work on labs.\ngit clone --depth 1 --single-branch --branch master https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\nIf the git command is not available, you can simply go to https://github.com/NBISweden/workshop-scRNAseq and download the repo as a zip file and unzip it in a suitable location."
  },
  {
    "objectID": "other/containers.html#images",
    "href": "other/containers.html#images",
    "title": "Run labs in container",
    "section": "3 Images",
    "text": "3 Images\nSeparate Docker images are made available for Seurat, Bioconductor and Scanpy toolkits. An additional set of images are available for spatial analyses. All images follow the registry/username/image:tag convention. The image is always ghcr.io/nbisweden/workshop-scrnaseq. Add the appropriate tag based on the lab you are running.\nAn overview of the available docker images:\n\n\n\nTopic\nImage\n\n\n\n\nSeurat\n2024-seurat-r4.3.0\n\n\nSeurat spatial\n2024-seurat_spatial-r4.3.0\n\n\nBioconductor\n2024-bioconductor-r4.3.0\n\n\nBioconductor spatial\n2024-bioconductor_spatial-r4.3.0\n\n\nScanpy\n2024-scanpy-py3.10\n\n\nScanpy spatial\n2024-scanpy_spatial-py3.10\n\n\n\n\n3.1 Seurat\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat-r4.3.0\ndocker run --rm -ti -p 8787:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat-r4.3.0\nIn the browser, go to localhost:8787.\nUse the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\nRStudio login screen\n\n\n\n\n\nRStudio preview\n\n\n\n\n\n\n3.2 Bioconductor\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor-r4.3.0\ndocker run --rm -ti -p 8787:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor-r4.3.0\nIn the browser, go to localhost:8787. Use the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\n\nImportant\n\n\n\nDo not close this terminal.\n\n\n\n\n3.3 Scanpy\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy-py3.10\ndocker run --rm -ti -p 8888:8888 -v ${PWD}:/home/jovyan/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy-py3.10\nAt the end of the prompt, you will see a URL that starts with http://127.0.0.1, similar to the one below:\nhttp://127.0.0.1:8888/lab?token=0a1d9ec51b91528a1d1fe2ad2c74f59ecb94c47070c2911d\nNote that your token value will be different. Copy the entire URL (with the token) and paste it in your browser.\n\n\n\n\n\n\nImportant\n\n\n\nDo not close this terminal.\n\n\n\n\n\n\n\nJupyter home\n\n\n\n\n\nJupyter preview"
  },
  {
    "objectID": "other/faq.html",
    "href": "other/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#command-line-developer-tools-not-found",
    "href": "other/faq.html#command-line-developer-tools-not-found",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "href": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "title": "FAQ",
    "section": "2 Error: umap-learn not found, or other python packages",
    "text": "2 Error: umap-learn not found, or other python packages\n\nIf your R does not find the correct python version, it will complain that umap-learn is not installed and ask you to install it. Here are some tips on how to find the correct python version that was installed in the conda environment.\nTry selecting the correct conda env in R. In this example the conda environment is named myenv.\nlibrary(reticulate)\nreticulate::use_conda(\"myenv\")\nThen check what python you have in R:\nreticulate::py_config()\n# should read at top:\npython:         /Users/asbj/miniconda3/envs/myenv/bin/python\nIf that still is not right, you may have an r-reticulate python installation as well and need to perform the steps below.\n\nRestart R and select python version\nFirst, find out what path you have to your conda python (in TERMINAL):\n\nwhich python\n/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\n\nThen in R (after restarting):\n\nreticulate::use_python(\"/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\", required=T)\n\nThen check again with py_config if correct version of python is used:\n\nreticulate::py_config()\n\nIf you have the correct version now, you should be able to run UMAP without issues."
  },
  {
    "objectID": "other/faq.html#unable-to-load-stringi.so",
    "href": "other/faq.html#unable-to-load-stringi.so",
    "title": "FAQ",
    "section": "3 Unable to load stringi.so",
    "text": "3 Unable to load stringi.so\n \nYou can install stringi in R using:\ninstall.packages('stringi')"
  },
  {
    "objectID": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "href": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "title": "FAQ",
    "section": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing",
    "text": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing\n\nThis is a problem with the MacOSX compiler, in which conda is unable to find it.\n#Download MacOSX10.9.sdk from Github\ncurl -o MacOSX10.9.sdk.tar.gz \"https://github.com/phracker/MacOSX-SDKs/releases/download/11.3/MacOSX10.9.sdk.tar.xz\"\n\n#extract\nsudo tar -xzf MacOSX10.9.sdk.tar.xz\n\n#copy\nsudo cp -r MacOSX10.9.sdk /opt/\n\n#give executable permissions\nsudo chmod -R a+rX /opt\n\n#Link the path where conda looks to where the file is\nln -s /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk /opt/MacOSX10.9.sdk"
  },
  {
    "objectID": "other/faq.html#error-option-error-has-null-value",
    "href": "other/faq.html#error-option-error-has-null-value",
    "title": "FAQ",
    "section": "5 ERROR: option error has NULL value",
    "text": "5 ERROR: option error has NULL value\n\nThis error happens when running code inline. One possible solution is to restart Rstudio and type.\nif(interactive()) { options(error = utils::recover)}\nPlease try other solutions listed here. If none of those work, you can click on the wheel engine symbol and check Chunk output in console."
  },
  {
    "objectID": "other/faq.html#r-crashes-due-to-memory-issues",
    "href": "other/faq.html#r-crashes-due-to-memory-issues",
    "title": "FAQ",
    "section": "6 R crashes due to memory issues",
    "text": "6 R crashes due to memory issues\n\nIf R crashes due to memory issues, it may be a good idea to increase the vector size R_MAX_VSIZE. Put in the file .Renviron either in your home directory or the folder you are launching Rstudio from:\nR_MAX_VSIZE=70Gb\nOr to whatever value matches your computer, the default size is 16Gb."
  },
  {
    "objectID": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "href": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "title": "FAQ",
    "section": "7 Docker run fails on Mac apple silicon",
    "text": "7 Docker run fails on Mac apple silicon\nDocker run on Apple Mac M1/M2/M3 processors experience this error when running docker run ... on an image not built on Apple silicon.\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] 01_set_env: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] 01_set_env: exited 0.\n[cont-init.d] 02_userconf: executing...\n[cont-init.d] 02_userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nTTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\nrserver[1195]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\n\n2023-11-28T14:31:03.943703Z [rserver] ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\nrserver[1199]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: rstudio::core::Error rstudio::core::system::launchChildProcess(std::string, std::string, rstudio::core::system::ProcessConfig, rstudio::core::system::ProcessConfigFilter, PidType*) src/cpp/core/system/PosixSystem.cpp:2195\nIn Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon."
  }
]