



```{r}
#| eval: false

# SEURAT
VlnPlot(obj, features = "nUMI", group.by = "batches")

# BIOCONDUCTOR
# plotColData(sce,y = "nUMI",x = "batches",colour_by = "batches")
```

Since we are not interested in the effects of the batches in this example, but only the differentiation paths for each cell type. We can use the integrated space of harmony embedding (where we removed batch effects). Since the harmony (same applies to MNN, SCANORAMA, LIGER ) is a corrected version of PCA, we can multiply the harmony embedding with PCA loadings to generate batch-corrected "pseudo counts". Note that we can only reconstruct data from the highly variable genes that were used to compute PCA and HARMONY.

```{r}
#| eval: false

# Get the gene means and standard deviation
library(sparseMatrixStats)
genes <- rownames(PCA_loadings)
gene_means <- rowMeans2(filt_NORM_COUNTS[genes, ])
gene_sd <- sqrt(rowVars(filt_NORM_COUNTS[genes, ]))

# Project normalized gene counts
CORRECTED_NORMCOUNTS <- t(filt_HARMONY %*% t(PCA_loadings)) * gene_sd + gene_means - 0.02
CORRECTED_NORMCOUNTS <- Matrix(round(CORRECTED_NORMCOUNTS, 3), sparse = T)
CORRECTED_NORMCOUNTS@x[CORRECTED_NORMCOUNTS@x < 0] <- 0
CORRECTED_NORMCOUNTS <- drop0(CORRECTED_NORMCOUNTS)

# Transform the normalized data back to raw counts (used for differential expression)
CORRECTED_COUNTS <- round((expm1(CORRECTED_NORMCOUNTS)) * 1000)
```

Let's compare how the normalized data compares to the batch-corrected one.

```{r}
#| eval: false

par(mfrow = c(3, 3))
{
  plot(obj@reductions$umap@cell.embeddings, type = "n")
  draw_graph(layout = obj@reductions$umap@cell.embeddings, graph = filt_KNN)
  points(obj@reductions$umap@cell.embeddings, col = pal[filt_clustering], pch = 16)
  text(centroids2d[, 1], centroids2d[, 2],
    labels = rownames(centroids2d), cex = 0.8, font = 2
  )
}

vars <- c("Cd34", "Ms4a1", "Cd3e", "Ltf", "Cst3", "Mcpt8", "Alas2", "Siglech")
for (i in vars) {
  plot(filt_NORM_COUNTS[i, ], CORRECTED_NORMCOUNTS[i, ], main = i, pch = 16, cex = 0.4)
  rr <- c(diff(range(filt_NORM_COUNTS[i, ])) / 50, (range(CORRECTED_NORMCOUNTS[i, ])))
  polygon(c(-rr[1], -rr[1], rr[1], rr[1]), c(rr[3], rr[2], rr[2], rr[3]), border = "red")
  text(rr[1], max(CORRECTED_NORMCOUNTS[i, ]), " < Imputed\n    counts", adj = c(0, 1), col = "red", font = 2)
}
```

:::{.callout-caution}
Please note in the graphs above that there is a significant amount of imputation (i.e., we artificially add counts to certain cells where we'd expect to see). Please keep this in mind and use these matrices with caution in downstream analysis!
:::

Let's also take a closer inspection on the UMAPs:

```{r}
#| eval: false

par(mfrow = c(4, 5), mar = c(.1, .1, 2, 1))

vars <- c("Cd34", "Ms4a1", "Cd3e", "Ltf", "Cst3", "Mcpt8", "Alas2", "Siglech", "C1qc")
for (j in c("filt_NORM_COUNTS", "CORRECTED_NORMCOUNTS")) {{
  plot(obj@reductions$umap@cell.embeddings, type = "n", axes = F, xlab = "", ylab = "", main = j)
  draw_graph(layout = obj@reductions$umap@cell.embeddings, graph = filt_KNN)
  points(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], pch = 16)
  text(centroids2d, labels = rownames(centroids2d), cex = 0.8, font = 2)
}

for (i in vars) {
  x <- get(j)[i, ]
  x <- x - min(x) / (max(x) - min(x))
  o <- order(x)
  plot(obj@reductions$umap@cell.embeddings[o, ],
    main = paste0(i), pch = 16, cex = 0.4, axes = F, xlab = "", ylab = "",
    col = colorRampPalette(c("lightgray", "blue"))(99)[x[o] * 98 + 1]
  )
}}
```
