{
  "hash": "adef6e7be96352c43d78fe6d1edd8211",
  "result": {
    "markdown": "---\ntitle: \"{{< meta qc_title >}}\"\nsubtitle: \"{{< meta subtitle_scanpy >}}\"\ndescription: \"{{< meta qc_description >}}\"\nformat: html\nengine: jupyter\n---\n\n::: {.callout-note}\nCode chunks run Python commands unless it starts with `%%bash`, in which case, those chunks run shell commands.\n:::\n\n## {{< meta qc_data >}}\n\n\n{{< meta qc_data_1 >}}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\n\npath_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n\npath_covid = \"./data/covid\"\nif not os.path.exists(path_covid):\n    os.makedirs(path_covid, exist_ok=True)\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport urllib.request\n\nfile_list = [\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n]\n\nfor i in file_list:\n    path_file = os.path.join(path_covid, i)\n    if not os.path.exists(path_file):\n        file_url = os.path.join(path_data, \"covid\", i)\n        urllib.request.urlretrieve(file_url, path_file)\n```\n:::\n\n\n{{< meta qc_data_2 >}}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80)\n```\n:::\n\n\n{{< meta qc_data_3 >}}\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndata_cov1 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_1.h5'))\ndata_cov1.var_names_make_unique()\ndata_cov15 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_15.h5'))\ndata_cov15.var_names_make_unique()\ndata_cov17 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_17.h5'))\ndata_cov17.var_names_make_unique()\ndata_ctrl5 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_5.h5'))\ndata_ctrl5.var_names_make_unique()\ndata_ctrl13 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_13.h5'))\ndata_ctrl13.var_names_make_unique()\ndata_ctrl14 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_14.h5'))\ndata_ctrl14.var_names_make_unique()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nreading ./data/covid/ncov_pbmc_1.h5\n (0:00:00)\nreading ./data/covid/ncov_pbmc_15.h5\n (0:00:00)\nreading ./data/covid/ncov_pbmc_17.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_5.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_13.h5\n (0:00:00)\nreading ./data/covid/normal_pbmc_14.h5\n (0:00:00)\n```\n:::\n:::\n\n\n## {{< meta qc_collate >}}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# add some metadata\ndata_cov1.obs['type']=\"Covid\"\ndata_cov1.obs['sample']=\"covid_1\"\ndata_cov15.obs['type']=\"Covid\"\ndata_cov15.obs['sample']=\"covid_15\"\ndata_cov17.obs['type']=\"Covid\"\ndata_cov17.obs['sample']=\"covid_17\"\ndata_ctrl5.obs['type']=\"Ctrl\"\ndata_ctrl5.obs['sample']=\"ctrl_5\"\ndata_ctrl13.obs['type']=\"Ctrl\"\ndata_ctrl13.obs['sample']=\"ctrl_13\"\ndata_ctrl14.obs['type']=\"Ctrl\"\ndata_ctrl14.obs['sample']=\"ctrl_14\"\n\n# merge into one object.\nadata = data_cov1.concatenate(data_cov15, data_cov17, data_ctrl5, data_ctrl13, data_ctrl14)\n\n# and delete individual datasets to save space\ndel(data_cov1, data_cov15, data_cov17)\ndel(data_ctrl5, data_ctrl13, data_ctrl14)\n```\n:::\n\n\nYou can print a summary of the datasets in the Scanpy object, or a summary of the whole object.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nprint(adata.obs['sample'].value_counts())\nadata\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsample\ncovid_1     1500\ncovid_15    1500\ncovid_17    1500\nctrl_5      1500\nctrl_13     1500\nctrl_14     1500\nName: count, dtype: int64\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nAnnData object with n_obs × n_vars = 9000 × 33538\n    obs: 'type', 'sample', 'batch'\n    var: 'gene_ids', 'feature_types', 'genome'\n```\n:::\n:::\n\n\n## {{< meta qc_calqc >}}\n\n\n{{< meta qc_calqc_1 >}}\n\n\n{{< meta qc_calqc_2 >}}\n\n\n\nFirst, let Scanpy calculate some general qc-stats for genes and cells with the function `sc.pp.calculate_qc_metrics`, similar to `calculateQCmetrics()` in Scater. It can also calculate proportion of counts for specific gene populations, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# mitochondrial genes\nadata.var['mt'] = adata.var_names.str.startswith('MT-') \n# ribosomal genes\nadata.var['ribo'] = adata.var_names.str.startswith((\"RPS\",\"RPL\"))\n# hemoglobin genes.\nadata.var['hb'] = adata.var_names.str.contains((\"^HB[^(P)]\"))\n\nadata.var\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gene_ids</th>\n      <th>feature_types</th>\n      <th>genome</th>\n      <th>mt</th>\n      <th>ribo</th>\n      <th>hb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MIR1302-2HG</th>\n      <td>ENSG00000243485</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>FAM138A</th>\n      <td>ENSG00000237613</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>OR4F5</th>\n      <td>ENSG00000186092</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>AL627309.1</th>\n      <td>ENSG00000238009</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>AL627309.3</th>\n      <td>ENSG00000239945</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>AC233755.2</th>\n      <td>ENSG00000277856</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>AC233755.1</th>\n      <td>ENSG00000275063</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>AC240274.1</th>\n      <td>ENSG00000271254</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>AC213203.1</th>\n      <td>ENSG00000277475</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>FAM231C</th>\n      <td>ENSG00000268674</td>\n      <td>Gene Expression</td>\n      <td>GRCh38</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>33538 rows × 6 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt','ribo','hb'], percent_top=None, log1p=False, inplace=True)\n```\n:::\n\n\n{{< meta qc_calqc_3 >}}\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nmito_genes = adata.var_names.str.startswith('MT-')\n# for each cell compute fraction of counts in mito genes vs. all genes\n# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\nadata.obs['percent_mt2'] = np.sum(\n    adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n# add the total counts per cell as observations-annotation to adata\nadata.obs['n_counts'] = adata.X.sum(axis=1).A1\n\nadata\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nAnnData object with n_obs × n_vars = 9000 × 33538\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n```\n:::\n:::\n\n\n## {{< meta qc_plotqc >}}\n\n\n{{< meta qc_plotqc_1 >}}\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation= 45)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-11-output-1.png){}\n:::\n:::\n\n\n{{< meta qc_plotqc_2 >}}\n\n::: {.cell fig-height='5' fig-width='5' execution_count=11}\n``` {.python .cell-code}\nsc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color=\"sample\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n:::{.callout-note title=\"Discuss\"}\n\n{{< meta qc_plotqc_3 >}}\n\n\n:::\n\n## {{< meta qc_filter >}}\n\n### {{< meta qc_filter_detect >}}\n\n\n{{< meta qc_filter_detect_1 >}}\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nsc.pp.filter_cells(adata, min_genes=200)\nsc.pp.filter_genes(adata, min_cells=3)\n\nprint(adata.n_obs, adata.n_vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfiltered out 897 cells that have less than 200 genes expressed\nfiltered out 14683 genes that are detected in less than 3 cells\n8103 18855\n```\n:::\n:::\n\n\n{{< meta qc_filter_detect_3 >}}\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# skip for now as we are doing doublet prediction\n#keep_v2 = (adata.obs['n_genes_by_counts'] < 2000) & (adata.obs['n_genes_by_counts'] > 500) & (adata.obs['lib_prep'] == 'v2')\n#print(sum(keep_v2))\n\n# filter for gene detection for v3\n#keep_v3 = (adata.obs['n_genes_by_counts'] < 4100) & (adata.obs['n_genes_by_counts'] > 1000) & (adata.obs['lib_prep'] != 'v2')\n#print(sum(keep_v3))\n\n# keep both sets of cells\n#keep = (keep_v2) | (keep_v3)\n#print(sum(keep))\n#adata = adata[keep, :]\n\n#print(\"Remaining cells %d\"%adata.n_obs)\n```\n:::\n\n\n{{< meta qc_filter_detect_4 >}}\n\n::: {.cell fig-height='6' fig-width='6' execution_count=14}\n``` {.python .cell-code}\nsc.pl.highest_expr_genes(adata, n_top=20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnormalizing counts per cell\n    finished (0:00:00)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-15-output-2.png){}\n:::\n:::\n\n\n{{< meta qc_filter_detect_5 >}}\n\n\n\n### {{< meta qc_filter_mr >}}\n\n\n{{< meta qc_filter_mr_1 >}}\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# filter for percent mito\nadata = adata[adata.obs['pct_counts_mt'] < 20, :]\n\n# filter for percent ribo > 0.05\nadata = adata[adata.obs['pct_counts_ribo'] > 5, :]\n\nprint(\"Remaining cells %d\"%adata.n_obs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemaining cells 5888\n```\n:::\n:::\n\n\n{{< meta qc_filter_mr_2 >}}\n\n\n\n### {{< meta qc_filter_plot >}}\n\n\n{{< meta qc_filter_plot_1 >}}\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation = 45)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-17-output-1.png){}\n:::\n:::\n\n\n### {{< meta qc_filter_genes >}}\n\n\n{{< meta qc_filter_genes_1 >}}\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nmalat1 = adata.var_names.str.startswith('MALAT1')\n# we need to redefine the mito_genes since they were first \n# calculated on the full object before removing low expressed genes.\nmito_genes = adata.var_names.str.startswith('MT-')\nhb_genes = adata.var_names.str.contains('^HB[^(P)]')\n\nremove = np.add(mito_genes, malat1)\nremove = np.add(remove, hb_genes)\nkeep = np.invert(remove)\n\nadata = adata[:,keep]\n\nprint(adata.n_obs, adata.n_vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5888 18830\n```\n:::\n:::\n\n\n## {{< meta qc_sex >}}\n\n\n{{< meta qc_sex_1 >}}\n\n\n\nTo get choromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline\nas it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. Hence, we will use biomart to fetch chromosome information.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# requires pybiomart\nannot = sc.queries.biomart_annotations(\"hsapiens\", [\"ensembl_gene_id\", \"external_gene_name\", \"start_position\", \"end_position\", \"chromosome_name\"], ).set_index(\"external_gene_name\")\n# adata.var[annot.columns] = annot\n```\n:::\n\n\n{{< meta qc_sex_3 >}}\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nchrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"Y\"])\nchrY_genes\n\nadata.obs['percent_chrY'] = np.sum(\n    adata[:, chrY_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n```\n:::\n\n\n{{< meta qc_sex_4 >}}\n\n::: {.cell fig-height='5' fig-width='5' execution_count=20}\n``` {.python .cell-code}\n# color inputs must be from either .obs or .var, so add in XIST expression to obs.\nadata.obs[\"XIST-counts\"] = adata.X[:,adata.var_names.str.match('XIST')].toarray()\n\nsc.pl.scatter(adata, x='XIST-counts', y='percent_chrY', color=\"sample\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-21-output-1.png){}\n:::\n:::\n\n\n{{< meta qc_sex_5 >}}\n\n::: {.cell fig-height='5' fig-width='10' execution_count=21}\n``` {.python .cell-code}\nsc.pl.violin(adata, [\"XIST-counts\", \"percent_chrY\"], jitter=0.4, groupby = 'sample', rotation= 45)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-22-output-1.png){}\n:::\n:::\n\n\n{{< meta qc_sex_6 >}}\n\n\n\n## {{< meta qc_cellcycle >}}\n\n\n{{< meta qc_cellcycle_1 >}}\n\n\n\nFirst read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. We first download the file.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\npath_file = os.path.join(path_results, 'regev_lab_cell_cycle_genes.txt')\nif not os.path.exists(path_file):\n    urllib.request.urlretrieve(os.path.join(path_data, 'regev_lab_cell_cycle_genes.txt'), path_file)\n```\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ncell_cycle_genes = [x.strip() for x in open('./data/covid/results/regev_lab_cell_cycle_genes.txt')]\nprint(len(cell_cycle_genes))\n\n# Split into 2 lists\ns_genes = cell_cycle_genes[:43]\ng2m_genes = cell_cycle_genes[43:]\n\ncell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]\nprint(len(cell_cycle_genes))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n97\n94\n```\n:::\n:::\n\n\nBefore running cell cycle we have to normalize the data. In the scanpy object, the data slot will be overwritten with the normalized data. So first, save the raw data into the slot `raw`. Then run normalization, log transformation and scale the data.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# save normalized counts in raw slot.\nadata.raw = adata\n\n# normalize to depth 10 000\nsc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n\n# logaritmize\nsc.pp.log1p(adata)\n\n# scale\nsc.pp.scale(adata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnormalizing by total count per cell\n    finished (0:00:00): normalized adata.X and added    'n_counts', counts per cell before normalization (adata.obs)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n```\n:::\n:::\n\n\nWe here perform cell cycle scoring. The function is actually a wrapper to sc.tl.score_gene_list, which is launched twice, to score separately S and G2M phases. Both sc.tl.score_gene_list and sc.tl.score_cell_cycle_genes are a port from Seurat and are supposed to work in a very similar way. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nsc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncalculating cell cycle phase\ncomputing score 'S_score'\nWARNING: genes are not in var_names and ignored: ['MLF1IP']\n    finished: added\n    'S_score', score of gene set (adata.obs).\n    727 total control genes are used. (0:00:00)\ncomputing score 'G2M_score'\nWARNING: genes are not in var_names and ignored: ['FAM64A', 'HN1']\n    finished: added\n    'G2M_score', score of gene set (adata.obs).\n    771 total control genes are used. (0:00:00)\n-->     'phase', cell cycle phase (adata.obs)\n```\n:::\n:::\n\n\n{{< meta qc_cellcycle_2 >}}\n\n::: {.cell fig-height='5' fig-width='10' execution_count=26}\n``` {.python .cell-code}\nsc.pl.violin(adata, ['S_score', 'G2M_score'], jitter=0.4, groupby = 'sample', rotation=45)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-27-output-1.png){}\n:::\n:::\n\n\n{{< meta qc_cellcycle_3 >}}\n\n\n\n## {{< meta qc_doublet >}}\n\n\n{{< meta qc_doublet_1 >}}\n\n\n\n:::{.callout-caution}\n\n{{< meta qc_doublet_2 >}}\n\n\n:::\n\nFor doublet detection, we will use the package `Scrublet`, so first we need to get the raw counts from `adata.raw.X` and run scrublet with that matrix. Then we add in the doublet prediction info into our anndata object.\n\nDoublet prediction should be run for each dataset separately, so first we need to split the adata object into 6 separate objects, one per sample and then run scrublet on each of them.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nimport scrublet as scr\n\n# split per batch into new objects.\nbatches = adata.obs['sample'].cat.categories.tolist()\nalldata = {}\nfor batch in batches:\n    tmp = adata[adata.obs['sample'] == batch,]\n    print(batch, \":\", tmp.shape[0], \" cells\")\n    scrub = scr.Scrublet(tmp.raw.X)\n    out = scrub.scrub_doublets(verbose=False, n_prin_comps = 20)\n    alldata[batch] = pd.DataFrame({'doublet_score':out[0],'predicted_doublets':out[1]},index = tmp.obs.index)\n    print(alldata[batch].predicted_doublets.sum(), \" predicted_doublets\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncovid_1 : 900  cells\n25  predicted_doublets\ncovid_15 : 599  cells\n8  predicted_doublets\ncovid_17 : 1101  cells\n18  predicted_doublets\nctrl_5 : 1052  cells\n24  predicted_doublets\nctrl_13 : 1173  cells\n56  predicted_doublets\nctrl_14 : 1063  cells\n32  predicted_doublets\n```\n:::\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n# add predictions to the adata object.\nscrub_pred = pd.concat(alldata.values())\nadata.obs['doublet_scores'] = scrub_pred['doublet_score'] \nadata.obs['predicted_doublets'] = scrub_pred['predicted_doublets'] \n\nsum(adata.obs['predicted_doublets'])\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n163\n```\n:::\n:::\n\n\n{{< meta qc_doublet_3 >}}\n\n::: {.cell fig-height='5' fig-width='5' execution_count=29}\n``` {.python .cell-code}\n# add in column with singlet/doublet instead of True/Fals\n%matplotlib inline\n\nadata.obs['doublet_info'] = adata.obs[\"predicted_doublets\"].astype(str)\nsc.pl.violin(adata, 'n_genes_by_counts', jitter=0.4, groupby = 'doublet_info', rotation=45)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-30-output-1.png){}\n:::\n:::\n\n\nNow, lets run PCA and UMAP and plot doublet scores onto UMAP to check the doublet predictions.\n\n::: {.cell fig-height='4' fig-width='12' execution_count=30}\n``` {.python .cell-code}\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\nadata = adata[:, adata.var.highly_variable]\nsc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\nsc.pp.scale(adata, max_value=10)\nsc.tl.pca(adata, svd_solver='arpack')\nsc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color=['doublet_scores','doublet_info','sample'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nextracting highly variable genes\n    finished (0:00:01)\n--> added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nregressing out ['total_counts', 'pct_counts_mt']\n    finished (0:00:37)\ncomputing PCA\n    on highly variable genes\n    with n_comps=50\n    finished (0:00:02)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 40\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:09)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:07)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](scanpy_01_qc_files/figure-html/cell-31-output-2.png){}\n:::\n:::\n\n\n{{< meta qc_doublet_4 >}}\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n# also revert back to the raw counts as the main matrix in adata\nadata = adata.raw.to_adata() \n\nadata = adata[adata.obs['doublet_info'] == 'False',:]\nprint(adata.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(5725, 18830)\n```\n:::\n:::\n\n\n## {{< meta qc_save >}}\n\n\n{{< meta qc_save_1 >}}\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nadata.write_h5ad('data/covid/results/scanpy_covid_qc.h5ad')\n```\n:::\n\n\n## {{< meta session >}}\n\n<details>\n  <summary>Click here</summary>\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nsc.logging.print_versions()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-----\nanndata     0.10.3\nscanpy      1.9.6\n-----\nPIL                 10.0.0\nannoy               NA\nanyio               NA\nasttokens           NA\nattr                23.1.0\nbabel               2.12.1\nbackcall            0.2.0\ncertifi             2023.11.17\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.8.2\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexceptiongroup      1.2.0\nexecuting           1.2.0\nfastjsonschema      NA\nfuture              0.18.3\ngmpy2               2.1.2\nh5py                3.9.0\nidna                3.4\nigraph              0.10.8\nipykernel           6.23.1\nipython_genutils    0.2.0\njedi                0.18.2\njinja2              3.1.2\njoblib              1.3.2\njson5               NA\njsonpointer         2.0\njsonschema          4.17.3\njupyter_events      0.6.3\njupyter_server      2.6.0\njupyterlab_server   2.22.1\nkiwisolver          1.4.5\nlazy_loader         NA\nleidenalg           0.10.1\nllvmlite            0.41.1\nlouvain             0.8.1\nmarkupsafe          2.1.2\nmatplotlib          3.8.0\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nmpmath              1.3.0\nnatsort             8.4.0\nnbformat            5.8.0\nnumba               0.58.1\nnumpy               1.26.2\nopt_einsum          v3.3.0\noverrides           NA\npackaging           23.1\npandas              2.1.4\nparso               0.8.3\npatsy               0.5.5\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.5.1\nprometheus_client   NA\nprompt_toolkit      3.0.38\npsutil              5.9.5\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npybiomart           0.2.0\npycparser           2.21\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npynndescent         0.5.11\npyparsing           3.1.1\npyrsistent          NA\npythonjsonlogger    NA\npytz                2023.3\nrequests            2.31.0\nrequests_cache      0.4.13\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nscipy               1.11.4\nscrublet            NA\nseaborn             0.12.2\nsend2trash          NA\nsession_info        1.0.0\nsix                 1.16.0\nskimage             0.22.0\nsklearn             1.3.2\nsniffio             1.3.0\nsocks               1.7.1\nsparse              0.14.0\nstack_data          0.6.2\nstatsmodels         0.14.1\nsympy               1.12\ntexttable           1.7.0\nthreadpoolctl       3.2.0\ntorch               2.0.0\ntornado             6.3.2\ntqdm                4.65.0\ntraitlets           5.9.0\ntyping_extensions   NA\numap                0.5.5\nurllib3             2.0.2\nwcwidth             0.2.6\nwebsocket           1.5.2\nyaml                6.0\nzmq                 25.0.2\nzoneinfo            NA\nzstandard           0.19.0\n-----\nIPython             8.13.2\njupyter_client      8.2.0\njupyter_core        5.3.0\njupyterlab          4.0.1\nnotebook            6.5.4\n-----\nPython 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:58:44) [GCC 11.3.0]\nLinux-6.5.11-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-01-07 15:46\n```\n:::\n:::\n\n\n</details>\n\n",
    "supporting": [
      "scanpy_01_qc_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}