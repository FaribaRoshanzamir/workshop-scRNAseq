---
output: html_document
editor_options: 
  chunk_output_type: console
---


#CSS_ALL:author: "Åsa Björklund  &  Paulo Czarnewski"
#CSS_ALL:date: "Sept 13, 2019"
#CSS_ALL:output:
#CSS_ALL:  html_document:
#CSS_ALL:    self_contained: true
#CSS_ALL:    highlight: tango
#CSS_ALL:    df_print: paged
#CSS_ALL:    toc: yes
#CSS_ALL:    toc_float:
#CSS_ALL:      collapsed: false
#CSS_ALL:      smooth_scroll: true
#CSS_ALL:    toc_depth: 3
#CSS_ALL:    keep_md: yes
#CSS_ALL:  html_notebook:
#CSS_ALL:    self_contained: true
#CSS_ALL:    highlight: tango
#CSS_ALL:    df_print: paged
#CSS_ALL:    toc: yes
#CSS_ALL:    toc_float:
#CSS_ALL:      collapsed: false
#CSS_ALL:      smooth_scroll: true
#CSS_ALL:    toc_depth: 3
#CSS_ALL:    keep_md: yes

self_contained: false

#define path to this script (wherever it is)
```{r setup, include=FALSE}
initial.options <- commandArgs(trailingOnly = FALSE)
script_path <- dirname(sub("--file=","",initial.options[grep("--file=",initial.options)]))
setwd(script_path)

dir.create("compiled/seurat",recursive = T)
dir.create("compiled/scater",recursive = T)
dir.create("compiled/scanpy",recursive = T)
```


#----------------------------#
#   GET LIBRARIES AND DATA   #
#----------------------------#
#DATA_TITLE:# Get data

#DATA_ALL1:In this tutorial, we will be using 3 publicly available dataset downloaded from 10X Genomics repository. They can be downloaded using the following bash commands. Simply create a folder called `data` and then use `curl` to pull the data from the 10X database.

#DATA_ALL2:With data in place, now we can start loading libraries we will use in this tutorial.

#DATA_ALL3:We can first load the data individually by reading directly from HDF5 file format (.h5). Note that among those , the dataset p3.1k actually has both gene expression and CITE-seq data, so we will use only the `Gene Expression` here.

#DATA_SEURAT:
#DATA_SCRAN:
#DATA_SCRANPY:
#-----------




#-------------------#
#   CREATE OBJECT   #
#-------------------#
#OBJ_TITLE:# Create Object
#OBJ_ALL1:We can now load the expression matricies into objects and then merge them into a single merged object. Each analysis workflow (Seurat, Scater, Scranpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column `Chemistry` in the metadata for plotting later on.

#OBJ_ALL2: Here it is how the count matrix and the metatada look like for every cell.

#OBJ_SEURAT:
#OBJ_SCRAN:
#OBJ_SCRANPY:
#-----------







#--------#
#   QC   #
#--------#
#QC_TITLE:# Calculate QC

#QC_ALL1:Having the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitocondrial and ribossomal genes per cell and add to the metadata. This will be helpfull to visualize them across different metadata parameteres (i.e. datasetID and chemistry version). There are several ways of doing this, and here manually calculate the proportion of mitochondrial reads and add to the metadata table.

#QC_ALL1.1:Citing from "Simple Single Cell" workflows (Lun, McCarthy & Marioni, 2017): "High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane."

#QC_ALL2:In the same manner we will calculate the proportion gene expression that comes from ribosomal proteins.


#QC_TITLE2:# Plot QC

#QC_ALL3:Now we can plot some of the QC-features as violin plots.

#QC_ALL4:As you can see, the v2 chemistry gives lower gene detection, but higher detection of ribosomal proteins. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. And we can plot the different QC-measures as scatter plots.
#-----------





#---------------#
#   FILTERING   #
#---------------#
#FILTERING_TITLE:# Filtering

#FILTERING_TITLE1:## Detection-based filtering

#FILTERING_ALL0:A standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.

#FILTERING_ALL3:Additionaly, Extremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In these datasets, there is also a clear difference between the v2 vs v3 10x chemistry with regards to gene detection, so it may not be fair to apply the same cutoffs to all of them. Also, in the protein assay data there is a lot of cells with few detected genes giving a bimodal distribution. This type of distribution is not seen in the other 2 datasets. Considering that they are all PBMC datasets it makes sense to regard this distribution as low quality libraries. Filter the cells with high gene detection (putative doublets) with cutoffs 4100 for v3 chemistry and 2000 for v2. Here, we will filter the cells with low gene detection (low quality libraries) with less than 1000 genes for v2 and < 500 for v2.

#FILTERING_ALL01:Additionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.

#FILTERING_ALL02:As you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. Let us assemble some information about such genes, which are important for quality control and downstream filtering.


#FILTERING_TITLE2:## Mito/Ribo filtering

#FILTERING_ALL1:We also have quite a lot of cells with high proportion of mitochondrial and ribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the `percent_mito` variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 25% mitochondrial reads and that will be used as a cutoff.

#FILTERING_ALL2:As you can see, there is still quite a lot of variation in `percent_mito`, so it will have to be dealt with in the data analysis step. We can also notice that the `percent_ribo` are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.



#FILTERING_TITLE4:## Plot filtered QC

#FILTERING_ALL5:Lets plot the same QC-stats another time.
#-----------





#----------------#
#   CELL CYCLE   #
#----------------#
#CELLCYCLE_TITLE:# Calculate cell-cycle scores

#CELLCYCLE_ALL1:We here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.

#CELLCYCLE_SCANPY:First read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. Cell cycle genes were retrieved from the scanpy_usage github site via web browser at [RegevLab Github repo](https://github.com/theislab/scanpy_usage/blob/master/180209_cell_cycle/data/regev_lab_cell_cycle_genes.txt).

#CELLCYCLE_ALL2:We can now plot a violin plot for the cell cycle scores as well.

#CELLCYCLE_ALL3:In this case it looks like we only have a few cycling cells in the datasets.

#CELLCYCLE_ALL4:Finally, lets save the QC-filtered data for further analysis.

#-----------
```{r setup, include=FALSE}
lab <- readLines(paste0(script_path,"/scater/scater_01_qc.Rmd"))
lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

t_lab <- lab
for( i in u ){
  j <- grep(i,t_lab)
  temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
  t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
}

writeLines(t_lab,paste0(script_path,"/compiled/scater/scater_01_qc_compiled.Rmd"))
#rmarkdown::render(paste0(script_path,"/compiled/seurat/seurat_01_qc_compiled.Rmd"))
```









#------------------------------#
#   DIMENSIONALITY REDUCTION   #
#------------------------------#

#DIMRED_TITLE:# Load data

#DIMRED_ALL1:First, let's load all necessary libraries and the QC-filtered dataset from the previous step.

#DIMRED_ALL1.1:## Feature selection

#DIMRED_ALL2:Next, we first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.

#DIMRED_ALL3:## Z-score transformation

#DIMRED_ALL4:Now that the data is prepared, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling is called Z-score normalization it is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use this function to remove any unwanted sources of variation from the dataset, such as `cell cycle`, `sequencing depth`, `percent mitocondria`, etc. 


#---------#
#   PCA   #
#---------#
#PCA_TITLE:# PCA

#PCA_ALL1:Performing PCA has many useful applications and interpretations, which much depends on the data used. In the case of life sciences, we want to segregate samples based on gene expression patterns in the data.
#PCA_SEURAT:To run PCA you can use the function `RunPCA()`.
#PCA_SCRAN:To run PCA you can use the function `runPCA()`.
#PCA_SCANPY:To run PCA, you can use the function `pca()`.

#PCA_ALL2:We can plot the first 6 dimensions like so.

#PCA_ALL3:To identify which genes contribute the most to each PC, one can retreive the loading matrix information:
#PCA_ALL4:The same list of genes can also be visualized as a heatmap.
#PCA_ALL5:We can also plot the amount of variance explained by each PC.
#PCA_ALL6:Based on this plot, we can see that the top 7 PCs retain a lot of information, while other PCs contain pregressivelly less. However, it is still advisable to use more PCs since they might contain informaktion about rare cell types (such as platelets and DCs in this dataset)



#----------#
#   tSNE   #
#----------#
#tSNE_TITLE:# tSNE

#tSNE_ALL1:We can now run [BH-tSNE](https://arxiv.org/abs/1301.3342).

#tSNE_ALL2:We can now plot the tSNE colored per dataset. We can start now clearly seeing the effect of batches present in the dataset.



#----------#
#   UMAP   #
#----------#
#UMAP_TITLE:# UMAP

#UMAP_ALL1:We can now run [UMAP](https://arxiv.org/abs/1802.03426).

#UMAP_ALL2:We can now plot the UMAP colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.



#DIMRED_TITLE2:

#DIMRED_ALL5:

#DIMRED_ALL6:Let's plot some marker genes for different celltypes onto the embedding. Some genes are:

#MARKER_TABLE:Markers	| Cell Type
#MARKER_TABLE:--- | ---
#MARKER_TABLE:CD3E	| T cells
#MARKER_TABLE:CD3E CD4	| CD4+ T cells
#MARKER_TABLE:CD3E CD8A	| CD8+ T cells
#MARKER_TABLE:GNLY, NKG7	| NK cells
#MARKER_TABLE:MS4A1	| B cells
#MARKER_TABLE:CD14, LYZ, CST3, MS4A7	| CD14+ Monocytes
#MARKER_TABLE:FCGR3A, LYZ, CST3, MS4A7	| FCGR3A+  Monocytes
#MARKER_TABLE:FCER1A, CST3 | DCs


#DIMRED_ALL7:Here, we can conclude that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis. We can now save the object for use in the next step.


```{r setup, include=FALSE}
lab <- readLines(paste0(script_path,"/scater/scater_02_dim_reduction.Rmd"))
lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

t_lab <- lab
for( i in u ){
  j <- grep(i,t_lab)
  temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
  t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
}

writeLines(t_lab,paste0(script_path,"/compiled/scater/scater_02_dim_reduction_compiled.Rmd"))
```
#-----------











#----------------------#
#   DATA INTEGRATION   #
#----------------------#
#INTEG_TITLE:# Data Integration

#INTEG_ALL1:In this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore two different methods to correct for batch effects across datasets. We will also look at a quantitative measure to assess the quality of the integrated data. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of the most recent methods for single data integration:

#INTEG_TABLE:Markdown | Language | Library | Ref
#INTEG_TABLE:--- | --- | --- | ---
#INTEG_TABLE:CCA | R | Seurat | [Cell](https://www.sciencedirect.com/science/article/pii/S0092867419305598?via%3Dihub)
#INTEG_TABLE:MNN | R/Python | Scater/Scanpy | [Nat. Biotech.](https://www.nature.com/articles/nbt.4091)
#INTEG_TABLE:Conos | R | conos | [Nat. Methods](https://www.nature.com/articles/s41592-019-0466-z?error=cookies_not_supported&code=5680289b-6edb-40ad-9934-415dac4fdb2f)
#INTEG_TABLE:Scanorama | Python | scanorama | [Nat. Biotech.](https://www.nature.com/articles/s41587-019-0113-3)

#INTEG_ALL2:Let's first load necessary libraries and the data saved in the previous lab.

#INTEG_ALL3:We split the combined object into a list, with each dataset as an element. We perform standard preprocessing (log-normalization), and identify variable features individually for each dataset based on a variance stabilizing transformation ("vst").

#INTEG_SEURAT1:We identify anchors using the FindIntegrationAnchors function, which takes a list of Seurat objects as input.

#INTEG_SEURAT2:We then pass these anchors to the IntegrateData function, which returns a Seurat object.

#INTEG_SEURAT3:We can observe that a new assay slot is now created under the name `CCA`.

#INTEG_SEURAT4:After running IntegrateData, the Seurat object will contain a new Assay with the integrated (or ‘batch-corrected’) expression matrix. Note that the original (uncorrected values) are still stored in the object in the “RNA” assay, so you can switch back and forth. We can then use this new integrated matrix for downstream analysis and visualization. Here we scale the integrated data, run PCA, and visualize the results with UMAP and TSNE. The integrated datasets cluster by cell type, instead of by technology.


#INTEG_ALL4:We can now plot the count and the integrated space reduced dimensions.

#INTEG_ALL5:Finally, lets save the integrated data for further analysis.

```{r setup, include=FALSE}
lab <- readLines(paste0(script_path,"/seurat/seurat_03_integration.Rmd"))
lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

t_lab <- lab
for( i in u ){
  j <- grep(i,t_lab)
  temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
  t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
}

writeLines(t_lab,paste0(script_path,"/compiled/seurat/seurat_03_integration_compiled.Rmd"))
```

#-----------












#----------------#
#   KNN-GRAPHS   #
#----------------#
#KNN_ALL:

#-----------






#----------------#
#   CLUSTERING   #
#----------------#
#CLUST_ALL:

#-----------





#-----------------#
#   DGE-MARKERS   #
#-----------------#
#DGEM_ALL:

#-----------






#--------------------#
#   DGE-CONDITIONS   #
#--------------------#
#DGEC_ALL:

#-----------





